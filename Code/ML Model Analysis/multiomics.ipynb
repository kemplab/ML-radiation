{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot, lines\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "from scipy.stats import ttest_ind, spearmanr\n",
    "import glob\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import pairwise_distances, roc_curve, jaccard_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import pearsonr, f_oneway, linregress\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from scipy.stats import f_oneway, linregress, chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder and datset names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'withhyperopt_3'\n",
    "individual_datasets = ['clinical','gene_all','mutation_onehot_all','objscreen_kegg']\n",
    "individual_datasets_labels = ['Clinical','Gene Expression','Mutation','Metabolites']\n",
    "colors = ['#FFD700','#3DAEC5','#2E8B57','#DC143C']\n",
    "n_splits = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '_shap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_stacker = True\n",
    "analyze_shap_values = True\n",
    "analyze_shap_interactions = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of dataset\n",
    "dataset_name = '+'.join(individual_datasets)\n",
    "\n",
    "# output folders\n",
    "if not os.path.isdir('%s/%s/%s' % (folder_name, dataset_name, output_folder)):\n",
    "    os.mkdir('%s/%s/%s' % (folder_name, dataset_name, output_folder))\n",
    "    \n",
    "    # stacker\n",
    "    if analyze_stacker:\n",
    "        os.mkdir('%s/%s/%s/stacker' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/stacker/summary' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/stacker/clinical_features' % (folder_name, dataset_name, output_folder))\n",
    "        \n",
    "    # shap values\n",
    "    if analyze_shap_values:\n",
    "        os.mkdir('%s/%s/%s/shap_values' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/summary' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/summary/cohort' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/features' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/patients' % (folder_name, dataset_name, output_folder))\n",
    "    \n",
    "    # shap interactions\n",
    "    if analyze_shap_interactions:\n",
    "        os.mkdir('%s/%s/%s/shap_interactions' % (folder_name, dataset_name, output_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merged dataset\n",
    "with open('_datasets/%s.pickle' % individual_datasets[0], 'rb') as f:\n",
    "    X_matrix, y_vector, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "X_matrix.columns = ['%s # %s' % (individual_datasets[0], x) for x in X_matrix.columns.tolist()]\n",
    "categorical_conversion = {}\n",
    "for key in categorical_conversion_old:\n",
    "    categorical_conversion['%s # %s' % (individual_datasets[0], key)] = categorical_conversion_old[key]\n",
    "for b in range(1,len(individual_datasets)):\n",
    "    with open('_datasets/%s.pickle' % individual_datasets[b], 'rb') as f:\n",
    "        X_matrix_, y_vector_, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "    X_matrix_.columns = ['%s # %s' % (individual_datasets[b], x) for x in X_matrix_.columns.tolist()]\n",
    "    categorical_conversion_ = {}\n",
    "    for key in categorical_conversion_old:\n",
    "        categorical_conversion_['%s # %s' % (individual_datasets[b], key)] = categorical_conversion_old[key]\n",
    "    if X_matrix.index.tolist() == X_matrix_.index.tolist():\n",
    "        X_matrix = pd.concat([X_matrix, X_matrix_], axis=1)\n",
    "        categorical_conversion = {**categorical_conversion, **categorical_conversion_}\n",
    "    else:\n",
    "        raise Exception(\"Dataset sample lists don't match\")\n",
    "samples = X_matrix.index.tolist()\n",
    "features =  X_matrix.columns.tolist()\n",
    "\n",
    "# list of merged features\n",
    "if len(categorical_conversion) > 0:\n",
    "    merged_features = []\n",
    "    for feature in features:\n",
    "        if feature.split(' | ')[0] not in categorical_conversion:\n",
    "            merged_features.append(feature)\n",
    "        elif feature.split(' | ')[0] not in merged_features:\n",
    "            merged_features.append(feature.split(' | ')[0])\n",
    "else:\n",
    "    merged_features = features.copy()\n",
    "    \n",
    "# merge feature matrix\n",
    "X_matrix_ = X_matrix.copy()\n",
    "for feature in categorical_conversion:\n",
    "    X_matrix_[feature] = np.nan\n",
    "    X_matrix_[feature] = X_matrix_[feature].astype(object)\n",
    "    \n",
    "    # get values for categorical features\n",
    "    values = []\n",
    "    for sample in X_matrix.index.tolist():\n",
    "        for val in categorical_conversion[feature]:\n",
    "            if X_matrix.at[sample,'%s | %s' % (feature, val)] == 1:\n",
    "                X_matrix_.at[sample, feature] = val\n",
    "X_matrix = X_matrix_[merged_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacker - log loss\n",
    "if analyze_stacker:\n",
    "    df = pd.read_csv('%s/stacker_logloss.csv' % folder_name, index_col=0)\n",
    "    stacker_log_loss = df.loc[['split_%d' % (i+1) for i in range(n_splits)]][dataset_name].values.tolist()\n",
    "    stacker_performance_weights = [1/x for x in stacker_log_loss]\n",
    "\n",
    "# classifier - weighted log loss\n",
    "df = pd.read_csv('%s/weightedlogloss.csv' % folder_name, index_col=0)\n",
    "classifier_weighted_log_loss = df.loc[['split_%d' % (i+1) for i in range(n_splits)]][dataset_name].values.tolist()\n",
    "classifier_performance_weights = [1/x for x in classifier_weighted_log_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "        \n",
    "    # load shap values\n",
    "    shap_expected = []\n",
    "    shap_values = []\n",
    "    for i in range(n_splits):\n",
    "        with open('%s/%s/shap_values_%d.pickle' % (folder_name, dataset_name, i+1) ,'rb') as f:\n",
    "            shap_expected_, shap_values_ = pickle.load(f)\n",
    "            shap_expected.append(shap_expected_)\n",
    "            shap_values.append(shap_values_)\n",
    "            \n",
    "    # remove samples that aren't analyzed\n",
    "    keep_index = []\n",
    "    for i,sample in enumerate(samples):\n",
    "        to_keep = False\n",
    "        for j in range(n_splits):\n",
    "            if sample in shap_values[j].index.tolist():\n",
    "                to_keep = True\n",
    "        if to_keep:\n",
    "            keep_index.append(i)\n",
    "    samples = [samples[i] for i in keep_index]\n",
    "    y_vector = [y_vector[i] for i in keep_index]\n",
    "    X_matrix = X_matrix.iloc[keep_index]\n",
    "    \n",
    "    # combine expected values\n",
    "    _expected_value_sum = [0 for sample in samples]\n",
    "    _shap_weight = [0 for sample in samples]\n",
    "    for i,sample in enumerate(samples):\n",
    "        for j in range(n_splits):\n",
    "            if sample in shap_values[j].index.tolist():\n",
    "                _expected_value_sum[i] += classifier_performance_weights[j] * shap_expected[j][shap_values[j].index.tolist().index(sample)]\n",
    "                _shap_weight[i] += classifier_performance_weights[j]\n",
    "    expected_value = np.divide(_expected_value_sum, _shap_weight)\n",
    "    \n",
    "    # combine shap values\n",
    "    for i in range(n_splits):\n",
    "        samples_not_included = [x for x in samples if x not in shap_values[i].index.tolist()]\n",
    "        shap_values[i] = pd.concat([shap_values[i], pd.DataFrame(data=0, index=samples_not_included, columns=shap_values[i].columns.tolist())])\n",
    "        shap_values[i] = shap_values[i].loc[samples]\n",
    "        features_not_included = [x for x in merged_features if x not in shap_values[i].columns.tolist()]\n",
    "        shap_values[i] = pd.concat([shap_values[i], pd.DataFrame(data=0, index=samples, columns=features_not_included)], axis=1, sort=False)\n",
    "        shap_values[i] = shap_values[i][merged_features]\n",
    "    shap_value = pd.DataFrame(data=0, index=samples, columns=merged_features)\n",
    "    for i in range(n_splits):\n",
    "        shap_value = np.add(shap_value, classifier_performance_weights[i]*shap_values[i])\n",
    "    for j in range(len(samples)):\n",
    "        shap_value.loc[samples[j]] /= _shap_weight[j]\n",
    "    \n",
    "    # calculate absolute shap values\n",
    "    shap_value_abs = shap_value.abs()\n",
    "    \n",
    "    # zero shap values for imputed features\n",
    "    for sample in shap_value_abs.index.tolist():\n",
    "        for feature in shap_value_abs.columns.tolist():\n",
    "            if pd.isna(X_matrix.at[sample,feature]):\n",
    "                shap_value_abs.at[sample,feature] = 0\n",
    "    \n",
    "    # normalize by difference between prior and posterior\n",
    "    for i,sample in enumerate(samples):\n",
    "        shap_value_abs.loc[sample] /= np.sum(shap_value_abs.loc[sample].values.tolist())\n",
    "        \n",
    "    # mean and standard error for each feature\n",
    "    shap_value_abs_mean = shap_value_abs.mean(axis=0).values.tolist()\n",
    "    shap_value_abs_mean_cumsum = np.cumsum(sorted(shap_value_abs_mean)[::-1])\n",
    "    shap_value_abs_std = shap_value_abs.std(axis=0).values.tolist()\n",
    "    shap_value_abs_sterr = [x/np.sqrt(len(samples)) for x in shap_value_abs_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_value.T.to_csv('dataset4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([x.split(' # ')[-1] for x in shap_value.columns.tolist()]).to_csv('dataset4_features.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([x.split(' # ')[0] for x in shap_value.columns.tolist()]).to_csv('dataset4_sets.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "\n",
    "    # top 95% features\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1][:len([x for x in shap_value_abs_mean_cumsum if x<=0.95])]\n",
    "    overall_top_features = [merged_features[i] for i in top_N_index]\n",
    "    overall_top_values = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "    \n",
    "    # top N features - mean\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1]\n",
    "    top_N_mean = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "\n",
    "    # plot - all shap values\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=18)\n",
    "    plt.rc('ytick', labelsize=18)\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xscale('log')\n",
    "    ax.plot(range(1,len(merged_features)+1), sorted(shap_value_abs_mean)[::-1], 'k.-', markersize=5)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.ylim(-0.0001,0.12)\n",
    "    plt.yticks([0,0.02,0.04,0.06,0.08,0.1,0.12])\n",
    "    plt.xlabel('Features', fontsize=20)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range(1,len(merged_features)+1), shap_value_abs_mean_cumsum, '.-', color='#808080', markersize=5)\n",
    "    ax2.plot([len([x for x in shap_value_abs_mean_cumsum if x<=0.95]),len([x for x in shap_value_abs_mean_cumsum if x<=0.95])],[0,0.95],'--',color='#808080')\n",
    "    ax2.plot([len([x for x in shap_value_abs_mean_cumsum if x<=0.95]),1.1*len(merged_features)],[0.95,0.95],'--',color='#808080')\n",
    "    ax2.plot([len([x for x in shap_value_abs_mean if x>0]),len([x for x in shap_value_abs_mean if x>0])],[0,1],'--',color='#808080')\n",
    "    ax2.tick_params(axis='y', labelcolor='#808080')\n",
    "    ax2.set_ylabel('Cumulative Sum', color='#808080', fontsize=20)\n",
    "    ax2.set_ylim(0,1.01)\n",
    "    ax2.set_yticks([0,0.25,0.5,0.75,0.95,1])\n",
    "    num_int = len(str(len(merged_features)))\n",
    "    plt.xticks([10**x for x in range(num_int)][:-1]+[len(merged_features)],[10**x for x in range(num_int)][:-1]+[len(merged_features)])\n",
    "    plt.xlim(0.95,1.05*len(merged_features))  \n",
    "    plt.text(len([x for x in shap_value_abs_mean_cumsum if x<=0.95]),0.03,'%d' % len([x for x in shap_value_abs_mean_cumsum if x<=0.95]), weight='bold', ha='right', fontsize=20)\n",
    "    plt.text(len([x for x in shap_value_abs_mean if x>0]),0.03,'%d' % len([x for x in shap_value_abs_mean if x>0]), ha='left', fontsize=20)\n",
    "    #plt.text(len(merged_features),0.03,'%d' % len(merged_features), weight='bold', ha='right', fontsize=20)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    vals = ax2.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax2.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax2.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax2.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/all_features.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "    \n",
    "    # plot - number of top features in each dataset\n",
    "    number_of_top_features = []\n",
    "    for dataset in individual_datasets:\n",
    "        number_of_top_features.append(len([x for x in overall_top_features if x.split(' # ')[0]==dataset]))\n",
    "    def func(pct, allvals):\n",
    "        absolute = int(np.round(pct/100.*np.sum(number_of_top_features)))\n",
    "        return \"{:d}\".format(absolute)\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #patches, texts, autotexts = plt.pie(number_of_top_features, labels=individual_datasets_labels, colors=colors, autopct=lambda pct: func(pct, number_of_top_features))\n",
    "    patches, texts, autotexts = plt.pie(number_of_top_features, colors=colors, autopct=lambda pct: func(pct, number_of_top_features))\n",
    "    for i in range(len(texts)):\n",
    "        texts[i].set_fontsize(24)\n",
    "        autotexts[i].set_fontsize(30)\n",
    "    plt.title('Number of Features', fontsize=30)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_number.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()\n",
    "        \n",
    "    # plot - dataset contribution\n",
    "    dataset_contribution = []\n",
    "    for dataset in individual_datasets:\n",
    "        dataset_contribution.append(np.sum([x for i,x in enumerate(shap_value_abs_mean) if merged_features[i].split(' # ')[0]==dataset and merged_features[i] in overall_top_features]))\n",
    "    dataset_contribution = [x/np.sum(dataset_contribution) for x in dataset_contribution]\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #patches, texts, autotexts = plt.pie(dataset_contribution, labels=individual_datasets_labels, colors=colors, autopct='%1.1f%%')\n",
    "    patches, texts, autotexts = plt.pie(dataset_contribution, colors=colors, autopct='%1.1f%%')\n",
    "    for i in range(len(texts)):\n",
    "        texts[i].set_fontsize(24)\n",
    "        autotexts[i].set_fontsize(26)\n",
    "    plt.title('Contribution of Features', fontsize=30)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot - individual patient dataset contribution\n",
    "dataset_contribution_individual = [[] for dataset in individual_datasets]\n",
    "dataset_contribution_individual_top = [[] for dataset in individual_datasets]\n",
    "for j,sample in enumerate(samples):\n",
    "    sample_values = shap_value_abs.loc[sample].values.tolist()\n",
    "    for i,dataset in enumerate(individual_datasets):\n",
    "        dataset_contribution_individual[i].append(np.sum([sample_values[a] for a in range(len(merged_features)) if merged_features[a].split(' # ')[0]==dataset and merged_features[a] in overall_top_features])/np.sum(sample_values))\n",
    "    if np.sum([sample_values[a] for a in range(len(merged_features)) if merged_features[a].split(' # ')[0]==dataset and merged_features[a] in overall_top_features])/np.sum(sample_values) > (1/len(individual_datasets)):\n",
    "        dataset_contribution_individual_top[i].append(sample)\n",
    "        \n",
    "# move clinical to end\n",
    "dataset_contribution_individual_ = dataset_contribution_individual.copy()\n",
    "dataset_contribution_individual_.append(dataset_contribution_individual_.pop(0))\n",
    "individual_datasets_labels_ = individual_datasets_labels.copy()\n",
    "individual_datasets_labels_.append(individual_datasets_labels_.pop(0))\n",
    "colors_ = colors.copy()\n",
    "colors_.append(colors_.pop(0))\n",
    "        \n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig = plt.figure(figsize=(3*len(individual_datasets),10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rc('xtick', labelsize=22)\n",
    "plt.rc('ytick', labelsize=30)\n",
    "fig = sns.boxplot(data=dataset_contribution_individual_, whis=1, fliersize=0, palette=colors_)\n",
    "fig = sns.swarmplot(data=dataset_contribution_individual_, color='black', alpha=0.25)\n",
    "plt.xlim([-0.5,len(individual_datasets)-0.5])\n",
    "fig.set(xticklabels=individual_datasets_labels_)\n",
    "fig.spines['right'].set_visible(False)\n",
    "fig.spines['top'].set_visible(False)\n",
    "plt.ylabel('Percent Contribution', fontsize=32)\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_individual.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#3DAEC5','#2E8B57','#DC143C','#FFD700']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig = plt.figure(figsize=(3*len(individual_datasets),10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rc('xtick', labelsize=26)\n",
    "plt.rc('ytick', labelsize=30)\n",
    "fig = sns.boxplot(data=dataset_contribution_individual_, whis=1, fliersize=0, palette=colors)\n",
    "fig = sns.swarmplot(data=dataset_contribution_individual_, color='black', alpha=0.25)\n",
    "plt.xlim([-0.5,len(individual_datasets)-0.5])\n",
    "fig.set(xticklabels=individual_datasets_labels_)\n",
    "fig.spines['right'].set_visible(False)\n",
    "fig.spines['top'].set_visible(False)\n",
    "plt.ylabel('Percent Contribution', fontsize=32)\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_individual.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "seed_ = 1\n",
    "def compute_inertia(a, X):\n",
    "    W = [np.mean(pairwise_distances(X[a == c, :])) for c in np.unique(a)]\n",
    "    return np.mean(W)\n",
    "\n",
    "def compute_gap(clustering, data, k_max=5, n_references=100):\n",
    "    if len(data.shape) == 1:\n",
    "        data = data.reshape(-1, 1)\n",
    "    reference = np.random.rand(*data.shape)\n",
    "    reference_inertia = []\n",
    "    for k in range(1, k_max+1):\n",
    "        local_inertia = []\n",
    "        for _ in range(n_references):\n",
    "            clustering.n_clusters = k\n",
    "            assignments = clustering.fit_predict(reference)\n",
    "            local_inertia.append(compute_inertia(assignments, reference))\n",
    "        reference_inertia.append(np.mean(local_inertia))\n",
    "    \n",
    "    ondata_inertia = []\n",
    "    for k in range(1, k_max+1):\n",
    "        clustering.n_clusters = k\n",
    "        assignments = clustering.fit_predict(data)\n",
    "        ondata_inertia.append(compute_inertia(assignments, data))\n",
    "        \n",
    "    gap = np.log(reference_inertia)-np.log(ondata_inertia)\n",
    "    return gap, np.log(reference_inertia), np.log(ondata_inertia)\n",
    "\n",
    "# calculate optimal number of distrubutions\n",
    "k_max = 10\n",
    "gap, reference_inertia, ondata_inertia = compute_gap(KMeans(random_state=seed_), np.array(dataset_contribution_individual[0]).reshape(-1,1), k_max=k_max)\n",
    "optimal_number_of_distributions = np.argmax(gap)+1\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1,k_max+1), gap, 'k.-', markersize=5)\n",
    "ax.plot([optimal_number_of_distributions, optimal_number_of_distributions],[0.15,np.max(gap)], 'k--')\n",
    "plt.xlabel('Number of Distributions', fontsize=20)\n",
    "plt.ylabel('Gap Statistic', fontsize=20)\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10])\n",
    "plt.ylim([0.15,0.3])\n",
    "plt.yticks([0.15,0.2,0.25,0.3])\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/clinical_kmeans_gap.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# separate samples into distributions\n",
    "kmeans = KMeans(n_clusters=optimal_number_of_distributions).fit(np.array(dataset_contribution_individual[0]).reshape(-1,1))\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_.reshape(-1,)\n",
    "distribution_labels = []\n",
    "for val in labels:\n",
    "    distribution_labels.append(sorted(centers).index(centers[val]))\n",
    "distribution_names = ['low','medium','high']\n",
    "distribution_names_labels = ['Low','Medium','High']\n",
    "\n",
    "# histogram\n",
    "values = dataset_contribution_individual[0]\n",
    "n_bins = 25\n",
    "_, bin_edges = np.histogram(values, bins=n_bins)\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "colors_ = ['#FFFACD','#F0E68C','#BFBB99']\n",
    "for i in range(optimal_number_of_distributions):\n",
    "    sns.distplot([values[a] for a in range(len(values)) if distribution_labels[a]==i], hist=True, kde=True, bins=bin_edges, color=colors_[i], hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4})\n",
    "plt.legend(['Low Clinical - %0.1f%%' % (len([x for x in distribution_labels if x==0])/len(distribution_labels)*100),'Medium Clinical - %0.1f%%' % (len([x for x in distribution_labels if x==1])/len(distribution_labels)*100),'High Clinical - %0.1f%%' % (len([x for x in distribution_labels if x==2])/len(distribution_labels)*100)], fontsize=16)\n",
    "plt.xlabel('Percent Contribution - Clinical', fontsize=20)\n",
    "plt.ylabel('Density', fontsize=20)    \n",
    "plt.xlim(0,1)\n",
    "plt.xticks([0,0.25,0.5,0.75,1],['0%','25%','50%','75%','100%'])\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/clinical_multimodal.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# dataset contribution - low/med/high clinical\n",
    "for a in range(len(distribution_names)):\n",
    "    \n",
    "    # subset shap values\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = shap_value_abs_distribution.mean(axis=0).values.tolist()\n",
    "    \n",
    "    # new top features\n",
    "    shap_value_abs_distribution_cumsum = np.cumsum(sorted(shap_value_abs_distribution_mean)[::-1])\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:len([x for x in shap_value_abs_distribution_cumsum if x<=0.95])]\n",
    "    new_overall_top_features = [merged_features[i] for i in top_N_index]\n",
    "    \n",
    "    # dataset contribution\n",
    "    dataset_contribution_distribution = []\n",
    "    for dataset in individual_datasets:\n",
    "        dataset_contribution_distribution.append(np.sum([x for i,x in enumerate(shap_value_abs_distribution_mean) if merged_features[i].split(' # ')[0]==dataset and merged_features[i] in new_overall_top_features]))\n",
    "    dataset_contribution_distribution = [x/np.sum(dataset_contribution_distribution) for x in dataset_contribution_distribution]\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    patches, texts, autotexts = plt.pie(dataset_contribution_distribution, colors=colors, autopct='%1.1f%%')\n",
    "    plt.title('%s Clinical' % distribution_names_labels[a], fontsize=30)\n",
    "    for i in range(len(texts)):\n",
    "        texts[i].set_fontsize(24)\n",
    "        autotexts[i].set_fontsize(26)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_clinical_%s.png' % (folder_name, dataset_name, output_folder, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'objscreen_kegg # HC02065'\n",
    "title = 'Triglyceride pool'\n",
    "\n",
    "# get values\n",
    "val = X_matrix[feature].values.tolist()\n",
    "sh = shap_value[feature].values.tolist()\n",
    "keep_index = [i for i,x in enumerate(val) if not pd.isna(x)]\n",
    "val = [val[i] for i in keep_index]\n",
    "sh = [sh[i] for i in keep_index]\n",
    "\n",
    "# spearman correlation\n",
    "from scipy.stats import spearmanr\n",
    "r = spearmanr(val,sh).correlation\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(val, sh, 'k.', markersize=5)\n",
    "plt.plot([0.00001,0.1],[0,0],'k--',linewidth=1)\n",
    "plt.title(title, fontsize=18)\n",
    "ax.set_xscale('log')\n",
    "plt.xlim([1e-4,1e-2])\n",
    "#plt.ylim([-0.01,0.025])\n",
    "#plt.yticks([-0.01,0,0.01,0.02])\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.xlabel(r'Metabolite Production [mmol gDW$^{-1}$ hr$^{-1}$]', fontsize=15)\n",
    "plt.ylabel(r'$\\Delta$P', fontsize=20)\n",
    "plt.savefig('%s/%s/%s/shap_values/example/met2.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'objscreen_kegg # but'\n",
    "title = 'Butyric acid'\n",
    "\n",
    "# get values\n",
    "val = X_matrix[feature].values.tolist()\n",
    "sh = shap_value[feature].values.tolist()\n",
    "keep_index = [i for i,x in enumerate(val) if not pd.isna(x)]\n",
    "val = [val[i] for i in keep_index]\n",
    "sh = [sh[i] for i in keep_index]\n",
    "\n",
    "# spearman correlation\n",
    "from scipy.stats import spearmanr\n",
    "r = spearmanr(val,sh).correlation\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(val, sh, 'k.', markersize=5)\n",
    "plt.plot([1e-5,1e1],[0,0],'k--',linewidth=1)\n",
    "plt.title(title, fontsize=18)\n",
    "ax.set_xscale('log')\n",
    "plt.xlim([1e-5,1e1])\n",
    "plt.ylim([-0.01,0.03])\n",
    "plt.yticks([-0.01,0,0.01,0.02,0.03])\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.xlabel(r'Metabolite Production [mmol gDW$^{-1}$ hr$^{-1}$]', fontsize=15)\n",
    "plt.ylabel(r'$\\Delta$P', fontsize=20)\n",
    "plt.savefig('%s/%s/%s/shap_values/example/met.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_names = ['Histology','Cisplatin response','Cancer type','Pathologic M','Clinical stage','Temozolomide response','IDH1 SNP','Fluorouracil response','Cyclophosphamide response','Tumor location','Patient age','Pathologic T','Carboplatin response','Pathologic N','Pathologic stage','Paclitaxel response','Butyric acid','Prostaglandin D2','Heparan sulfate','Patient race','BRAF SNP','Patient gender','EGFR SNP','O-D-Mannosylprotein','Saccharopine','Digalactosylceramidesulfate','S-Glutaryldihydrolipoamide','Clinical grade','Estrone sulfate','CDH10','Pyroglutamic acid','3-Sulfinoalanine','CDK5R2','4-Phosphopantothenoylcysteine','LY75','dGTP','Clinical T','Prostaglandin J2','Phytosphingosine',\"Pantetheine 4'-phosphate\",'Elaidic acid','Smoking history','Triglyceride pool','Alcohol per day','HOMER2','Adrenic acid','P2RX6','Capric acid','DNAH9 SNP','Pack years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "    \n",
    "    # N value\n",
    "    N = 50\n",
    "    \n",
    "    # top N features - mean\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1][:N]\n",
    "    top_N_mean = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    colors_ = []\n",
    "    for dataset in top_N_datasets:\n",
    "        colors_.append(colors[individual_datasets.index(dataset)])\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5)\n",
    "    for i in range(len(barlist)):\n",
    "        barlist[i].set_color(colors_[i])\n",
    "    plt.xticks(range(N), top_features_names, rotation=90, fontsize=14)\n",
    "    plt.xlim(-1,N)\n",
    "    plt.yticks([0,0.02,0.04,0.06,0.08,0.1,0.12])\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=22)\n",
    "    plt.title('All Patients', fontsize=24)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.legend([barlist[colors_.index(x)] for x in colors], individual_datasets_labels, fontsize=18, frameon=False)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/top%d.png' % (folder_name, dataset_name, output_folder, N), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features_names = ['Histology','IDH1 SNP','Cancer type','Pathologic M','Clinical stage','Pathologic T','Patient age','Butyric acid','Prostaglandin D2','Pathologic N','EGFR SNP','BRAF SNP','Heparan sulfate','O-D-Mannosylprotein','Pathologic Stage','Saccharopine','Digalactosylceramidesulfate','S-Glutaryldihydrolipoamide','CDH10','Estrone sulfate','Tumor location','3-Sulfinoalanine','Pyroglutamic acid',\"Pantetheine 4'-phosphate\",'CDK5R2','LY75','4-Phosphopantothenoylcysteine','Triglyceride pool','dGTP','Patient race','Prostaglandin J2','Patient gender','Clinical T','HOMER2','Elaidic acid','Phytosphingosine','P2RX6','DNAH9 SNP','Capric acid','TSC22D4','3-Sulfinylpyruvic acid','Adrenic acid','Phenylacetylglutamine','Clinical grade','Indole-5,6-quinone','INPP5J','GTP','Carboplatin response','SEMA5B','Phosphatidylinositol pool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top N features - mean - low clinical\n",
    "for a in range(len(distribution_names))[0:1]:\n",
    "\n",
    "    # get values\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = shap_value_abs_distribution.mean(axis=0).values.tolist()\n",
    "    shap_value_abs_distribution_std = shap_value_abs_distribution.std(axis=0).values.tolist()\n",
    "    shap_value_abs_distribution_sterr = [x/np.sqrt(len([y for y in distribution_labels if y==a])) for x in shap_value_abs_distribution_std]\n",
    "\n",
    "    # plot\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:N]\n",
    "    top_N_mean = [shap_value_abs_distribution_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_distribution_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    colors_ = []\n",
    "    for dataset in top_N_datasets:\n",
    "        colors_.append(colors[individual_datasets.index(dataset)])\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(22,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5)\n",
    "    for i in range(len(barlist)):\n",
    "        barlist[i].set_color(colors_[i])\n",
    "    plt.xticks(range(N), top_features_names, rotation=90, fontsize=14)\n",
    "    plt.xlim(-1,N)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.title('%s Clinical Patients' % distribution_names_labels[a], fontsize=24)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.legend([barlist[colors_.index(x)] for x in colors], individual_datasets_labels, fontsize=18, frameon=False)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/top%d_clinical_%s.png' % (folder_name, dataset_name, output_folder, N, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drug Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of drugs\n",
    "drugs = ['Cisplatin','Temozolomide','Fluorouracil','Cyclophosphamide','Carboplatin','Paclitaxel']\n",
    "responses = ['Complete Response','Partial Response','Stable Disease','Clinical Progressive Disease']\n",
    "responses_color = ['#5bc2ae','#a5d98f','#e6da81','#d93f20']\n",
    "\n",
    "# initialize drug responses\n",
    "response_sensitive = [[0,0,0,0] for drug in drugs]\n",
    "response_resistant = [[0,0,0,0] for drug in drugs]\n",
    "\n",
    "# iterate over drugs:\n",
    "for i,drug in enumerate(drugs):\n",
    "\n",
    "    # iterate over samples\n",
    "    for j,sample in enumerate(samples):\n",
    "\n",
    "        # record drug response\n",
    "        if X_matrix.at[sample,'clinical # RESPONSE DRUG %s' % drug] in responses:\n",
    "            if y_vector[j]==0:\n",
    "                response_sensitive[i][responses.index(X_matrix.at[sample,'clinical # RESPONSE DRUG %s' % drug])] += 1\n",
    "            else:\n",
    "                response_resistant[i][responses.index(X_matrix.at[sample,'clinical # RESPONSE DRUG %s' % drug])] += 1\n",
    "                \n",
    "# convert to fraction\n",
    "for i in range(len(response_sensitive)):\n",
    "    response_sensitive[i] = [x/np.sum(response_sensitive[i]) for x in response_sensitive[i]]\n",
    "for i in range(len(response_resistant)):\n",
    "    response_resistant[i] = [x/np.sum(response_resistant[i]) for x in response_resistant[i]]\n",
    "                \n",
    "# stacked bar plot\n",
    "width=0.4\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plots_sensitive = []\n",
    "plots_resistant = []\n",
    "for i in range(len(responses)):\n",
    "    plots_sensitive.append(plt.bar(np.arange(len(drugs)), [response_sensitive[a][i] for a in range(len(drugs))], bottom=[np.sum(response_sensitive[a][:i]) for a in range(len(drugs))], align='edge', width=-width, color=responses_color[i]))\n",
    "    plots_resistant.append(plt.bar(np.arange(len(drugs)), [response_resistant[a][i] for a in range(len(drugs))], bottom=[np.sum(response_resistant[a][:i]) for a in range(len(drugs))], align='edge', width=width, color=responses_color[i]))\n",
    "plt.xticks([-width/2+x for x in range(len(drugs))]+[width/2+x for x in range(len(drugs))], ['Sensitive' for x in range(len(drugs))]+['Resistant' for x in range(len(drugs))], fontsize=18, rotation=90)\n",
    "plt.text(5.8,0.95,'Drug Response', fontsize=18)\n",
    "plt.legend(plots_sensitive,responses, fontsize=16, bbox_to_anchor=(1.0,0.96), frameon=False)\n",
    "plt.text(-0.5,-0.23,'Radiation\\nResponse', fontsize=18, horizontalalignment='right')\n",
    "for i in range(len(drugs)):\n",
    "    plt.text(i,1.01,drugs[i], fontsize=16, horizontalalignment='center')\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1],['0%','20%','40%','60%','80%','100%'])\n",
    "plt.ylabel('Percentage of Patients', fontsize=20)\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/drug.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of genes\n",
    "genes_ = ['IDH1','BRAF','EGFR']\n",
    "\n",
    "# initialize mutations\n",
    "mutations = [{} for gene in genes_]\n",
    "mutations_cohort = [{} for gene in genes_]\n",
    "mutations_count = [[0,0] for gene in genes_]\n",
    "\n",
    "# iterate over cancer types\n",
    "for fn in glob.glob('_datasets/mutation/_data_/input/*.maf'):\n",
    "    cohort = fn.split('\\\\')[-1].split('.maf')[0]\n",
    "    \n",
    "    # load file\n",
    "    df_maf = pd.read_table(fn,skiprows=[0,1,2,3,4],header=0)\n",
    "    \n",
    "    # iterate over samples\n",
    "    available_samples = [x[:16] for x in df_maf['Tumor_Sample_Barcode'].values.tolist()]\n",
    "    for sample in [x for x in samples if x in available_samples]:\n",
    "        \n",
    "        # subset data\n",
    "        get_rows = [i for i,x in enumerate(df_maf['Tumor_Sample_Barcode'].values.tolist()) if x[:16]==sample and df_maf.at[i,'Variant_Type']=='SNP']\n",
    "        df_subset = df_maf.loc[get_rows]\n",
    "        \n",
    "        # iterate over genes\n",
    "        for gene in genes_:\n",
    "            if gene in df_subset['Hugo_Symbol'].values.tolist():\n",
    "                df_subset_ = df_subset[df_subset['Hugo_Symbol']==gene].reset_index(drop=True)\n",
    "                for i in range(df_subset_.shape[0]):\n",
    "                    \n",
    "                    # add to count\n",
    "                    if y_vector[samples.index(sample)]==0:\n",
    "                        mutations_count[genes_.index(gene)][0] += 1\n",
    "                    else:\n",
    "                        mutations_count[genes_.index(gene)][1] += 1\n",
    "                        \n",
    "                    # collect missense and nonsense mutations\n",
    "                    if df_subset_.at[i,'Variant_Classification'] in ['Missense_Mutation','Nonsense_Mutation']:\n",
    "                        if df_subset_.at[i,'HGVSp_Short'].split('p.')[-1] not in mutations[genes_.index(gene)]:\n",
    "                            mutations[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]] = [0,0]\n",
    "                            mutations_cohort[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]] = {}\n",
    "                        if y_vector[samples.index(sample)]==0:\n",
    "                            mutations[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]][0] += 1\n",
    "                        else:\n",
    "                            mutations[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]][1] += 1\n",
    "                        if cohort not in mutations_cohort[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]]:\n",
    "                            mutations_cohort[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]][cohort] = 0\n",
    "                        mutations_cohort[genes_.index(gene)][df_subset_.at[i,'HGVSp_Short'].split('p.')[-1]][cohort] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "ax = fig.add_subplot(111)\n",
    "barWidth = 0.3\n",
    "r1 = np.arange(4)\n",
    "r2 = [x + barWidth for x in r1]\n",
    "plt.bar(r1, [mutations_count[0][0], mutations[0]['R132H'][0], mutations_count[1][0], mutations[1]['V600E'][0]], color='#5bc2ae', width=barWidth, edgecolor='white', label='Sensitive')\n",
    "plt.bar(r2, [mutations_count[0][1], mutations[0]['R132H'][1], mutations_count[1][1], mutations[1]['V600E'][1]], color='#d93f20', width=barWidth, edgecolor='white', label='Resistant')\n",
    "plt.xticks([0.15, 1.15, 2.15, 3.15],['All SNP','R132H','All SNP','V600E'])\n",
    "plt.ylabel('Number of Patients', fontsize=20)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.legend(fontsize=18, bbox_to_anchor=(0.95,1), frameon=False)\n",
    "trans = ax.get_xaxis_transform()\n",
    "plt.plot([-0.3,1.55],[-0.14,-0.14], color='k', transform=trans, clip_on=False)\n",
    "plt.text(0.65,-28,'IDH1',fontsize=22,horizontalalignment='center')\n",
    "plt.plot([1.7,3.55],[-0.14,-0.14], color='k', transform=trans, clip_on=False)\n",
    "plt.text(2.65,-28,'BRAF',fontsize=22,horizontalalignment='center')\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/mutation.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Recon3D metabolite list\n",
    "df_metabolites = pd.read_csv('../FBA-beta/data/recon/metabolites.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# list of kegg metabolites\n",
    "top_mets = []\n",
    "top_kegg = []\n",
    "for feature in overall_top_features:\n",
    "    if feature.split(' # ')[0] == 'objscreen_kegg':\n",
    "        top_mets.append(feature.split(' # ')[1])\n",
    "        available_compartments = [x[-2] for x in df_metabolites.index.tolist() if x[:-3]==feature.split(' # ')[1]]\n",
    "        top_kegg.append(df_metabolites.at['%s[%s]' % (feature.split(' # ')[1], available_compartments[0]), 'KEGG'])\n",
    "top_mets = sorted(list(set(top_mets)))\n",
    "top_kegg = sorted(list(set(top_kegg)))\n",
    "\n",
    "# output lists\n",
    "with open('%s/%s/%s/shap_values/summary/top_mets.txt' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    for met in top_mets:\n",
    "        f.write('%s\\n' % met)\n",
    "with open('%s/%s/%s/shap_values/summary/top_kegg.txt' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    for met in top_kegg:\n",
    "        f.write('%s\\n' % met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene resulting in increased or decreased probability with increased expression\n",
    "increase = []\n",
    "increase_r = []\n",
    "decrease = []\n",
    "decrease_r = []\n",
    "for feature in overall_top_features:\n",
    "    if feature.split(' # ')[0] == 'objscreen_kegg':\n",
    "    \n",
    "        # expression and shap values\n",
    "        expression = X_matrix[feature].values.tolist()\n",
    "        shapvalue = shap_value[feature].values.tolist()\n",
    "\n",
    "        # correlation coefficient\n",
    "        r = spearmanr(expression, shapvalue).correlation\n",
    "        if r > 0:\n",
    "            increase.append(feature.split(' # ')[1])\n",
    "            increase_r.append(r)\n",
    "        else:\n",
    "            decrease.append(feature.split(' # ')[1])\n",
    "            decrease_r.append(r)\n",
    "            \n",
    "# output lists\n",
    "with open('%s/%s/%s/shap_values/summary/top_mets_increase.txt' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    for met in increase:\n",
    "        f.write('%s\\n' % met)\n",
    "with open('%s/%s/%s/shap_values/summary/top_mets_increase.csv' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    f.write('MET,R\\n')\n",
    "    for i in range(len(increase)):\n",
    "        f.write('%s,%f\\n' % (increase[i],increase_r[i]))\n",
    "with open('%s/%s/%s/shap_values/summary/top_mets_decrease.txt' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    for met in decrease:\n",
    "        f.write('%s\\n' % met)\n",
    "with open('%s/%s/%s/shap_values/summary/top_mets_decrease.csv' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    f.write('MET,R\\n')\n",
    "    for i in range(len(decrease)):\n",
    "        f.write('%s,%f\\n' % (decrease[i],decrease_r[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_met_score = overall_top_values[overall_top_features.index('objscreen_kegg # but')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s/%s/shap_values/summary/top_mets.tsv' % (folder_name, dataset_name, output_folder), 'w') as f:\n",
    "    f.write('KEGG ID\\tVMH ID\\tMETABOLITE NAME\\tFORMULA\\tRELATIVE IMPORTANCE\\n')\n",
    "    for i,feature in enumerate(overall_top_features):\n",
    "        if feature.split(' # ')[0] == 'objscreen_kegg':\n",
    "            met = feature.split(' # ')[1]\n",
    "            available_compartments = [x[-2] for x in df_metabolites.index.tolist() if x[:-3]==met]\n",
    "            met_ = '%s[%s]' % (met, available_compartments[0])\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\t%f\\n' % (df_metabolites.at[met_,'KEGG'], met, df_metabolites.at[met_,'NAME'], df_metabolites.at[met_,'FORMULA'], overall_top_values[i]/top_met_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over cancer types\n",
    "for cohort in sorted(list(set(X_matrix['clinical # COHORT'].values.tolist()))):\n",
    "\n",
    "    # find histologic subtypes\n",
    "    histologies = []\n",
    "    values = []\n",
    "\n",
    "    # iterate over samples\n",
    "    for i,sample in enumerate(samples):\n",
    "\n",
    "        # record histology\n",
    "        if type(X_matrix.at[sample,'clinical # HISTOLOGIC'])==str:\n",
    "            if X_matrix.at[sample,'clinical # HISTOLOGIC'].split(' > ')[0]==cohort:\n",
    "                if X_matrix.at[sample,'clinical # HISTOLOGIC'].split(' > ')[1] not in histologies:\n",
    "                    histologies.append(X_matrix.at[sample,'clinical # HISTOLOGIC'].split(' > ')[1])\n",
    "                    values.append([y_vector[i]])\n",
    "                else:\n",
    "                    values[histologies.index(X_matrix.at[sample,'clinical # HISTOLOGIC'].split(' > ')[1])].append(y_vector[i])\n",
    "\n",
    "    # if multiple histologies\n",
    "    if len(histologies) >= 2:\n",
    "        print('----------')\n",
    "        print(cohort)\n",
    "        for i in range(len(histologies)):\n",
    "            print('%d/%d (%0.1f%%) Resistant - %s' % (len([x for x in values[i] if x==1]), len(values[i]), len([x for x in values[i] if x==1])/len(values[i])*100, histologies[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    if X_matrix.at[sample,'clinical # HISTOLOGIC'] == 'BRCA > Mucinous Carcinoma':\n",
    "        print(sample[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    # plot - individual patient dataset contribution\n",
    "    dataset_contribution_individual = [[] for dataset in individual_datasets]\n",
    "    dataset_contribution_individual_top = [[] for dataset in individual_datasets]\n",
    "    for j,sample in enumerate(samples):\n",
    "        sample_values = shap_value_abs.loc[sample].values.tolist()\n",
    "        for i,dataset in enumerate(individual_datasets):\n",
    "            dataset_contribution_individual[i].append(np.sum([sample_values[a] for a in range(len(merged_features)) if merged_features[a].split(' # ')[0]==dataset])/np.sum(sample_values))\n",
    "        if np.sum([sample_values[a] for a in range(len(merged_features)) if merged_features[a].split(' # ')[0]==dataset])/np.sum(sample_values) > (1/len(individual_datasets)):\n",
    "            dataset_contribution_individual_top[i].append(sample)\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(3*len(individual_datasets),10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.rc('xtick', labelsize=20)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = sns.boxplot(data=dataset_contribution_individual, whis=1, fliersize=0, palette=colors)\n",
    "    fig = sns.swarmplot(data=dataset_contribution_individual, color='black', alpha=0.25)\n",
    "    plt.xlim([-0.5,len(individual_datasets)-0.5])\n",
    "    fig.set(xticklabels=individual_datasets_labels)\n",
    "    fig.spines['right'].set_visible(False)\n",
    "    fig.spines['top'].set_visible(False)\n",
    "    plt.ylabel('Percent Contribution', fontsize=20)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_individual.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # top N features - mean - low/med/high clinical\n",
    "    for a in range(len(distribution_names)):\n",
    "        \n",
    "        # get values\n",
    "        shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "        shap_value_abs_distribution_mean = shap_value_abs_distribution.mean(axis=0).values.tolist()\n",
    "        shap_value_abs_distribution_std = shap_value_abs_distribution.std(axis=0).values.tolist()\n",
    "        shap_value_abs_distribution_sterr = [x/np.sqrt(len([y for y in distribution_labels if y==a])) for x in shap_value_abs_distribution_std]\n",
    "        \n",
    "        # plot\n",
    "        top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:N]\n",
    "        top_N_mean = [shap_value_abs_distribution_mean[i] for i in top_N_index]\n",
    "        top_N_sterr = [shap_value_abs_distribution_sterr[i] for i in top_N_index]\n",
    "        top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "        top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "        colors_ = []\n",
    "        for dataset in top_N_datasets:\n",
    "            colors_.append(colors[individual_datasets.index(dataset)])\n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "        plt.rc('xtick', labelsize=12)\n",
    "        plt.rc('ytick', labelsize=20)\n",
    "        fig = plt.figure(figsize=(20,5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5)\n",
    "        for i in range(len(barlist)):\n",
    "            barlist[i].set_color(colors_[i])\n",
    "        plt.xticks(range(N), top_N_features, rotation=90)\n",
    "        plt.xlim(-1,N)\n",
    "        plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "        plt.title('Top %d Features' % N, fontsize=24)\n",
    "        vals = ax.get_yticks()\n",
    "        decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "        if len([x for x in decimals if x != '0']) > 0:\n",
    "            number_of_places = np.max([len(x) for x in decimals])\n",
    "        else:\n",
    "            number_of_places = np.max([len(x) for x in decimals])-1\n",
    "        if number_of_places == 0:\n",
    "            ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "        elif number_of_places == 1:\n",
    "            ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "        elif number_of_places == 2:\n",
    "            ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "        else:\n",
    "            raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "        plt.legend([barlist[colors_.index(x)] for x in colors], individual_datasets_labels, fontsize=16)\n",
    "        plt.savefig('%s/%s/%s/shap_values/summary/top%d_clinical_%s.png' % (folder_name, dataset_name, output_folder, N, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrez gene lists for gene ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "\n",
    "    # gene lists for gene ontology - significant genes\n",
    "    N = len([x for x in shap_value_abs_mean_cumsum if x<=0.95])\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1][:N]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    overall_top_features = top_N_features.copy()\n",
    "    found_entrez = []\n",
    "    stepsize = 400\n",
    "    for i in range(int(np.ceil(len(top_N_features)/stepsize))):\n",
    "        time.sleep(1)\n",
    "        if i < len(top_N_features)/stepsize:\n",
    "            gene_list = ','.join(top_N_features[(stepsize*i):(stepsize*(i+1))])\n",
    "        else:\n",
    "            gene_list = ','.join(top_N_features[(stepsize*i):])\n",
    "        link = 'https://biodbnet-abcc.ncifcrf.gov/webServices/rest.php/biodbnetRestApi.json?method=db2db&input=genesymbolandsynonyms&inputValues=%s&outputs=geneid&taxonId=9606&format=row' % gene_list\n",
    "        data = json.loads(urllib.request.urlopen(link).read())  \n",
    "        for j in range(len(data)):\n",
    "            if (data[j]['Gene ID'] != '-') and ('//' not in data[j]['Gene ID']):\n",
    "                found_entrez.append(str(data[j]['Gene ID']))\n",
    "    with open('%s/%s/%s/shap_values/summary/sig_genes.txt' % (folder_name, dataset_name, output_folder),'w') as f:\n",
    "        for gene in sorted(list(set(found_entrez))):\n",
    "            f.write('%s\\n' % gene)\n",
    "            \n",
    "    # gene lists for gene ontology - reference genes\n",
    "    N = len(merged_features)\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1][:N]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    found_entrez = []\n",
    "    stepsize = 400\n",
    "    for i in range(int(np.ceil(len(top_N_features)/stepsize))):\n",
    "        time.sleep(1)\n",
    "        if i < len(top_N_features)/stepsize:\n",
    "            gene_list = ','.join(top_N_features[(stepsize*i):(stepsize*(i+1))])\n",
    "        else:\n",
    "            gene_list = ','.join(top_N_features[(stepsize*i):])\n",
    "        link = 'https://biodbnet-abcc.ncifcrf.gov/webServices/rest.php/biodbnetRestApi.json?method=db2db&input=genesymbolandsynonyms&inputValues=%s&outputs=geneid&taxonId=9606&format=row' % gene_list\n",
    "        data = json.loads(urllib.request.urlopen(link).read())  \n",
    "        for j in range(len(data)):\n",
    "            if (data[j]['Gene ID'] != '-') and ('//' not in data[j]['Gene ID']):\n",
    "                found_entrez.append(str(data[j]['Gene ID']))\n",
    "    with open('%s/%s/%s/shap_values/summary/ref_genes.txt' % (folder_name, dataset_name, output_folder),'w') as f:\n",
    "        for gene in sorted(list(set(found_entrez))):\n",
    "            f.write('%s\\n' % gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "    \n",
    "    # load cohort for each sample\n",
    "    with open('_datasets/clinical.pickle', 'rb') as f:\n",
    "        X_matrix_, y_vector_, categorical_conversion_ = pickle.load(f, encoding='latin1')\n",
    "    cohorts = []\n",
    "    for sample in X_matrix_.index.tolist():\n",
    "        for cohort in categorical_conversion_['COHORT']:\n",
    "            if X_matrix_.at[sample,'COHORT | %s' % cohort] == 1:\n",
    "                cohorts.append(cohort)\n",
    "\n",
    "    # iterate over datasets\n",
    "    for cohort in ['ACC', 'BLCA', 'BRCA', 'CESC', 'COAD', 'DLBC', 'GBM', 'HNSC', 'LGG', 'LIHC', 'LUAD', 'LUSC', 'PRAD', 'READ', 'SKCM', 'STAD', 'THCA', 'UCEC', 'UCS']:\n",
    "        \n",
    "        # subset patients within cohort\n",
    "        samples_ = [samples[i] for i in range(len(samples)) if cohorts[i]==cohort]\n",
    "        shap_value_abs_ = shap_value_abs.loc[samples_]\n",
    "        \n",
    "        # mean and standard error for each feature\n",
    "        shap_value_abs_mean = shap_value_abs_.mean(axis=0).values.tolist()\n",
    "        shap_value_abs_mean_cumsum = np.cumsum(sorted(shap_value_abs_mean)[::-1])\n",
    "        shap_value_abs_std = shap_value_abs_.std(axis=0).values.tolist()\n",
    "        shap_value_abs_sterr = [x/np.sqrt(len(samples)) for x in shap_value_abs_std]\n",
    "        \n",
    "        # top N features - mean\n",
    "        N = len([x for x in shap_value_abs_mean_cumsum if x<=0.95])\n",
    "        top_N_index = np.argsort(shap_value_abs_mean)[::-1][:N]\n",
    "        top_N_mean = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "        top_N_sterr = [shap_value_abs_sterr[i] for i in top_N_index]\n",
    "        top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "        top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "        \n",
    "        # gene lists for gene ontology - significant genes\n",
    "        found_entrez = []\n",
    "        stepsize = 400\n",
    "        for i in range(int(np.ceil(len(top_N_features)/stepsize))):\n",
    "            time.sleep(1)\n",
    "            if i < len(top_N_features)/stepsize:\n",
    "                gene_list = ','.join(top_N_features[(stepsize*i):(stepsize*(i+1))])\n",
    "            else:\n",
    "                gene_list = ','.join(top_N_features[(stepsize*i):])\n",
    "            link = 'https://biodbnet-abcc.ncifcrf.gov/webServices/rest.php/biodbnetRestApi.json?method=db2db&input=genesymbolandsynonyms&inputValues=%s&outputs=geneid&taxonId=9606&format=row' % gene_list\n",
    "            data = json.loads(urllib.request.urlopen(link).read())  \n",
    "            for j in range(len(data)):\n",
    "                if (data[j]['Gene ID'] != '-') and ('//' not in data[j]['Gene ID']):\n",
    "                    found_entrez.append(str(data[j]['Gene ID']))\n",
    "        with open('%s/%s/%s/shap_values/summary/cohort/%s_sig_genes.txt' % (folder_name, dataset_name, output_folder, cohort),'w') as f:\n",
    "            for gene in sorted(list(set(found_entrez))):\n",
    "                f.write('%s\\n' % gene) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "\n",
    "    # iterate over patients\n",
    "    for sample in samples:\n",
    "        \n",
    "        # get features with non-negative shap_values\n",
    "        sig_features = [feature for feature in merged_features if shap_value_abs.at[sample,feature]>0]\n",
    "        sig_values = [shap_value_abs.at[sample,x] for x in sig_features]\n",
    "        sort_index = np.argsort(sig_values)[::-1]\n",
    "        sig_features = [sig_features[i] for i in sort_index]\n",
    "        sig_values = [sig_values[i] for i in sort_index]\n",
    "        sig_values_cumsum = np.cumsum(sig_values)\n",
    "        sig_values_cumsum /= np.max(sig_values_cumsum)\n",
    "        \n",
    "        # top N features - mean\n",
    "        N = len([x for x in sig_values_cumsum if x<=0.95])\n",
    "        top_N_features = [x.split(' # ')[-1] for x in sig_features[:N]]\n",
    "        \n",
    "        # gene lists for gene ontology - significant genes\n",
    "        found_entrez = []\n",
    "        stepsize = 400\n",
    "        for i in range(int(np.ceil(len(top_N_features)/stepsize))):\n",
    "            time.sleep(1)\n",
    "            if i < len(top_N_features)/stepsize:\n",
    "                gene_list = ','.join(top_N_features[(stepsize*i):(stepsize*(i+1))])\n",
    "            else:\n",
    "                gene_list = ','.join(top_N_features[(stepsize*i):])\n",
    "            link = 'https://biodbnet-abcc.ncifcrf.gov/webServices/rest.php/biodbnetRestApi.json?method=db2db&input=genesymbolandsynonyms&inputValues=%s&outputs=geneid&taxonId=9606&format=row' % gene_list\n",
    "            data = json.loads(urllib.request.urlopen(link).read())  \n",
    "            for j in range(len(data)):\n",
    "                if (data[j]['Gene ID'] != '-') and ('//' not in data[j]['Gene ID']):\n",
    "                    found_entrez.append(str(data[j]['Gene ID']))\n",
    "        with open('%s/%s/%s/shap_values/summary/patient/%s_sig_genes.txt' % (folder_name, dataset_name, output_folder, sample),'w') as f:\n",
    "            for gene in sorted(list(set(found_entrez))):\n",
    "                f.write('%s\\n' % gene) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patient shap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function\n",
    "def plot_patient_example(patient_name, actual_value, expected_value, features_, shap_, original_):\n",
    "    \n",
    "    # initialize figure\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(20,.15*len(features_)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # patient name\n",
    "    if actual_value == 0:\n",
    "        plt.text(0.5,0.8,patient_name, horizontalalignment='center', verticalalignment='center', color='#5bc2ae', fontsize=18, weight='bold')\n",
    "    else:\n",
    "        plt.text(0.5,1,patient_name, horizontalalignment='center', verticalalignment='center', color='#d93f20', fontsize=18, weight='bold')\n",
    "    \n",
    "    # number line\n",
    "    plt.plot([0.18,0.23],[0,0],'k-',linewidth=1)\n",
    "    plt.plot([0.25,1],[0,0],'k-',linewidth=1)\n",
    "    plt.plot([0.22,0.24],[-0.3,0.3],'k-',linewidth=1)\n",
    "    plt.plot([0.24,0.26],[-0.3,0.3],'k-',linewidth=1)\n",
    "    for x in [0.18,0.5,1]:\n",
    "        plt.plot([x,x],[-0.1,0.1],'k-',linewidth=1)\n",
    "    plt.plot([expected_value,expected_value],[-0.3,0.1],'k--',linewidth=1)\n",
    "    plt.text(0.18,0.1,'0%', horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=16)\n",
    "    plt.text(0.5,0.1,'50%', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "    plt.text(1,0.1,'100%', horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=16)\n",
    "    plt.text(expected_value,0.1,'%0.1f%%' % (expected_value*100), horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "    plt.text(expected_value,0.75,'Prior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "    \n",
    "    # data\n",
    "    current_value = expected_value\n",
    "    y_value = -0.3\n",
    "    for i in range(len(features_)):\n",
    "        if not pd.isna(original_[i]):\n",
    "            if shap_[i] < 0:\n",
    "                plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color='#5bc2ae')\n",
    "                if type(original_[i]) == str:\n",
    "                    plt.text(current_value+0.005, y_value, '%s = %s' % (features_[i], original_[i]), horizontalalignment='left', verticalalignment='center', fontsize=10)\n",
    "                else:\n",
    "                    plt.text(current_value+0.005, y_value, '%s (Imputed)' % features_[i], horizontalalignment='left', verticalalignment='center', fontsize=10)\n",
    "            else:\n",
    "                plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color='#d93f20')\n",
    "                if type(original_[i]) == str:\n",
    "                    plt.text(current_value-0.005, y_value, '%s = %s' % (features_[i], original_[i]), horizontalalignment='right', verticalalignment='center', fontsize=10)\n",
    "                else:\n",
    "                    plt.text(current_value-0.005, y_value, '%s (Imputed)' % features_[i], horizontalalignment='right', verticalalignment='center', fontsize=10)\n",
    "            current_value += shap_[i]\n",
    "            y_value += -0.3\n",
    "        \n",
    "    # end line\n",
    "    plt.plot([current_value,current_value],[y_value+0.15,0.1],'k--',linewidth=1)\n",
    "    if current_value < 0.5:\n",
    "        plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=16, weight='bold')\n",
    "    else:\n",
    "        plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=16, weight='bold')\n",
    "    plt.text(current_value,0.75,'Posterior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "        \n",
    "    # limits\n",
    "    plt.xlim(-0.02,1.02)\n",
    "    plt.ylim(y_value-0.05, 0.8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: TCGA-DU-8165-01A\n",
    "for a,sample in enumerate(samples):\n",
    "    if sample=='TCGA-DU-8165-01A':\n",
    "    \n",
    "        # get nonzero shap and feature values\n",
    "        features_ = [feature.split(' # ')[-1] for feature in merged_features if shap_value.at[sample,feature] != 0]\n",
    "        shap_ = shap_value.loc[sample][['gene_all # %s' % x for x in features_]].tolist()\n",
    "        original_ = X_matrix.loc[sample][['gene_all # %s' % x for x in features_]].tolist()\n",
    "\n",
    "        # convert numerical values to strings\n",
    "        for j in range(len(original_)):\n",
    "            if not type(original_[j]) == str:\n",
    "                if type(original_[j]) == bool:\n",
    "                    original_[j] = str(original_[j])\n",
    "                elif not np.isnan(original_[j]):\n",
    "                    if original_[j] == int(original_[j]):\n",
    "                        original_[j] = str(int(original_[j]))\n",
    "                    else:\n",
    "                        original_[j] = str(np.round(original_[j],2))+' TPM'\n",
    "\n",
    "        # order features based on absolute shap value\n",
    "        sort_index = np.argsort(np.abs(shap_))[::-1]\n",
    "        features_ = [features_[i] for i in sort_index]\n",
    "        shap_ = [shap_[i] for i in sort_index]\n",
    "        original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "        # create figure\n",
    "        plot_patient_example(sample, y_vector[a], expected_value[a], features_, shap_, original_)\n",
    "        plt.savefig('%s/%s/%s/shap_values/patient_example.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function\n",
    "def plot_patient(patient_name, actual_value, expected_value, features_, shap_, original_):\n",
    "    \n",
    "    # initialize figure\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(20,.15*len(features_)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # patient name\n",
    "    if actual_value == 0:\n",
    "        plt.text(0.5,0.8,patient_name, horizontalalignment='center', verticalalignment='center', color='#5bc2ae', fontsize=18, weight='bold')\n",
    "    else:\n",
    "        plt.text(0.5,1,patient_name, horizontalalignment='center', verticalalignment='center', color='#d93f20', fontsize=18, weight='bold')\n",
    "    \n",
    "    # number line\n",
    "    plt.plot([0,1],[0,0],'k-',linewidth=1)\n",
    "    for x in [0,0.5,1]:\n",
    "        plt.plot([x,x],[-0.1,0.1],'k-',linewidth=1)\n",
    "    plt.plot([expected_value,expected_value],[-0.3,0.1],'k--',linewidth=1)\n",
    "    plt.text(0,0.1,'0%', horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=16)\n",
    "    plt.text(0.5,0.1,'50%', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "    plt.text(1,0.1,'100%', horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=16)\n",
    "    plt.text(expected_value,0.1,'%0.1f%%' % (expected_value*100), horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "    plt.text(expected_value,0.75,'Prior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "    \n",
    "    # data\n",
    "    current_value = expected_value\n",
    "    y_value = -0.3\n",
    "    for i in range(len(features_)):\n",
    "        if not pd.isna(original_[i]):\n",
    "            if shap_[i] < 0:\n",
    "                plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color='#5bc2ae')\n",
    "                if type(original_[i]) == str:\n",
    "                    plt.text(current_value+0.005, y_value, '%s = %s' % (features_[i], original_[i]), horizontalalignment='left', verticalalignment='center', fontsize=10)\n",
    "                else:\n",
    "                    plt.text(current_value+0.005, y_value, '%s (Imputed)' % features_[i], horizontalalignment='left', verticalalignment='center', fontsize=10)\n",
    "            else:\n",
    "                plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color='#d93f20')\n",
    "                if type(original_[i]) == str:\n",
    "                    plt.text(current_value-0.005, y_value, '%s = %s' % (features_[i], original_[i]), horizontalalignment='right', verticalalignment='center', fontsize=10)\n",
    "                else:\n",
    "                    plt.text(current_value-0.005, y_value, '%s (Imputed)' % features_[i], horizontalalignment='right', verticalalignment='center', fontsize=10)\n",
    "            current_value += shap_[i]\n",
    "            y_value += -0.3\n",
    "        \n",
    "    # end line\n",
    "    plt.plot([current_value,current_value],[y_value+0.15,0.1],'k--',linewidth=1)\n",
    "    if current_value < 0.5:\n",
    "        plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=16, weight='bold')\n",
    "    else:\n",
    "        plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=16, weight='bold')\n",
    "    plt.text(current_value,0.75,'Posterior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=16)\n",
    "        \n",
    "    # limits\n",
    "    plt.xlim(-0.02,1.02)\n",
    "    plt.ylim(y_value-0.05, 0.8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over patients\n",
    "for a,sample in enumerate(samples):\n",
    "    if y_vector[a]==1:\n",
    "    \n",
    "        # get nonzero shap and feature values\n",
    "        features_ = [feature.split(' # ')[-1] for feature in merged_features if shap_value.at[sample,feature] != 0]\n",
    "        shap_ = shap_value.loc[sample][['gene_all # %s' % x for x in features_]].tolist()\n",
    "        original_ = X_matrix.loc[sample][['gene_all # %s' % x for x in features_]].tolist()\n",
    "\n",
    "        # convert numerical values to strings\n",
    "        for j in range(len(original_)):\n",
    "            if not type(original_[j]) == str:\n",
    "                if type(original_[j]) == bool:\n",
    "                    original_[j] = str(original_[j])\n",
    "                elif not np.isnan(original_[j]):\n",
    "                    if original_[j] == int(original_[j]):\n",
    "                        original_[j] = str(int(original_[j]))\n",
    "                    else:\n",
    "                        original_[j] = str(original_[j])             \n",
    "\n",
    "        # order features based on absolute shap value\n",
    "        sort_index = np.argsort(np.abs(shap_))[::-1]\n",
    "        features_ = [features_[i] for i in sort_index]\n",
    "        shap_ = [shap_[i] for i in sort_index]\n",
    "        original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "        # create figure\n",
    "        plot_patient(sample, y_vector[a], expected_value[a], features_, shap_, original_)\n",
    "        plt.savefig('%s/%s/%s/shap_values/patients/%s.png' % (folder_name, dataset_name, output_folder, sample), bbox_inches='tight', dpi=400)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_stacker:\n",
    "    \n",
    "    # load stacker data from each split\n",
    "    stacker_samples = []\n",
    "    stacker_weights_ = []\n",
    "    stacker_performance = []\n",
    "    for i in range(n_splits):\n",
    "        with open('%s/%s/stacker_%d.pickle' % (folder_name, dataset_name, i+1) ,'rb') as f:\n",
    "            #X_test, X_test_all, y_test, test_predictions, testing_pred, weights = pickle.load(f)\n",
    "            X_test, X_test_all, y_test, y_pred, test_predictions, weights, test_best_classifier, bst = pickle.load(f)\n",
    "            \n",
    "        for j,sample in enumerate(X_test[0].index.tolist()):\n",
    "            if sample in stacker_samples:\n",
    "                for k,dataset in enumerate(individual_datasets):\n",
    "                    stacker_weights_[stacker_samples.index(sample)][k].append(weights[j,k])\n",
    "                stacker_performance[stacker_samples.index(sample)].append(stacker_performance_weights[i])\n",
    "            else:\n",
    "                stacker_samples.append(sample)\n",
    "                stacker_weights_.append([])\n",
    "                for k,dataset in enumerate(individual_datasets):\n",
    "                    stacker_weights_[-1].append([weights[j,k]])\n",
    "                stacker_performance.append([stacker_performance_weights[i]])\n",
    "                \n",
    "    # weighted average of stacker predictions\n",
    "    stacker_weights = []\n",
    "    for i in range(len(stacker_samples)):\n",
    "        stacker_weights.append([])\n",
    "        for j in range(len(individual_datasets)):\n",
    "            stacker_weights[-1].append(np.average(stacker_weights_[i][j], weights=stacker_performance[i]))\n",
    "    \n",
    "    # sort based on shap values\n",
    "    stacker_weights_ = []\n",
    "    for sample in samples:\n",
    "        stacker_weights_.append(stacker_weights[stacker_samples.index(sample)])\n",
    "    stacker_weights = stacker_weights_.copy()\n",
    "            \n",
    "    # dataframe\n",
    "    df = pd.DataFrame(columns=['Dataset','Value','Color'])\n",
    "    for i in range(len(individual_datasets)):\n",
    "        for j in range(len(samples)):\n",
    "            if distribution_labels[j]==0:\n",
    "                df.loc[df.shape[0]] = [i,stacker_weights[j][i],'red']\n",
    "            else:\n",
    "                df.loc[df.shape[0]] = [i,stacker_weights[j][i],'black']\n",
    "    stacker_weights_grouped = []\n",
    "    for i in range(len(individual_datasets)):\n",
    "        stacker_weights_grouped.append([x[i] for x in stacker_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal threshold\n",
    "values = stacker_weights_grouped[0]\n",
    "ids = [1 if distribution_labels[i]==0 else 0 for i in range(len(distribution_labels))]\n",
    "sort_index = np.argsort(values)\n",
    "values = [values[i] for i in sort_index]\n",
    "ids = [ids[i] for i in sort_index]\n",
    "thresh = []\n",
    "acc = []\n",
    "for i in range(1,len(ids)):\n",
    "    thresh.append(np.mean([values[i-1],values[i]]))\n",
    "    tp = len([i for i in range(len(ids)) if values[i]<thresh[-1] and ids[i]==1])\n",
    "    tn = len([i for i in range(len(ids)) if values[i]>thresh[-1] and ids[i]==0])\n",
    "    fp = len([i for i in range(len(ids)) if values[i]<thresh[-1] and ids[i]==0])\n",
    "    fn = len([i for i in range(len(ids)) if values[i]>thresh[-1] and ids[i]==1])\n",
    "    acc.append((tp+tn)/(tp+tn+fp+fn))\n",
    "max_acc = np.max(acc)\n",
    "max_thresh = thresh[np.argmax(acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of stacker weights\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=24)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(3*len(individual_datasets),10))\n",
    "ax = fig.add_subplot(111)\n",
    "fig = sns.boxplot(data=stacker_weights_grouped, whis=1, fliersize=0, palette=colors)\n",
    "fig = sns.swarmplot(data=df, x='Dataset', y='Value', hue='Color', palette=['black','red'], alpha=0.25)\n",
    "plt.plot([-1,4],[max_thresh,max_thresh],'k--')\n",
    "plt.text(0.5,max_thresh+0.015,'Optimal Threshold', fontsize=20)\n",
    "plt.text(0.5,max_thresh-0.04,'Accuracy: %0.1f%%' % (max_acc*100), fontsize=20)\n",
    "plt.xlim([-0.5,len(individual_datasets)-0.5])\n",
    "fig.set(xticklabels=individual_datasets_labels)\n",
    "fig.spines['right'].set_visible(False)\n",
    "fig.spines['top'].set_visible(False)\n",
    "plt.ylabel('Meta Learner Weight', fontsize=24)\n",
    "plt.ylim([0,1])\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1,max_thresh],['0%','20%','40%','60%','80%','100%','%0.1f%%' % (max_thresh*100)])\n",
    "plt.savefig('%s/%s/%s/stacker/summary/weights.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical factors differentiating stacker groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get factors\n",
    "X_stacker = X_matrix.loc[samples]\n",
    "numerical_factors = ['clinical # %s' % x for x in ['AGE','PACK YEARS','ALCOHOL DAYS PER WEEK','ALCOHOL PER DAY','KARNOFSKY']]\n",
    "categorical_factors = [x for x in X_stacker.columns.tolist() if x.split(' # ')[0]=='clinical' and x not in numerical_factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical factors\n",
    "for factor in numerical_factors:\n",
    "    \n",
    "    # get values\n",
    "    values = X_stacker[factor].values.tolist()\n",
    "    stackval = stacker_weights_grouped[0]\n",
    "    keep_index = [i for i,x in enumerate(values) if not pd.isna(x)]\n",
    "    values = [values[i] for i in keep_index]\n",
    "    stackval = [stackval[i] for i in keep_index]\n",
    "    \n",
    "    # correlation coefficient\n",
    "    corr = pearsonr(values, stackval)\n",
    "    #print(factor, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical factors\n",
    "for factor in categorical_factors:\n",
    "    \n",
    "    # get values\n",
    "    values = X_stacker[factor].values.tolist()\n",
    "    stackval = stacker_weights_grouped[0]\n",
    "    keep_index = [i for i,x in enumerate(values) if not pd.isna(x)]\n",
    "    values = [values[i] for i in keep_index]\n",
    "    stackval = [stackval[i] for i in keep_index]\n",
    "    \n",
    "    # ANOVA\n",
    "    classes = [x for x in collections.Counter(values).keys()]\n",
    "    val = []\n",
    "    for k in range(len(classes)):\n",
    "        val.append([x for l,x in enumerate(stackval) if values[l] == classes[k]])\n",
    "    F = f_oneway(*val)\n",
    "    #print(factor, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in categorical_factors[0:1]:\n",
    "    # plot factor\n",
    "    #factor = 'clinical # RESPONSE DRUG Cisplatin'\n",
    "\n",
    "    # values\n",
    "    values = X_stacker[factor].values.tolist()\n",
    "    stackval = stacker_weights_grouped[0]\n",
    "    keep_index = [i for i,x in enumerate(values) if not pd.isna(x)]\n",
    "    values = [values[i] for i in keep_index]\n",
    "    stackval = [stackval[i] for i in keep_index]\n",
    "    classes = sorted([x for x in collections.Counter(values).keys()])\n",
    "    val = []\n",
    "    for k in range(len(classes)):\n",
    "        val.append([x for l,x in enumerate(stackval) if values[l] == classes[k]])\n",
    "    keep_index = [i for i,x in enumerate(val) if len(x)>=3]\n",
    "    classes = [classes[i] for i in keep_index]\n",
    "    val = [val[i] for i in keep_index]\n",
    "    sort_index = np.argsort([np.mean(x) for x in val])\n",
    "    #sort_index = np.argsort(classes)\n",
    "    classes = [classes[i] for i in sort_index]\n",
    "    val = [val[i] for i in sort_index]\n",
    "    if len(classes)>0:\n",
    "        #if len([i for i,x in enumerate(val) if np.mean(x)<max_thresh])>0:\n",
    "        if True:\n",
    "\n",
    "            # plot\n",
    "            plt.rcParams['font.family'] = 'Arial'\n",
    "            fig = plt.figure(figsize=(len(val)/2,5))\n",
    "            ax = fig.add_subplot(111)\n",
    "            plt.rc('xtick', labelsize=18)\n",
    "            plt.rc('ytick', labelsize=20)\n",
    "            fig = sns.boxplot(data=val, whis=1, fliersize=0)\n",
    "            fig = sns.swarmplot(data=val, color='black', alpha=0.25)\n",
    "            plt.plot([-1,len(classes)],[max_thresh,max_thresh],'k--')\n",
    "            #plt.plot([-1,len(classes)],[max_thresh1,max_thresh1],'k--')\n",
    "            #plt.plot([-1,len(classes)],[max_thresh2,max_thresh2],'k--')\n",
    "            plt.xlim([-0.5,len(val)-0.5])\n",
    "            plt.xticks(list(range(len(classes))),classes, rotation=90)\n",
    "            fig.spines['right'].set_visible(False)\n",
    "            fig.spines['top'].set_visible(False)\n",
    "            plt.ylabel('Meta Learner Weight - Clinical', fontsize=20)\n",
    "            vals = ax.get_yticks()\n",
    "            decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "            if len([x for x in decimals if x != '0']) > 0:\n",
    "                number_of_places = np.max([len(x) for x in decimals])\n",
    "            else:\n",
    "                number_of_places = np.max([len(x) for x in decimals])-1\n",
    "            if number_of_places == 0:\n",
    "                ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "            elif number_of_places == 1:\n",
    "                ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "            elif number_of_places == 2:\n",
    "                ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "            else:\n",
    "                raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "            plt.title(factor)\n",
    "            plt.show()\n",
    "            #plt.close()\n",
    "            #plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_individual.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "            #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical factors differentiating clinical groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort\n",
    "factor = 'clinical # COHORT'\n",
    "\n",
    "# factor counts\n",
    "factors = sorted([x for x in collections.Counter(X_matrix[factor].values.tolist()).keys() if len([y for y in X_matrix[factor].values.tolist() if y==x])>=1])\n",
    "counts = np.array([[0.,0.,0.] for x in factors])\n",
    "numbers = [0]*len(factors)\n",
    "for i,sample in enumerate(samples):\n",
    "    if X_matrix.at[sample,factor] in factors:\n",
    "        counts[factors.index(X_matrix.at[sample,factor])][distribution_labels[i]] += 1\n",
    "        numbers[factors.index(X_matrix.at[sample,factor])] += 1\n",
    "    \n",
    "# normalize factor counts\n",
    "for i in range(len(counts)):\n",
    "    counts[i] = counts[i]/np.sum(counts[i])\n",
    "    \n",
    "# heat map\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "fig = plt.figure(figsize=(11,2))\n",
    "ax = sns.heatmap(counts.T, xticklabels=factors, yticklabels=['Low','Medium','High'], cmap=sns.diverging_palette(220, 10, n=1000), center=0.333, cbar=True)\n",
    "#ax = sns.clustermap(counts.T, row_cluster=False, xticklabels=factors, yticklabels=['Low','Medium','High'], cmap=sns.diverging_palette(220, 10, n=1000), center=0.333, cbar=True)\n",
    "cbar = ax.figure.colorbar(ax.collections[0])\n",
    "cbar.set_ticks([0,0.25,0.5,0.75,1])\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.outline.set_visible(False)\n",
    "cbar.set_label(r'Fraction of Patients', fontsize=16, labelpad=-20)\n",
    "plt.yticks(rotation=0,fontsize=16)\n",
    "plt.xticks(rotation=90,fontsize=16)\n",
    "#plt.savefig('fva_subtype.png', bbox_inches='tight', dpi=400)\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort\n",
    "factor = 'clinical # COHORT'\n",
    "\n",
    "# clinical values\n",
    "factors = sorted([x for x in collections.Counter(X_matrix[factor].values.tolist()).keys() if len([y for y in X_matrix[factor].values.tolist() if y==x])>=1])\n",
    "counts = [[] for factor in factors]\n",
    "for i,sample in enumerate(samples):\n",
    "    if X_matrix.at[sample,factor] in factors:\n",
    "        counts[factors.index(X_matrix.at[sample,factor])].append(dataset_contribution_individual[0][i])\n",
    "\n",
    "# sort\n",
    "sort_index = np.argsort([np.median(x) for x in counts])\n",
    "factors = [factors[i] for i in sort_index]\n",
    "counts = [counts[i] for i in sort_index]\n",
    "        \n",
    "# thresholds\n",
    "threshold1 = np.mean([np.max([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==0]),np.min([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==1])])\n",
    "threshold2 = np.mean([np.max([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==1]),np.min([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==2])])\n",
    "\n",
    "# colors\n",
    "colors_ = ['#FFFACD','#F0E68C','#BFBB99']\n",
    "colors = []\n",
    "for i in range(len(counts)):\n",
    "    if np.median(counts[i]) < threshold1:\n",
    "        colors.append(colors_[0])\n",
    "    elif np.median(counts[i]) < threshold2:\n",
    "        colors.append(colors_[1])\n",
    "    else:\n",
    "        colors.append(colors_[2])\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig = plt.figure(figsize=(len(factors)/2,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = sns.boxplot(data=counts, whis=1, fliersize=0, palette=colors)\n",
    "fig = sns.swarmplot(data=counts, color='black', alpha=0.25)\n",
    "plt.plot([-1,len(factors)],[threshold1,threshold1],'k--')\n",
    "plt.plot([-1,len(factors)],[threshold2,threshold2],'k--')\n",
    "plt.text(len(factors)-0.1,threshold1/2,'Low Clinical', fontsize=16, verticalalignment='center')\n",
    "plt.text(len(factors)-0.1,np.mean([threshold1,threshold2]),'Medium Clinical', fontsize=16, verticalalignment='center')\n",
    "plt.text(len(factors)-0.1,np.mean([threshold2,1]),'High Clinical', fontsize=16, verticalalignment='center')\n",
    "plt.xlim([-0.5,len(factors)-0.25])\n",
    "plt.xticks(list(range(len(factors))),factors, rotation=90)\n",
    "fig.spines['right'].set_visible(False)\n",
    "fig.spines['top'].set_visible(False)\n",
    "plt.ylabel('Percent Contribution - Clinical', fontsize=20)\n",
    "plt.ylim([0,1])\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/clinical_cohort.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_name = []\n",
    "factor_f = []\n",
    "factor_p = []\n",
    "\n",
    "for factor in categorical_factors:\n",
    "\n",
    "    # clinical values\n",
    "    factors = sorted([x for x in collections.Counter(X_matrix[factor].values.tolist()).keys() if len([y for y in X_matrix[factor].values.tolist() if y==x])>=1])\n",
    "    counts = [[] for factor in factors]\n",
    "    for i,sample in enumerate(samples):\n",
    "        if X_matrix.at[sample,factor] in factors:\n",
    "            counts[factors.index(X_matrix.at[sample,factor])].append(dataset_contribution_individual[0][i])\n",
    "\n",
    "    # sort\n",
    "    sort_index = np.argsort([np.median(x) for x in counts])\n",
    "    factors = [factors[i] for i in sort_index]\n",
    "    counts = [counts[i] for i in sort_index]\n",
    "\n",
    "    # thresholds\n",
    "    threshold1 = np.mean([np.max([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==0]),np.min([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==1])])\n",
    "    threshold2 = np.mean([np.max([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==1]),np.min([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==2])])\n",
    "    \n",
    "    # number in each group\n",
    "    groups = []\n",
    "    for i in range(len(factors)):\n",
    "        groups.append([0,0,0])\n",
    "        for j in range(len(counts[i])):\n",
    "            if counts[i][j] <= threshold1:\n",
    "                groups[-1][0] += 1\n",
    "            elif counts[i][j] <= threshold2:\n",
    "                groups[-1][1] += 1\n",
    "            else:\n",
    "                groups[-1][2] += 1\n",
    "    \n",
    "    # chi square test\n",
    "    try:\n",
    "        f,p,dof,expected = chi2_contingency(np.array(groups))\n",
    "        factor_name.append(factor)\n",
    "        factor_f.append(f)\n",
    "        factor_p.append(p)\n",
    "    except:\n",
    "        factor_name.append(factor)\n",
    "        factor_f.append(0)\n",
    "        factor_p.append(1)\n",
    "    \n",
    "    # plot\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(len(factors)/2,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.rc('xtick', labelsize=18)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = sns.boxplot(data=counts, whis=1, fliersize=0)\n",
    "    fig = sns.swarmplot(data=counts, color='black', alpha=0.25)\n",
    "    plt.plot([-1,len(factors)],[threshold1,threshold1],'k--')\n",
    "    plt.plot([-1,len(factors)],[threshold2,threshold2],'k--')\n",
    "    plt.text(len(factors)-0.1,threshold1/2,'Low Clinical', fontsize=16, verticalalignment='center')\n",
    "    plt.text(len(factors)-0.1,np.mean([threshold1,threshold2]),'Medium Clinical', fontsize=16, verticalalignment='center')\n",
    "    plt.text(len(factors)-0.1,np.mean([threshold2,1]),'High Clinical', fontsize=16, verticalalignment='center')\n",
    "    plt.xlim([-0.5,len(factors)-0.5])\n",
    "    plt.xticks(list(range(len(factors))),factors, rotation=90)\n",
    "    fig.spines['right'].set_visible(False)\n",
    "    fig.spines['top'].set_visible(False)\n",
    "    plt.ylabel('Percent Contribution - Clinical', fontsize=20)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.title(factor)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    #plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_individual.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort based on p value\n",
    "sort_index = np.argsort(factor_p)\n",
    "sort_index = [x for x in sort_index if factor_p[x]<=0.05]\n",
    "factor_name = [factor_name[i] for i in sort_index]\n",
    "factor_f = [factor_f[i] for i in sort_index]\n",
    "factor_p = [factor_p[i] for i in sort_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_name = ['Cancer Type','Histology','Pathologic T','Pathologic Stage','Clinical T','Temozolomide response','Clinical Stage','Pathologic N','Patient gender','Clinical N','Tumor location','Anastrozole response','Clinical grade','Carboplatin response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(111)\n",
    "barlist = plt.bar(range(len(factor_name)), [-np.log10(x) for x in factor_p])\n",
    "plt.plot([-1,len(factor_name)],[-np.log10(0.05),-np.log10(0.05)],'k--')\n",
    "for i in range(len(barlist)):\n",
    "    barlist[i].set_color('#FFD700')\n",
    "plt.xticks(range(len(factor_name)), factor_name, rotation=90, fontsize=14)\n",
    "plt.xlim(-1,len(factor_name))\n",
    "plt.yticks([1.301,20,40,60],labels=[1.301,20,40,60])\n",
    "plt.ylabel(r'-log$_{10}$(p-value)', fontsize=22)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "#plt.show()\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/clinical_factor.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s/%s/shap_values/summary/clinical_factor.csv' % (folder_name, dataset_name, output_folder),'w') as f:\n",
    "    f.write('FACTOR,F,p\\n')\n",
    "    for i in range(len(factor_name)):\n",
    "        f.write('%s,%f,%.20f\\n' % (factor_name[i].split('clinical # ')[-1], factor_f[i], factor_p[i]))\n",
    "        #print('%s,%f,%.20f' % (factor_name[i].split('clinical # ')[-1], factor_f[i], factor_p[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort\n",
    "factor = 'clinical # HISTOLOGIC'\n",
    "cohort = 'BRCA'\n",
    "\n",
    "# clinical values\n",
    "factors = sorted([x for x in collections.Counter(X_matrix[factor].values.tolist()).keys() if len([y for y in X_matrix[factor].values.tolist() if y==x])>=1])\n",
    "factors = [x for x in factors if x.split(' > ')[0]==cohort]\n",
    "if len(factors)>=2:\n",
    "    counts = [[] for factor in factors]\n",
    "    for i,sample in enumerate(samples):\n",
    "        if X_matrix.at[sample,factor] in factors:\n",
    "            counts[factors.index(X_matrix.at[sample,factor])].append(dataset_contribution_individual[0][i])\n",
    "\n",
    "    # sort\n",
    "    sort_index = np.argsort([np.mean(x) for x in counts])\n",
    "    factors = [factors[i] for i in sort_index]\n",
    "    counts = [counts[i] for i in sort_index]\n",
    "    \n",
    "    # groups to keep\n",
    "    keep_index = [0,3,4,5]\n",
    "    factors = [factors[i] for i in keep_index]\n",
    "    counts = [counts[i] for i in keep_index]\n",
    "    factors = [x.split(' > ')[1] for x in factors]\n",
    "    \n",
    "    # thresholds\n",
    "    threshold1 = np.mean([np.max([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==0]),np.min([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==1])])\n",
    "    threshold2 = np.mean([np.max([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==1]),np.min([x for i,x in enumerate(dataset_contribution_individual[0]) if distribution_labels[i]==2])])\n",
    "\n",
    "    # colors\n",
    "    colors_ = ['#FFFACD','#F0E68C','#BFBB99']\n",
    "    colors = []\n",
    "    for i in range(len(counts)):\n",
    "        if np.median(counts[i]) < threshold1:\n",
    "            colors.append(colors_[0])\n",
    "        elif np.median(counts[i]) < threshold2:\n",
    "            colors.append(colors_[1])\n",
    "        else:\n",
    "            colors.append(colors_[2])\n",
    "\n",
    "    # plot\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(len(factors)/2,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.rc('xtick', labelsize=18)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = sns.boxplot(data=counts, whis=1, fliersize=0, palette=colors)\n",
    "    fig = sns.swarmplot(data=counts, color='black', alpha=0.25)\n",
    "    plt.plot([-1,len(factors)],[threshold1,threshold1],'k--')\n",
    "    plt.plot([-1,len(factors)],[threshold2,threshold2],'k--')\n",
    "    plt.text(len(factors)-0.1,threshold1/2,'Low Clinical', fontsize=16, verticalalignment='center')\n",
    "    plt.text(len(factors)-0.1,np.mean([threshold1,threshold2]),'Medium Clinical', fontsize=16, verticalalignment='center')\n",
    "    plt.text(len(factors)-0.1,np.mean([threshold2,1]),'High Clinical', fontsize=16, verticalalignment='center')\n",
    "    plt.xlim([-0.5,len(factors)-0.5])\n",
    "    plt.xticks(list(range(len(factors))),factors, rotation=90)\n",
    "    fig.spines['right'].set_visible(False)\n",
    "    fig.spines['top'].set_visible(False)\n",
    "    plt.ylabel('Percent Contribution - Clinical', fontsize=20)\n",
    "    plt.ylim([0,1])\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/clinical_BRCA.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
