{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder and datset names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'withhyperopt_4'\n",
    "individual_datasets = ['clinical_noninvasive','objscreen_blood']\n",
    "individual_datasets_labels = ['Non-Invasive Clinical','Blood Metabolites']\n",
    "colors = ['#FFD700','#DC143C']\n",
    "n_splits = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '_shap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_stacker = True\n",
    "analyze_shap_values = True\n",
    "analyze_shap_interactions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of dataset\n",
    "dataset_name = '+'.join(individual_datasets)\n",
    "\n",
    "# output folders\n",
    "if not os.path.isdir('%s/%s/%s' % (folder_name, dataset_name, output_folder)):\n",
    "    os.mkdir('%s/%s/%s' % (folder_name, dataset_name, output_folder))\n",
    "    \n",
    "    # stacker\n",
    "    if analyze_stacker:\n",
    "        os.mkdir('%s/%s/%s/stacker' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/stacker/summary' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/stacker/clinical_features' % (folder_name, dataset_name, output_folder))\n",
    "        \n",
    "    # shap values\n",
    "    if analyze_shap_values:\n",
    "        os.mkdir('%s/%s/%s/shap_values' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/summary' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/summary/stacker' % (folder_name, dataset_name, output_folder))\n",
    "        for dataset in individual_datasets:\n",
    "            os.mkdir('%s/%s/%s/shap_values/summary/stacker/%s' % (folder_name, dataset_name, output_folder, dataset))\n",
    "        os.mkdir('%s/%s/%s/shap_values/summary/cohort' % (folder_name, dataset_name, output_folder))\n",
    "        for cohort in ['ACC', 'BLCA', 'BRCA', 'CESC', 'COAD', 'DLBC', 'GBM', 'HNSC', 'LGG', 'LIHC', 'LUAD', 'LUSC', 'PRAD', 'READ', 'SKCM', 'STAD', 'THCA', 'UCEC', 'UCS']:\n",
    "            os.mkdir('%s/%s/%s/shap_values/summary/cohort/%s' % (folder_name, dataset_name, output_folder, cohort))\n",
    "        os.mkdir('%s/%s/%s/shap_values/features' % (folder_name, dataset_name, output_folder))\n",
    "        os.mkdir('%s/%s/%s/shap_values/patients' % (folder_name, dataset_name, output_folder))\n",
    "    \n",
    "    # shap interactions\n",
    "    if analyze_shap_interactions:\n",
    "        os.mkdir('%s/%s/%s/shap_interactions' % (folder_name, dataset_name, output_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merged dataset\n",
    "with open('_datasets/%s.pickle' % individual_datasets[0], 'rb') as f:\n",
    "    X_matrix, y_vector, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "X_matrix.columns = ['%s # %s' % (individual_datasets[0], x) for x in X_matrix.columns.tolist()]\n",
    "categorical_conversion = {}\n",
    "for key in categorical_conversion_old:\n",
    "    categorical_conversion['%s # %s' % (individual_datasets[0], key)] = categorical_conversion_old[key]\n",
    "for b in range(1,len(individual_datasets)):\n",
    "    with open('_datasets/%s.pickle' % individual_datasets[b], 'rb') as f:\n",
    "        X_matrix_, y_vector_, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "    X_matrix_.columns = ['%s # %s' % (individual_datasets[b], x) for x in X_matrix_.columns.tolist()]\n",
    "    categorical_conversion_ = {}\n",
    "    for key in categorical_conversion_old:\n",
    "        categorical_conversion_['%s # %s' % (individual_datasets[b], key)] = categorical_conversion_old[key]\n",
    "    if X_matrix.index.tolist() == X_matrix_.index.tolist():\n",
    "        X_matrix = pd.concat([X_matrix, X_matrix_], axis=1)\n",
    "        categorical_conversion = {**categorical_conversion, **categorical_conversion_}\n",
    "    else:\n",
    "        raise Exception(\"Dataset sample lists don't match\")\n",
    "samples = X_matrix.index.tolist()\n",
    "features =  X_matrix.columns.tolist()\n",
    "\n",
    "# list of merged features\n",
    "if len(categorical_conversion) > 0:\n",
    "    merged_features = []\n",
    "    for feature in features:\n",
    "        if feature.split(' | ')[0] not in categorical_conversion:\n",
    "            merged_features.append(feature)\n",
    "        elif feature.split(' | ')[0] not in merged_features:\n",
    "            merged_features.append(feature.split(' | ')[0])\n",
    "else:\n",
    "    merged_features = features.copy()\n",
    "    \n",
    "# merge feature matrix\n",
    "X_matrix_ = X_matrix.copy()\n",
    "for feature in categorical_conversion:\n",
    "    X_matrix_[feature] = np.nan\n",
    "    X_matrix_[feature] = X_matrix_[feature].astype(object)\n",
    "    \n",
    "    # get values for categorical features\n",
    "    values = []\n",
    "    for sample in X_matrix.index.tolist():\n",
    "        for val in categorical_conversion[feature]:\n",
    "            if X_matrix.at[sample,'%s | %s' % (feature, val)] == 1:\n",
    "                X_matrix_.at[sample, feature] = val\n",
    "X_matrix = X_matrix_[merged_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacker - log loss\n",
    "if analyze_stacker:\n",
    "    df = pd.read_csv('%s/stacker_logloss.csv' % folder_name, index_col=0)\n",
    "    stacker_log_loss = df.loc[['split_%d' % (i+1) for i in range(n_splits)]][dataset_name].values.tolist()\n",
    "    stacker_performance_weights = [1/x for x in stacker_log_loss]\n",
    "\n",
    "# classifier - weighted log loss\n",
    "df = pd.read_csv('%s/weightedlogloss.csv' % folder_name, index_col=0)\n",
    "classifier_weighted_log_loss = df.loc[['split_%d' % (i+1) for i in range(n_splits)]][dataset_name].values.tolist()\n",
    "classifier_performance_weights = [1/x for x in classifier_weighted_log_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "        \n",
    "    # load shap values\n",
    "    shap_expected = []\n",
    "    shap_values = []\n",
    "    for i in range(n_splits):\n",
    "        with open('%s/%s/shap_values_%d.pickle' % (folder_name, dataset_name, i+1) ,'rb') as f:\n",
    "            shap_expected_, shap_values_ = pickle.load(f)\n",
    "            shap_expected.append(shap_expected_)\n",
    "            shap_values.append(shap_values_)\n",
    "            \n",
    "    # remove samples that aren't analyzed\n",
    "    keep_index = []\n",
    "    for i,sample in enumerate(samples):\n",
    "        to_keep = False\n",
    "        for j in range(n_splits):\n",
    "            if sample in shap_values[j].index.tolist():\n",
    "                to_keep = True\n",
    "        if to_keep:\n",
    "            keep_index.append(i)\n",
    "    samples = [samples[i] for i in keep_index]\n",
    "    y_vector = [y_vector[i] for i in keep_index]\n",
    "    X_matrix = X_matrix.iloc[keep_index]\n",
    "    \n",
    "    # combine expected values\n",
    "    _expected_value_sum = [0 for sample in samples]\n",
    "    _shap_weight = [0 for sample in samples]\n",
    "    for i,sample in enumerate(samples):\n",
    "        for j in range(n_splits):\n",
    "            if sample in shap_values[j].index.tolist():\n",
    "                _expected_value_sum[i] += classifier_performance_weights[j] * shap_expected[j][shap_values[j].index.tolist().index(sample)]\n",
    "                _shap_weight[i] += classifier_performance_weights[j]\n",
    "    expected_value = np.divide(_expected_value_sum, _shap_weight)\n",
    "    \n",
    "    # combine shap values\n",
    "    for i in range(n_splits):\n",
    "        samples_not_included = [x for x in samples if x not in shap_values[i].index.tolist()]\n",
    "        shap_values[i] = pd.concat([shap_values[i], pd.DataFrame(data=0, index=samples_not_included, columns=shap_values[i].columns.tolist())])\n",
    "        shap_values[i] = shap_values[i].loc[samples]\n",
    "        features_not_included = [x for x in merged_features if x not in shap_values[i].columns.tolist()]\n",
    "        shap_values[i] = pd.concat([shap_values[i], pd.DataFrame(data=0, index=samples, columns=features_not_included)], axis=1, sort=False)\n",
    "        shap_values[i] = shap_values[i][merged_features]\n",
    "    shap_value = pd.DataFrame(data=0, index=samples, columns=merged_features)\n",
    "    for i in range(n_splits):\n",
    "        shap_value = np.add(shap_value, classifier_performance_weights[i]*shap_values[i])\n",
    "    for j in range(len(samples)):\n",
    "        shap_value.loc[samples[j]] /= _shap_weight[j]\n",
    "        \n",
    "    # calculate absolute shap values\n",
    "    shap_value_abs = shap_value.abs()\n",
    "    \n",
    "    # zero shap values for imputed features\n",
    "    for sample in shap_value_abs.index.tolist():\n",
    "        for feature in shap_value_abs.columns.tolist():\n",
    "            if pd.isna(X_matrix.at[sample,feature]):\n",
    "                shap_value_abs.at[sample,feature] = 0\n",
    "    \n",
    "    # normalize by difference between prior and posterior\n",
    "    for i,sample in enumerate(samples):\n",
    "        shap_value_abs.loc[sample] /= np.sum(shap_value_abs.loc[sample].values.tolist())\n",
    "        \n",
    "    # mean and standard error for each feature\n",
    "    shap_value_abs_mean = shap_value_abs.mean(axis=0).values.tolist()\n",
    "    shap_value_abs_mean_cumsum = np.cumsum(sorted(shap_value_abs_mean)[::-1])\n",
    "    shap_value_abs_std = shap_value_abs.std(axis=0).values.tolist()\n",
    "    shap_value_abs_sterr = [x/np.sqrt(len(samples)) for x in shap_value_abs_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "\n",
    "    # top 95% features\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1][:len([x for x in shap_value_abs_mean_cumsum if x<=0.95])]\n",
    "    overall_top_features = [merged_features[i] for i in top_N_index]\n",
    "    overall_top_values = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "    \n",
    "    # top N features - mean\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1]\n",
    "    top_N_mean = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "\n",
    "    # plot - all shap values\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=18)\n",
    "    plt.rc('ytick', labelsize=18)\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xscale('log')\n",
    "    ax.plot(range(1,len(merged_features)+1), sorted(shap_value_abs_mean)[::-1], 'k.-', markersize=5)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.ylim(-0.0024,0.24)\n",
    "    plt.yticks([0,0.04,0.08,0.12,0.16,0.2,0.24])\n",
    "    plt.xlabel('Features', fontsize=20)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(range(1,len(merged_features)+1), shap_value_abs_mean_cumsum, '.-', color='#808080', markersize=5)\n",
    "    ax2.plot([len([x for x in shap_value_abs_mean_cumsum if x<=0.95]),len([x for x in shap_value_abs_mean_cumsum if x<=0.95])],[0,0.95],'--',color='#808080')\n",
    "    ax2.plot([len([x for x in shap_value_abs_mean_cumsum if x<=0.95]),1.1*len(merged_features)],[0.95,0.95],'--',color='#808080')\n",
    "    ax2.plot([len([x for x in shap_value_abs_mean if x>0]),len([x for x in shap_value_abs_mean if x>0])],[0,1],'--',color='#808080')\n",
    "    ax2.tick_params(axis='y', labelcolor='#808080')\n",
    "    ax2.set_ylabel('Cumulative Sum', color='#808080', fontsize=20)\n",
    "    ax2.set_ylim(0,1.01)\n",
    "    ax2.set_yticks([0,0.25,0.5,0.75,0.95,1])\n",
    "    num_int = len(str(len(merged_features)))\n",
    "    plt.xticks([10**x for x in range(num_int)]+[len(merged_features)],[10**x for x in range(num_int)]+[len(merged_features)])\n",
    "    plt.xlim(0.95,1.05*len(merged_features))  \n",
    "    plt.text(len([x for x in shap_value_abs_mean_cumsum if x<=0.95]),0.03,'%d' % len([x for x in shap_value_abs_mean_cumsum if x<=0.95]), weight='bold', ha='right', fontsize=20)\n",
    "    plt.text(len([x for x in shap_value_abs_mean if x>0]),0.03,'%d' % len([x for x in shap_value_abs_mean if x>0]), ha='right', fontsize=20)\n",
    "    #plt.text(len(merged_features),0.03,'%d' % len(merged_features), weight='bold', ha='right', fontsize=20)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    vals = ax2.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax2.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax2.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax2.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/all_features.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "    \n",
    "    # plot - dataset contribution\n",
    "    dataset_contribution = []\n",
    "    for dataset in individual_datasets:\n",
    "        dataset_contribution.append(np.sum([x for i,x in enumerate(shap_value_abs_mean) if merged_features[i].split(' # ')[0]==dataset and merged_features[i] in overall_top_features]))\n",
    "    dataset_contribution = [x/np.sum(dataset_contribution) for x in dataset_contribution]\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    patches, texts, autotexts = plt.pie(dataset_contribution, labels=individual_datasets_labels, colors=colors, autopct='%1.1f%%')\n",
    "    for i in range(len(texts)):\n",
    "        texts[i].set_fontsize(20)\n",
    "        autotexts[i].set_fontsize(20)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()\n",
    "    \n",
    "    # plot - individual patient dataset contribution\n",
    "    dataset_contribution_individual = [[] for dataset in individual_datasets]\n",
    "    dataset_contribution_individual_top = [[] for dataset in individual_datasets]\n",
    "    for j,sample in enumerate(samples):\n",
    "        sample_values = shap_value_abs.loc[sample].values.tolist()\n",
    "        for i,dataset in enumerate(individual_datasets):\n",
    "            dataset_contribution_individual[i].append(np.sum([sample_values[a] for a in range(len(merged_features)) if merged_features[a].split(' # ')[0]==dataset and merged_features[a] in overall_top_features])/np.sum(sample_values))\n",
    "        if np.sum([sample_values[a] for a in range(len(merged_features)) if merged_features[a].split(' # ')[0]==dataset])/np.sum(sample_values) > (1/len(individual_datasets)):\n",
    "            dataset_contribution_individual_top[i].append(sample)\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(3*len(individual_datasets),10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.rc('xtick', labelsize=20)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = sns.boxplot(data=dataset_contribution_individual, whis=1, fliersize=0, palette=colors)\n",
    "    fig = sns.swarmplot(data=dataset_contribution_individual, color='black', alpha=0.25)\n",
    "    plt.xlim([-0.5,len(individual_datasets)-0.5])\n",
    "    fig.set(xticklabels=individual_datasets_labels)\n",
    "    fig.spines['right'].set_visible(False)\n",
    "    fig.spines['top'].set_visible(False)\n",
    "    plt.ylabel('Percent Contribution', fontsize=20)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_individual.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "seed_ = 1\n",
    "def compute_inertia(a, X):\n",
    "    W = [np.mean(pairwise_distances(X[a == c, :])) for c in np.unique(a)]\n",
    "    return np.mean(W)\n",
    "\n",
    "def compute_gap(clustering, data, k_max=5, n_references=100):\n",
    "    np.random.seed(seed_)\n",
    "    if len(data.shape) == 1:\n",
    "        data = data.reshape(-1, 1)\n",
    "    reference = np.random.rand(*data.shape)\n",
    "    reference_inertia = []\n",
    "    for k in range(1, k_max+1):\n",
    "        local_inertia = []\n",
    "        for _ in range(n_references):\n",
    "            clustering.n_clusters = k\n",
    "            assignments = clustering.fit_predict(reference)\n",
    "            local_inertia.append(compute_inertia(assignments, reference))\n",
    "        reference_inertia.append(np.mean(local_inertia))\n",
    "    \n",
    "    ondata_inertia = []\n",
    "    for k in range(1, k_max+1):\n",
    "        clustering.n_clusters = k\n",
    "        assignments = clustering.fit_predict(data)\n",
    "        ondata_inertia.append(compute_inertia(assignments, data))\n",
    "        \n",
    "    gap = np.log(reference_inertia)-np.log(ondata_inertia)\n",
    "    return gap, np.log(reference_inertia), np.log(ondata_inertia)\n",
    "\n",
    "# calculate optimal number of distrubutions\n",
    "k_max = 10\n",
    "gap, reference_inertia, ondata_inertia = compute_gap(KMeans(random_state=seed_), np.array(dataset_contribution_individual[0]).reshape(-1,1), k_max=k_max)\n",
    "optimal_number_of_distributions = np.argmax(gap)+1\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1,k_max+1), gap, 'k.-', markersize=5)\n",
    "ax.plot([optimal_number_of_distributions, optimal_number_of_distributions],[0.05,np.max(gap)], 'k--')\n",
    "plt.xlabel('Number of Distributions', fontsize=20)\n",
    "plt.ylabel('Gap Statistic', fontsize=20)\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10])\n",
    "plt.ylim([0.05,0.35])\n",
    "plt.yticks([.05,.15,.25,.35])\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/clinical_kmeans_gap.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# separate samples into distributions\n",
    "kmeans = KMeans(n_clusters=optimal_number_of_distributions).fit(np.array(dataset_contribution_individual[0]).reshape(-1,1))\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_.reshape(-1,)\n",
    "distribution_labels = []\n",
    "for val in labels:\n",
    "    distribution_labels.append(sorted(centers).index(centers[val]))\n",
    "distribution_names = ['low','high']\n",
    "distribution_names_labels = ['Low','High']\n",
    "\n",
    "# histogram\n",
    "values = dataset_contribution_individual[0]\n",
    "n_bins = 25\n",
    "_, bin_edges = np.histogram(values, bins=n_bins)\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "colors_ = ['#FFFACD','#F0E68C']\n",
    "for i in range(optimal_number_of_distributions):\n",
    "    sns.distplot([values[a] for a in range(len(values)) if distribution_labels[a]==i], hist=True, kde=True, bins=bin_edges, color=colors_[i], hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4})\n",
    "plt.legend(['Low Clinical - %0.1f%%' % (len([x for x in distribution_labels if x==0])/len(distribution_labels)*100),'High Clinical - %0.1f%%' % (len([x for x in distribution_labels if x==1])/len(distribution_labels)*100)], fontsize=16)\n",
    "plt.xlabel('Percent Contribution - Clinical', fontsize=20)\n",
    "plt.ylabel('Count', fontsize=20)    \n",
    "plt.xlim(0,1)\n",
    "plt.xticks([0,0.25,0.5,0.75,1],['0%','25%','50%','75%','100%'])\n",
    "plt.savefig('%s/%s/%s/shap_values/summary/clinical_multimodal.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# dataset contribution - low/med/high clinical\n",
    "for a in range(len(distribution_names)):\n",
    "    \n",
    "    # subset shap values\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = shap_value_abs_distribution.mean(axis=0).values.tolist()\n",
    "    \n",
    "    # new top features\n",
    "    shap_value_abs_distribution_cumsum = np.cumsum(sorted(shap_value_abs_distribution_mean)[::-1])\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:len([x for x in shap_value_abs_distribution_cumsum if x<=0.95])]\n",
    "    new_overall_top_features = [merged_features[i] for i in top_N_index]\n",
    "    \n",
    "    # dataset contribution\n",
    "    dataset_contribution_distribution = []\n",
    "    for dataset in individual_datasets:\n",
    "        dataset_contribution_distribution.append(np.sum([x for i,x in enumerate(shap_value_abs_distribution_mean) if merged_features[i].split(' # ')[0]==dataset and merged_features[i] in new_overall_top_features]))\n",
    "    dataset_contribution_distribution = [x/np.sum(dataset_contribution_distribution) for x in dataset_contribution_distribution]\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    patches, texts, autotexts = plt.pie(dataset_contribution_distribution, labels=individual_datasets_labels, colors=colors, autopct='%1.1f%%')\n",
    "    plt.title('%s Clinical' % distribution_names_labels[a], fontsize=20)\n",
    "    for i in range(len(texts)):\n",
    "        texts[i].set_fontsize(20)\n",
    "        autotexts[i].set_fontsize(20)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_clinical_%s.png' % (folder_name, dataset_name, output_folder, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset contribution - low/med/high clinical\n",
    "for a in range(len(distribution_names))[0:1]:\n",
    "    \n",
    "    # subset shap values\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = shap_value_abs_distribution.mean(axis=0).values.tolist()\n",
    "    \n",
    "    # new top features\n",
    "    shap_value_abs_distribution_cumsum = np.cumsum(sorted(shap_value_abs_distribution_mean)[::-1])\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:len([x for x in shap_value_abs_distribution_cumsum if x<=0.95])]\n",
    "    new_overall_top_features = [merged_features[i] for i in top_N_index]\n",
    "    \n",
    "    # dataset contribution\n",
    "    contribution_names = ['Other Non-Invasive Clinical','Cancer Type','Blood Metabolites']\n",
    "    contribution_values = [np.sum([x for i,x in enumerate(shap_value_abs_distribution_mean) if merged_features[i].split(' # ')[0]=='clinical_noninvasive' and merged_features[i] in new_overall_top_features and merged_features[i]!='clinical_noninvasive # COHORT']), shap_value_abs_distribution_mean[merged_features.index('clinical_noninvasive # COHORT')],  np.sum([x for i,x in enumerate(shap_value_abs_distribution_mean) if merged_features[i].split(' # ')[0]=='objscreen_blood' and merged_features[i] in new_overall_top_features])]\n",
    "    contribution_values = [x/np.sum(contribution_values) for x in contribution_values]\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    patches, texts, autotexts = plt.pie(contribution_values, colors=['#FFD700','#e6c200','#DC143C'], autopct='%1.1f%%')\n",
    "    plt.title('%s Clinical' % distribution_names_labels[a], fontsize=20)\n",
    "    for i in range(len(texts)):\n",
    "        texts[i].set_fontsize(26)\n",
    "        autotexts[i].set_fontsize(26)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/dataset_contribution_clinical_%s_cohort.png' % (folder_name, dataset_name, output_folder, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_shap_values:\n",
    "    \n",
    "    # N value\n",
    "    N = 50\n",
    "    \n",
    "    # top N features - mean\n",
    "    top_N_index = np.argsort(shap_value_abs_mean)[::-1][:N]\n",
    "    top_N_mean = [shap_value_abs_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    colors_ = []\n",
    "    for dataset in top_N_datasets:\n",
    "        colors_.append(colors[individual_datasets.index(dataset)])\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5)\n",
    "    for i in range(len(barlist)):\n",
    "        barlist[i].set_color(colors_[i])\n",
    "    plt.xticks(range(N), top_N_features, rotation=90)\n",
    "    plt.xlim(-1,N)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.title('Top %d Features' % N, fontsize=24)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.legend([barlist[colors_.index(x)] for x in colors], individual_datasets_labels, fontsize=16)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/top%d.png' % (folder_name, dataset_name, output_folder, N), bbox_inches='tight', dpi=400)\n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top N features - mean - low/med/high clinical\n",
    "for a in range(len(distribution_names))[0:1]:\n",
    "\n",
    "    # get values\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = shap_value_abs_distribution.mean(axis=0).values.tolist()\n",
    "    shap_value_abs_distribution_std = shap_value_abs_distribution.std(axis=0).values.tolist()\n",
    "    shap_value_abs_distribution_sterr = [x/np.sqrt(len([y for y in distribution_labels if y==a])) for x in shap_value_abs_distribution_std]\n",
    "\n",
    "    # plot\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:N]\n",
    "    top_N_mean = [shap_value_abs_distribution_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_distribution_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [merged_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [merged_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    colors_ = []\n",
    "    for dataset in top_N_datasets:\n",
    "        colors_.append(colors[individual_datasets.index(dataset)])\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5)\n",
    "    for i in range(len(barlist)):\n",
    "        barlist[i].set_color(colors_[i])\n",
    "    plt.xticks(range(N), top_N_features, rotation=90)\n",
    "    plt.xlim(-1,N)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.title('%s Clinical Patients' % distribution_names[a], fontsize=24)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.legend([barlist[colors_.index(x)] for x in colors], individual_datasets_labels, fontsize=16)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/top%d_clinical_%s.png' % (folder_name, dataset_name, output_folder, N, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top features - low clinical - other non-invasive clinical\n",
    "for a in range(len(distribution_names))[0:1]:\n",
    "\n",
    "    # get values\n",
    "    keep_features_id = [i for i,x in enumerate(merged_features) if x.split(' # ')[0]=='clinical_noninvasive' and x!='clinical_noninvasive # COHORT']\n",
    "    keep_features = [merged_features[i] for i in keep_features_id]\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = [shap_value_abs_distribution.mean(axis=0).values.tolist()[i] for i in keep_features_id]\n",
    "    shap_value_abs_distribution_std = [shap_value_abs_distribution.std(axis=0).values.tolist()[i] for i in keep_features_id]\n",
    "    shap_value_abs_distribution_sterr = [x/np.sqrt(len([y for y in distribution_labels if y==a])) for x in shap_value_abs_distribution_std]\n",
    "\n",
    "    # plot\n",
    "    N = 5\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:N]\n",
    "    top_N_mean = [shap_value_abs_distribution_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_distribution_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [keep_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [keep_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    labels = ['Tumor location','Clinical Stage','Patient age','Patient race','Patient Gender']\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(20/50*N*1.5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5, color=['#FFD700'])\n",
    "    plt.xticks(range(N), labels, rotation=90, fontsize=16)\n",
    "    plt.xlim(-1,N)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.title('Other Non-Invasive Clinical', fontsize=20)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/top%d_clinical_%s_otherclinical.png' % (folder_name, dataset_name, output_folder, N, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top features - low clinical - blood metabolies\n",
    "for a in range(len(distribution_names))[0:1]:\n",
    "\n",
    "    # get values\n",
    "    keep_features_id = [i for i,x in enumerate(merged_features) if x.split(' # ')[0]=='objscreen_blood']\n",
    "    keep_features = [merged_features[i] for i in keep_features_id]\n",
    "    shap_value_abs_distribution = shap_value_abs.loc[[samples[i] for i in range(len(samples)) if distribution_labels[i]==a]]\n",
    "    shap_value_abs_distribution_mean = [shap_value_abs_distribution.mean(axis=0).values.tolist()[i] for i in keep_features_id]\n",
    "    shap_value_abs_distribution_std = [shap_value_abs_distribution.std(axis=0).values.tolist()[i] for i in keep_features_id]\n",
    "    shap_value_abs_distribution_sterr = [x/np.sqrt(len([y for y in distribution_labels if y==a])) for x in shap_value_abs_distribution_std]\n",
    "\n",
    "    # plot\n",
    "    N = 11\n",
    "    top_N_index = np.argsort(shap_value_abs_distribution_mean)[::-1][:N]\n",
    "    top_N_mean = [shap_value_abs_distribution_mean[i] for i in top_N_index]\n",
    "    top_N_sterr = [shap_value_abs_distribution_sterr[i] for i in top_N_index]\n",
    "    top_N_datasets = [keep_features[i].split(' # ')[0] for i in top_N_index]\n",
    "    top_N_features = [keep_features[i].split(' # ')[-1] for i in top_N_index]\n",
    "    labels = ['Butyric acid','Prostaglandin J2','Phenylacetic acid','5Z-Tetradecenoic acid','Aminoadipic acid','Pyroglutamic acid','GDP','Allysine','Capric acid','Prostaglandin D2','Adrenic acid']\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(20/50*N*1.5,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    barlist = plt.bar(range(N), top_N_mean, yerr=top_N_sterr, capsize=5, color=['#DC143C'])\n",
    "    plt.xticks(range(N), labels, rotation=90, fontsize=16)\n",
    "    plt.xlim(-1,N)\n",
    "    plt.ylabel(r'Mean |$\\Delta$P|', fontsize=20)\n",
    "    plt.title('Blood Metabolites', fontsize=20)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    vals = ax.get_yticks()\n",
    "    decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "    if len([x for x in decimals if x != '0']) > 0:\n",
    "        number_of_places = np.max([len(x) for x in decimals])\n",
    "    else:\n",
    "        number_of_places = np.max([len(x) for x in decimals])-1\n",
    "    if number_of_places == 0:\n",
    "        ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 1:\n",
    "        ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "    elif number_of_places == 2:\n",
    "        ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "    else:\n",
    "        raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "    plt.savefig('%s/%s/%s/shap_values/summary/top%d_clinical_%s_blood.png' % (folder_name, dataset_name, output_folder, N, distribution_names[a]), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function\n",
    "def plot_patient(patient_name, actual_value, expected_value, features_, shap_, original_):\n",
    "    \n",
    "    # initialize figure\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    fig = plt.figure(figsize=(20,.25*len(features_)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # patient name\n",
    "    if actual_value == 0:\n",
    "        plt.text(0.5,0.6,patient_name, horizontalalignment='center', verticalalignment='center', color='#5bc2ae', fontsize=14, weight='bold')\n",
    "    else:\n",
    "        plt.text(0.5,0.6,patient_name, horizontalalignment='center', verticalalignment='center', color='#d93f20', fontsize=14, weight='bold')\n",
    "    \n",
    "    # number line\n",
    "    plt.plot([0,1],[0,0],'k-',linewidth=1)\n",
    "    for x in [0,0.5,1]:\n",
    "        plt.plot([x,x],[-0.1,0.1],'k-',linewidth=1)\n",
    "    plt.plot([expected_value,expected_value],[-0.3,0.1],'k--',linewidth=1)\n",
    "    plt.text(0,0.1,'0%', horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=12)\n",
    "    plt.text(0.5,0.1,'50%', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "    plt.text(1,0.1,'100%', horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=12)\n",
    "    plt.text(expected_value,0.1,'%0.1f%%' % (expected_value*100), horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "    plt.text(expected_value,0.3,'Prior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "    \n",
    "    # data\n",
    "    current_value = expected_value\n",
    "    y_value = -0.3\n",
    "    for i in range(len(features_)):\n",
    "        if shap_[i] < 0:\n",
    "            plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color='#5bc2ae')\n",
    "            if type(original_[i]) == str:\n",
    "                plt.text(current_value+0.005, y_value, '%s = %s' % (features_[i], original_[i]), horizontalalignment='left', verticalalignment='center', fontsize=12)\n",
    "            else:\n",
    "                plt.text(current_value+0.005, y_value, '%s (Imputed)' % features_[i], horizontalalignment='left', verticalalignment='center', fontsize=12)\n",
    "        else:\n",
    "            plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color='#d93f20')\n",
    "            if type(original_[i]) == str:\n",
    "                plt.text(current_value-0.005, y_value, '%s = %s' % (features_[i], original_[i]), horizontalalignment='right', verticalalignment='center', fontsize=12)\n",
    "            else:\n",
    "                plt.text(current_value-0.005, y_value, '%s (Imputed)' % features_[i], horizontalalignment='right', verticalalignment='center', fontsize=12)\n",
    "        current_value += shap_[i]\n",
    "        y_value += -0.3\n",
    "        \n",
    "    # end line\n",
    "    plt.plot([current_value,current_value],[y_value+0.15,0.1],'k--',linewidth=1)\n",
    "    if current_value < 0.5:\n",
    "        plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=12, weight='bold')\n",
    "    else:\n",
    "        plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=12, weight='bold')\n",
    "    plt.text(current_value,0.3,'Posterior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "        \n",
    "    # limits\n",
    "    plt.xlim(-0.02,1.02)\n",
    "    plt.ylim(y_value-0.05, 0.8)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over patients\n",
    "for a,sample in enumerate(samples):\n",
    "    #if distribution_labels[a]==0 and y_vector[a]==1 and X_matrix.at[sample,'clinical_noninvasive # COHORT']!='LGG':\n",
    "    if True:\n",
    "    \n",
    "        # get nonzero shap and feature values\n",
    "        features_ = [feature for feature in merged_features if shap_value.loc[sample][feature] != 0]\n",
    "        shap_ = shap_value.loc[sample][features_].tolist()\n",
    "        original_ = X_matrix.loc[sample][features_].tolist()\n",
    "\n",
    "        # convert numerical values to strings\n",
    "        for j in range(len(original_)):\n",
    "            if not type(original_[j]) == str:\n",
    "                if type(original_[j]) == bool:\n",
    "                    original_[j] = str(original_[j])\n",
    "                elif not np.isnan(original_[j]):\n",
    "                    if original_[j] == int(original_[j]):\n",
    "                        original_[j] = str(int(original_[j]))\n",
    "                    else:\n",
    "                        original_[j] = str(original_[j])\n",
    "\n",
    "\n",
    "        # order features based on absolute shap value\n",
    "        sort_index = np.argsort(np.abs(shap_))[::-1]\n",
    "        features_ = [features_[i] for i in sort_index]\n",
    "        shap_ = [shap_[i] for i in sort_index]\n",
    "        original_ = [original_[i] for i in sort_index]\n",
    "        \n",
    "        # group imputed values\n",
    "        #imputed_id = [i for i,x in enumerate(original_) if pd.isna(x)]\n",
    "        #imputed_sum = np.sum([shap_[i] for i in imputed_id])\n",
    "        #for i in imputed_id[::-1]:\n",
    "        #    del features_[i]\n",
    "        #    del shap_[i]\n",
    "        #    del original_[i]\n",
    "        #features_.append('(Imputed)')\n",
    "        #shap_.append(imputed_sum)\n",
    "        #original_.append(np.nan)\n",
    "        \n",
    "        # create figure\n",
    "        #if np.sum(shap_)+expected_value[a] > 0.5:\n",
    "            #plot_patient(sample, y_vector[a], expected_value[a], features_, shap_, original_)\n",
    "            #plt.savefig('%s/%s/%s/shap_values/patients/%s.png' % (folder_name, dataset_name, output_folder, sample), bbox_inches='tight', dpi=400)\n",
    "            #plt.close()\n",
    "        if True:\n",
    "            print(expected_value[a]+np.sum(shap_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color functions\n",
    "def adjust_color_lightness(r, g, b, factor):\n",
    "    h, l, s = rgb_to_hls(r / 255.0, g / 255.0, b / 255.0)\n",
    "    l = max(min(l * factor, 1.0), 0.0)\n",
    "    r, g, b = hls_to_rgb(h, l, s)\n",
    "    return int(r * 255), int(g * 255), int(b * 255)\n",
    "\n",
    "def lighten_color(r, g, b, factor=0.1):\n",
    "    return adjust_color_lightness(r, g, b, 1 + factor)\n",
    "\n",
    "def darken_color(r, g, b, factor=0.1):\n",
    "    return adjust_color_lightness(r, g, b, 1 - factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'TCGA-S9-A7IY-01A'\n",
    "a = samples.index(sample)\n",
    "feature_names = ['Karnofsky Score','12,13-DHOME','Patient Age',r'6-Keto-prostaglandin F1$\\alpha$','D-Fructose','Urea','Valeric acid','Eicosatrienoic acid','Palmitic acid','Allopregnanolone','Behenic acid','Oxoadipic acid','Phosphorylcholine','Sphingosine','N-Acetylputrescine','Thromboxane A2','Lanosterin','Adipic acid','2-Methylcitric acid','Glyceraldehyde','Adenine','Hydroperoxylinoleic acid','Oleic acid','Dihydrobiopterin','4-Hydroxynonenal','Eicosenoic acid','Phenylacetylglutamine','Sphinganine','L-Arabitol','Xanthurenic acid','GTP','5-Hydroxyindoleacetic acid','Guanosine','Patient Race','4-Hydroxyproline','Quinolinic acid','Capric acid','Eicosatetraenoic acid',r'20$\\alpha$-Dihydroprogesterone','Prostaglandin D2','Argininosuccinic acid','Elaidic acid','GDP','Butyric acid','Pyroglutamic acid','Allysine','Prostaglandin J2','Aminoadipic acid','Phenylacetic acid','5Z-Tetradecenoic acid','Cancer Type']\n",
    "\n",
    "# get nonzero shap and feature values\n",
    "features_ = [feature for feature in merged_features if shap_value.loc[sample][feature] != 0]\n",
    "shap_ = shap_value.loc[sample][features_].tolist()\n",
    "original_ = X_matrix.loc[sample][features_].tolist()\n",
    "\n",
    "# convert numerical values to strings\n",
    "for j in range(len(original_)):\n",
    "    if not type(original_[j]) == str:\n",
    "        if type(original_[j]) == bool:\n",
    "            original_[j] = str(original_[j])\n",
    "        elif not np.isnan(original_[j]):\n",
    "            if original_[j] == int(original_[j]):\n",
    "                original_[j] = str(int(original_[j]))\n",
    "            else:\n",
    "                original_[j] = str(original_[j])\n",
    "\n",
    "# order features based on absolute shap value\n",
    "sort_index = np.argsort(np.abs(shap_))[::-1]\n",
    "features_ = [features_[i] for i in sort_index]\n",
    "shap_ = [shap_[i] for i in sort_index]\n",
    "original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "# only keep top cumulative 95%\n",
    "shap_normalized = [np.abs(x)/np.sum(np.abs(shap_)) for x in shap_]\n",
    "threshold_index = [i for i,x in enumerate(np.cumsum(shap_normalized)) if x<0.95][-1]\n",
    "features_ = features_[:threshold_index]\n",
    "shap_ = shap_[:threshold_index]\n",
    "original_ = original_[:threshold_index]\n",
    "                \n",
    "# order features based on shap value\n",
    "sort_index = np.argsort(shap_)\n",
    "features_ = [features_[i] for i in sort_index]\n",
    "shap_ = [shap_[i] for i in sort_index]\n",
    "original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "# remove imputed features\n",
    "sort_index = [i for i,x in enumerate(original_) if not pd.isna(x)]\n",
    "features_ = [features_[i] for i in sort_index]\n",
    "shap_ = [shap_[i] for i in sort_index]\n",
    "original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(111)\n",
    "barlist = plt.bar([x+1 for x in list(range(len(shap_)))], shap_)\n",
    "for i in range(len(barlist)):\n",
    "    if features_[i]=='clinical_noninvasive # COHORT':\n",
    "        barlist[i].set_color('#e6c200')\n",
    "    else:\n",
    "        barlist[i].set_color(colors[individual_datasets.index(features_[i].split(' # ')[0])])\n",
    "    if shap_[i] < 0:\n",
    "        plt.text(i+1,0+0.0004,feature_names[i], fontsize=12, rotation=90, horizontalalignment='center', verticalalignment='bottom')\n",
    "    else:\n",
    "        plt.text(i+1,0-0.0001,feature_names[i], fontsize=12, rotation=90, horizontalalignment='center', verticalalignment='top')\n",
    "plt.plot([0,len(shap_)+1],[0,0],'k-',linewidth=1)\n",
    "plt.xlim([0,len(shap_)+1])\n",
    "plt.ylim([-0.02,0.05])\n",
    "plt.xticks([])\n",
    "plt.yticks([-0.02,-0.01,0,0.01,0.02,0.03,0.04,0.052],labels=['-2%','-1%','0%','1%','2%','3%','4%','13%'])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "plt.ylabel(r'$\\Delta$P', fontsize=20)\n",
    "#plt.text(1,0.04,'%s\\n%d y.o. %s %s\\nCancer Type: %s' % (sample[:12],X_matrix.at[sample,'clinical_noninvasive # AGE'],X_matrix.at[sample,'clinical_noninvasive # RACE'].title(),X_matrix.at[sample,'clinical_noninvasive # GENDER'].title(),X_matrix.at[sample,'clinical_noninvasive # COHORT']), fontsize=17)\n",
    "plt.text(1,0.043,'%s\\nClass: ' % (sample[:12]), fontsize=17)\n",
    "if y_vector[a]==0:\n",
    "    plt.text(4.1,0.043,'Sensitive', fontsize=17, weight='bold', color='#5bc2ae')\n",
    "else:\n",
    "    plt.text(4.1,0.043,'Resistant', fontsize=17, weight='bold', color='#d93f20')\n",
    "plt.savefig('%s/%s/%s/shap_values/example/bar.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap plots\n",
    "for feature in features_:\n",
    "    if feature.split(' # ')[0]=='objscreen_blood' or feature.split(' # ')[1] in ['KARNOFSKY','AGE']:\n",
    "    \n",
    "        # get values\n",
    "        val = X_matrix[feature].values.tolist()\n",
    "        sh = shap_value[feature].values.tolist()\n",
    "        patient_index = samples.index(sample)\n",
    "        keep_index = [i for i,x in enumerate(val) if not pd.isna(x)]\n",
    "        val = [val[i] for i in keep_index]\n",
    "        sh = [sh[i] for i in keep_index]\n",
    "        patient_index = keep_index.index(patient_index)\n",
    "\n",
    "        # plot\n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "        plt.rc('xtick', labelsize=20)\n",
    "        plt.rc('ytick', labelsize=20)\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.plot(val, sh, 'k.')\n",
    "        plt.plot(val[patient_index], sh[patient_index], 'r.')\n",
    "        plt.title(feature)\n",
    "        if feature.split(' # ')[0]=='objscreen_blood':\n",
    "            ax.set_xscale('log')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'objscreen_blood # M02745'\n",
    "title = '5Z-Tetradecenoic acid'\n",
    "\n",
    "# get values\n",
    "val = X_matrix[feature].values.tolist()\n",
    "sh = shap_value[feature].values.tolist()\n",
    "patient_index = samples.index(sample)\n",
    "keep_index = [i for i,x in enumerate(val) if not pd.isna(x)]\n",
    "val = [val[i] for i in keep_index]\n",
    "sh = [sh[i] for i in keep_index]\n",
    "patient_index = keep_index.index(patient_index)\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(val, sh, 'k.', markersize=5)\n",
    "plt.plot(val[patient_index], sh[patient_index], '.', markersize=12, color='#d93f20')\n",
    "plt.plot([0.001,0.1],[0,0],'k--',linewidth=1)\n",
    "plt.title(title, fontsize=18)\n",
    "ax.set_xscale('log')\n",
    "plt.xlim([0.001,0.1])\n",
    "plt.ylim([-0.02,0.04])\n",
    "plt.yticks([-0.02,0,0.02,0.04])\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.xlabel(r'Metabolite Production [mmol gDW$^{-1}$ hr$^{-1}$]', fontsize=16)\n",
    "plt.ylabel(r'$\\Delta$P', fontsize=20)\n",
    "plt.savefig('%s/%s/%s/shap_values/example/met1.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'objscreen_blood # pheacgln'\n",
    "title = 'Phenylacetylglutamine'\n",
    "\n",
    "# get values\n",
    "val = X_matrix[feature].values.tolist()\n",
    "sh = shap_value[feature].values.tolist()\n",
    "patient_index = samples.index(sample)\n",
    "keep_index = [i for i,x in enumerate(val) if not pd.isna(x)]\n",
    "val = [val[i] for i in keep_index]\n",
    "sh = [sh[i] for i in keep_index]\n",
    "patient_index = keep_index.index(patient_index)\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(val, sh, 'k.', markersize=5)\n",
    "plt.plot(val[patient_index], sh[patient_index], '.', markersize=12, color='#d93f20')\n",
    "plt.plot([0.00001,0.1],[0,0],'k--',linewidth=1)\n",
    "plt.title(title, fontsize=18)\n",
    "ax.set_xscale('log')\n",
    "plt.xlim([0.00001,0.1])\n",
    "plt.ylim([-0.01,0.025])\n",
    "plt.yticks([-0.01,0,0.01,0.02])\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.xlabel(r'Metabolite Production [mmol gDW$^{-1}$ hr$^{-1}$]', fontsize=16)\n",
    "plt.ylabel(r'$\\Delta$P', fontsize=20)\n",
    "plt.savefig('%s/%s/%s/shap_values/example/met2.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'objscreen_blood # pheacgln'\n",
    "title = 'Phenylacetylglutamine'\n",
    "\n",
    "# get values\n",
    "val = X_matrix[feature].values.tolist()\n",
    "sh = shap_value[feature].values.tolist()\n",
    "patient_index = samples.index(sample)\n",
    "keep_index = [i for i,x in enumerate(val) if not pd.isna(x)]\n",
    "val = [val[i] for i in keep_index]\n",
    "sh = [sh[i] for i in keep_index]\n",
    "patient_index = keep_index.index(patient_index)\n",
    "\n",
    "# plot\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(val, sh, 'k.', markersize=5)\n",
    "plt.plot(val[patient_index], sh[patient_index], '.', markersize=12, color='#d93f20')\n",
    "plt.plot([0.00001,0.1],[0,0],'k--',linewidth=1)\n",
    "plt.title(title, fontsize=18)\n",
    "ax.set_xscale('log')\n",
    "plt.xlim([0.00001,0.1])\n",
    "plt.ylim([-0.01,0.025])\n",
    "plt.yticks([-0.01,0,0.01,0.02])\n",
    "vals = ax.get_yticks()\n",
    "decimals = [str(round(x*100,6)).split('.')[1] for x in vals]\n",
    "if len([x for x in decimals if x != '0']) > 0:\n",
    "    number_of_places = np.max([len(x) for x in decimals])\n",
    "else:\n",
    "    number_of_places = np.max([len(x) for x in decimals])-1\n",
    "if number_of_places == 0:\n",
    "    ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "elif number_of_places == 1:\n",
    "    ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "elif number_of_places == 2:\n",
    "    ax.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "else:\n",
    "    raise Exception('Number of decimal places = %d' % number_of_places)\n",
    "plt.xlabel(r'Metabolite Production [mmol gDW$^{-1}$ hr$^{-1}$]', fontsize=16)\n",
    "plt.ylabel(r'$\\Delta$P', fontsize=20)\n",
    "plt.savefig('%s/%s/%s/shap_values/example/met2.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrow plot\n",
    "p1 = np.sum([x for i,x in enumerate(shap_) if features_[i].split(' # ')[0]=='clinical_noninvasive' and features_[i]!='clinical_noninvasive # COHORT'])\n",
    "p2 = np.sum([x for i,x in enumerate(shap_) if features_[i]=='clinical_noninvasive # COHORT'])\n",
    "p3 = np.sum([x for i,x in enumerate(shap_) if features_[i].split(' # ')[0]=='objscreen_blood'])\n",
    "shap_ = [p1,p2,p3]\n",
    "features_ = ['Other Non-Invasive Clinical','Cancer Type','Blood Metabolites']\n",
    "colors_ = ['#FFD700','#e6c200','#DC143C']\n",
    "\n",
    "# initialize figure\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig = plt.figure(figsize=(6,2))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# number line\n",
    "plt.plot([0,1],[0,0],'k-',linewidth=1)\n",
    "for x in [0,0.5,1]:\n",
    "    plt.plot([x,x],[-0.1,0.1],'k-',linewidth=1)\n",
    "plt.plot([expected_value[a],expected_value[a]],[-0.3,0.1],'k--',linewidth=1)\n",
    "plt.text(0,0.1,'0%', horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=12)\n",
    "plt.text(0.5,0.1,'50%', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "plt.text(1,0.1,'100%', horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=12)\n",
    "plt.text(expected_value[a],0.1,'%0.1f%%' % (expected_value[a]*100), horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "plt.text(expected_value[a],0.3,'Prior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "\n",
    "# data\n",
    "current_value = expected_value[a]\n",
    "y_value = -0.3\n",
    "for i in range(len(features_)):\n",
    "    plt.arrow(current_value, y_value, shap_[i], 0, width=0.05, head_length= 0.2*np.abs(shap_[i]), length_includes_head=True, color=colors_[i])\n",
    "    if shap_[i] < 0: \n",
    "        plt.text(current_value+0.005, y_value, '%s  ' % features_[i], horizontalalignment='right', verticalalignment='center', fontsize=12)\n",
    "        plt.text(current_value+shap_[i]/2.3, y_value+0.04, '  %0.1f%%' % (shap_[i]*100), horizontalalignment='left', fontsize=8)\n",
    "    else:\n",
    "        plt.text(current_value-0.005, y_value, '%s' % features_[i], horizontalalignment='right', verticalalignment='center', fontsize=12)\n",
    "        plt.text(current_value+shap_[i]/2.3, y_value+0.04, '+%0.1f%%' % (shap_[i]*100), horizontalalignment='center', fontsize=8)\n",
    "    current_value += shap_[i]\n",
    "    y_value += -0.3\n",
    "\n",
    "# end line\n",
    "plt.plot([current_value,current_value],[y_value+0.15,0.1],'k--',linewidth=1)\n",
    "plt.plot([0.5,0.5],[y_value+0.15,0.1],'k--',linewidth=1)\n",
    "if current_value < 0.5:\n",
    "    plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#5bc2ae', fontsize=12, weight='bold')\n",
    "else:\n",
    "    plt.text(current_value,0.1,'%0.1f%%' % (current_value*100), horizontalalignment='center', verticalalignment='bottom', color='#d93f20', fontsize=12, weight='bold')\n",
    "plt.text(current_value,0.3,'Posterior', horizontalalignment='center', verticalalignment='bottom', color='black', fontsize=12)\n",
    "\n",
    "# limits\n",
    "plt.xlim(-0.02,1.02)\n",
    "plt.ylim(y_value-0.05, 0.8)\n",
    "plt.axis('off')\n",
    "plt.savefig('%s/%s/%s/shap_values/example/arrows.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset contribution\n",
    "contribution_names = ['Other Non-Invasive Clinical','Cancer Type','Blood Metabolites']\n",
    "contribution_values = [np.sum([np.abs(x) for i,x in enumerate(shap_) if features_[i].split(' # ')[0]=='clinical_noninvasive' and features_[i]!='clinical_noninvasive # COHORT']), np.sum([np.abs(x) for i,x in enumerate(shap_) if features_[i]=='clinical_noninvasive # COHORT']),  np.sum([np.abs(x) for i,x in enumerate(shap_) if features_[i].split(' # ')[0]=='objscreen_blood'])]\n",
    "contribution_values = [x/np.sum(contribution_values) for x in contribution_values]\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "patches, texts, autotexts = plt.pie(contribution_values, colors=['#FFD700','#e6c200','#DC143C'], autopct='%1.1f%%')\n",
    "for i in range(len(texts)):\n",
    "    texts[i].set_fontsize(26)\n",
    "    autotexts[i].set_fontsize(26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,sample in enumerate(samples):\n",
    "    if y_vector[a]==1:\n",
    "    \n",
    "        # get nonzero shap and feature values\n",
    "        features_ = [feature for feature in merged_features if shap_value.loc[sample][feature] != 0]\n",
    "        shap_ = shap_value.loc[sample][features_].tolist()\n",
    "        original_ = X_matrix.loc[sample][features_].tolist()\n",
    "\n",
    "        # convert numerical values to strings\n",
    "        for j in range(len(original_)):\n",
    "            if not type(original_[j]) == str:\n",
    "                if type(original_[j]) == bool:\n",
    "                    original_[j] = str(original_[j])\n",
    "                elif not np.isnan(original_[j]):\n",
    "                    if original_[j] == int(original_[j]):\n",
    "                        original_[j] = str(int(original_[j]))\n",
    "                    else:\n",
    "                        original_[j] = str(original_[j])\n",
    "\n",
    "        # order features based on absolute shap value\n",
    "        sort_index = np.argsort(np.abs(shap_))[::-1]\n",
    "        features_ = [features_[i] for i in sort_index]\n",
    "        shap_ = [shap_[i] for i in sort_index]\n",
    "        original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "        # only keep top cumulative 95%\n",
    "        shap_normalized = [np.abs(x)/np.sum(np.abs(shap_)) for x in shap_]\n",
    "        threshold_index = [i for i,x in enumerate(np.cumsum(shap_normalized)) if x<0.95][-1]\n",
    "        features_ = features_[:threshold_index]\n",
    "        shap_ = shap_[:threshold_index]\n",
    "        original_ = original_[:threshold_index]\n",
    "\n",
    "        # order features based on shap value\n",
    "        sort_index = np.argsort(shap_)\n",
    "        features_ = [features_[i] for i in sort_index]\n",
    "        shap_ = [shap_[i] for i in sort_index]\n",
    "        original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "        # remove imputed features\n",
    "        sort_index = [i for i,x in enumerate(original_) if not pd.isna(x)]\n",
    "        features_ = [features_[i] for i in sort_index]\n",
    "        shap_ = [shap_[i] for i in sort_index]\n",
    "        original_ = [original_[i] for i in sort_index]\n",
    "\n",
    "        p1 = np.sum([x for i,x in enumerate(shap_) if features_[i].split(' # ')[0]=='clinical_noninvasive' and features_[i]!='clinical_noninvasive # COHORT'])\n",
    "        p2 = np.sum([x for i,x in enumerate(shap_) if features_[i]=='clinical_noninvasive # COHORT'])\n",
    "        p3 = np.sum([x for i,x in enumerate(shap_) if features_[i].split(' # ')[0]=='objscreen_blood'])\n",
    "        if p3>(p1+p2) and (expected_value[a]+p1+p2+p3)>0.5 and (expected_value[a]+p1+p2)<0.5:\n",
    "            print(sample, X_matrix.at[sample,'clinical_noninvasive # COHORT'], p1, p2, p3, (expected_value[a]+p1+p2), (expected_value[a]+p1+p2+p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_stacker:\n",
    "    \n",
    "    # load stacker data from each split\n",
    "    stacker_samples = []\n",
    "    stacker_weights_ = []\n",
    "    stacker_performance = []\n",
    "    for i in range(n_splits):\n",
    "        with open('%s/%s/stacker_%d.pickle' % (folder_name, dataset_name, i+1) ,'rb') as f:\n",
    "            #X_test, X_test_all, y_test, test_predictions, testing_pred, weights = pickle.load(f)\n",
    "            X_test, X_test_all, y_test, y_pred, test_predictions, weights, test_best_classifier, bst = pickle.load(f)\n",
    "        for j,sample in enumerate(X_test[0].index.tolist()):\n",
    "            if sample in stacker_samples:\n",
    "                for k,dataset in enumerate(individual_datasets):\n",
    "                    stacker_weights_[stacker_samples.index(sample)][k].append(weights[j,k])\n",
    "                stacker_performance[stacker_samples.index(sample)].append(stacker_performance_weights[i])\n",
    "            else:\n",
    "                stacker_samples.append(sample)\n",
    "                stacker_weights_.append([])\n",
    "                for k,dataset in enumerate(individual_datasets):\n",
    "                    stacker_weights_[-1].append([weights[j,k]])\n",
    "                stacker_performance.append([stacker_performance_weights[i]])\n",
    "                \n",
    "    # weighted average of stacker predictions\n",
    "    stacker_weights = []\n",
    "    for i in range(len(stacker_samples)):\n",
    "        stacker_weights.append([])\n",
    "        for j in range(len(individual_datasets)):\n",
    "            stacker_weights[-1].append(np.average(stacker_weights_[i][j], weights=stacker_performance[i]))\n",
    "            \n",
    "    # plot of stacker weights\n",
    "    stacker_weights_grouped = []\n",
    "    for i in range(len(individual_datasets)):\n",
    "        stacker_weights_grouped.append([x[i] for x in stacker_weights])\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rc('xtick', labelsize=20)\n",
    "    plt.rc('ytick', labelsize=20)\n",
    "    fig = plt.figure(figsize=(3*len(individual_datasets),10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    fig = sns.boxplot(data=stacker_weights_grouped, whis=1, fliersize=0, palette=colors)\n",
    "    fig = sns.swarmplot(data=stacker_weights_grouped, color='black', alpha=0.25)\n",
    "    plt.xlim([-0.5,len(individual_datasets)-0.5])\n",
    "    fig.set(xticklabels=individual_datasets_labels)\n",
    "    fig.spines['right'].set_visible(False)\n",
    "    fig.spines['top'].set_visible(False)\n",
    "    plt.ylabel('Stacker Weight', fontsize=20)\n",
    "    plt.savefig('%s/%s/%s/stacker/summary/weights.png' % (folder_name, dataset_name, output_folder), bbox_inches='tight', dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate based on clinical factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analyze_stacker:\n",
    "    \n",
    "    # separate based on clinical factors\n",
    "    if 'clinical' in individual_datasets:\n",
    "        \n",
    "        # initialize feature and pvalue lists\n",
    "        separation_feature = []\n",
    "        separation_pvalue = []\n",
    "        separation_feature_values = []\n",
    "        separation_weight_factors = []\n",
    "        \n",
    "        # iterate over clinical factors\n",
    "        for feature in merged_features:\n",
    "            if feature.split(' # ')[0] == 'clinical':\n",
    "                \n",
    "                # categorical\n",
    "                if feature.split(' # ')[1] not in ['AGE','PACK YEARS','ALCOHOL PER DAY']:\n",
    "                    \n",
    "                    # if one-hot encoded\n",
    "                    if feature in categorical_conversion:\n",
    "                        \n",
    "                        # unique values\n",
    "                        unique_values = sorted(categorical_conversion[feature])\n",
    "                        \n",
    "                        # contingency table\n",
    "                        weight_factors = [[[] for dataset in individual_datasets] for value in unique_values]                \n",
    "                        for i,sample in enumerate(stacker_samples):\n",
    "                            for j,value in enumerate(unique_values):\n",
    "                                if X_matrix.at[sample, '%s | %s' % (feature, value)] == 1:\n",
    "                                    for k in range(len(individual_datasets)):\n",
    "                                        weight_factors[j][k].append(stacker_weights[i][k])\n",
    "                        separation_feature.append(feature.split(' # ')[1])\n",
    "                        for i,value in enumerate(unique_values):\n",
    "                            separation_feature_values.append('%s | %s' % (feature, value))\n",
    "                            separation_weight_factors.append(weight_factors[i])\n",
    "                        if len(individual_datasets) > 2:\n",
    "                            separation_pvalue.append([])\n",
    "                            for i in range(len(individual_datasets)):\n",
    "                                separation_pvalue[-1].append(f_oneway(*[weight_factors[j][i] for j in range(len(unique_values))]).pvalue)\n",
    "                        else:\n",
    "                            separation_pvalue.append(f_oneway(*[weight_factors[j][0] for j in range(len(unique_values))]).pvalue)\n",
    "                             \n",
    "                    # if not one-hot encoded\n",
    "                    else:\n",
    "                        \n",
    "                        # get all unique values\n",
    "                        unique_values = sorted(list(set([x for x in X_matrix[feature].values.tolist() if not pd.isna(x)])))\n",
    "                        \n",
    "                        # contingency table\n",
    "                        weight_factors = [[[] for dataset in individual_datasets] for value in unique_values]    \n",
    "                        for i,sample in enumerate(stacker_samples):\n",
    "                            if not pd.isna(X_matrix.at[sample,feature]):\n",
    "                                for k in range(len(individual_datasets)):\n",
    "                                    weight_factors[unique_values.index(X_matrix.at[sample,feature])][k].append(stacker_weights[i][k])\n",
    "                        separation_feature.append(feature.split(' # ')[1])\n",
    "                        for i,value in enumerate(unique_values):\n",
    "                            separation_feature_values.append('%s | %s' % (feature, value))\n",
    "                            separation_weight_factors.append(weight_factors[i])\n",
    "                        if len(individual_datasets) > 2:\n",
    "                            separation_pvalue.append([])\n",
    "                            for i in range(len(individual_datasets)):\n",
    "                                separation_pvalue[-1].append(f_oneway(*[weight_factors[j][i] for j in range(len(unique_values))]).pvalue)\n",
    "                        else:\n",
    "                            separation_pvalue.append(f_oneway(*[weight_factors[j][0] for j in range(len(unique_values))]).pvalue)\n",
    "                            \n",
    "        # find top feature value for each dataset\n",
    "        for i,dataset in enumerate(individual_datasets):\n",
    "            \n",
    "            # get mean dataset weight\n",
    "            weight_mean = []\n",
    "            weight_values = []\n",
    "            feature_value = []\n",
    "            for j,value in enumerate(separation_feature_values):\n",
    "                if len(separation_weight_factors[j][i]) >= 3:\n",
    "                    feature_value.append(value.split(' # ')[1])\n",
    "                    weight_mean.append(np.mean(separation_weight_factors[j][i]))\n",
    "                    weight_values.append(separation_weight_factors[j][i])\n",
    "                    \n",
    "            # sort weights\n",
    "            sort_index = np.argsort(weight_mean)[::-1]\n",
    "            weight_mean = [weight_mean[a] for a in sort_index]\n",
    "            weight_values = [weight_values[a] for a in sort_index]\n",
    "            feature_value = [feature_value[a] for a in sort_index]\n",
    "            \n",
    "            # plot\n",
    "            N = 20\n",
    "            plt.rcParams['font.family'] = 'Arial'\n",
    "            plt.rc('xtick', labelsize=12)\n",
    "            plt.rc('ytick', labelsize=20)\n",
    "            fig = plt.figure(figsize=(20,5))\n",
    "            ax = fig.add_subplot(111)\n",
    "            fig = sns.boxplot(data=weight_values[:N], whis=1, fliersize=0, palette=[colors[i] for a in range(N)])\n",
    "            fig = sns.swarmplot(data=weight_values[:N], color='black', alpha=0.25)\n",
    "            fig.set_xticklabels(labels=feature_value[:N], rotation=90)\n",
    "            plt.xlim(-1,N)\n",
    "            plt.ylabel(r'Stacker Weight', fontsize=20)\n",
    "            plt.title('Top %d Features - %s' % (N, individual_datasets_labels[i]), fontsize=24)\n",
    "            plt.savefig('%s/%s/%s/stacker/summary/top%d_%s.png' % (folder_name, dataset_name, output_folder, N, dataset), bbox_inches='tight', dpi=400)\n",
    "            plt.close()\n",
    "            \n",
    "        # find top feature value for all combined except clinical\n",
    "        if (len(individual_datasets) >= 3) and ('clinical' in individual_datasets):\n",
    "            \n",
    "            # get mean dataset weight\n",
    "            weight_mean = []\n",
    "            weight_values = []\n",
    "            feature_value = []\n",
    "            for j,value in enumerate(separation_feature_values):\n",
    "                if len(separation_weight_factors[j][0]) >= 3:\n",
    "                    feature_value.append(value.split(' # ')[1])\n",
    "                    for i, dataset in enumerate(individual_datasets):\n",
    "                        if dataset != 'clinical':\n",
    "                            if len(weight_mean) < len(feature_value):\n",
    "                                weight_mean.append(np.mean(separation_weight_factors[j][i]))\n",
    "                                weight_values.append(np.array(separation_weight_factors[j][i]))\n",
    "                            else:\n",
    "                                weight_mean[-1] += np.mean(separation_weight_factors[j][i])\n",
    "                                weight_values[-1] = np.add(weight_values[-1],separation_weight_factors[j][i])\n",
    "                    \n",
    "            # sort weights\n",
    "            sort_index = np.argsort(weight_mean)[::-1]\n",
    "            weight_mean = [weight_mean[a] for a in sort_index]\n",
    "            weight_values = [weight_values[a] for a in sort_index]\n",
    "            feature_value = [feature_value[a] for a in sort_index]\n",
    "            \n",
    "            # plot\n",
    "            N = 20\n",
    "            plt.rcParams['font.family'] = 'Arial'\n",
    "            plt.rc('xtick', labelsize=12)\n",
    "            plt.rc('ytick', labelsize=20)\n",
    "            fig = plt.figure(figsize=(20,5))\n",
    "            ax = fig.add_subplot(111)\n",
    "            fig = sns.boxplot(data=weight_values[:N], whis=1, fliersize=0, palette=['#D3D3D3' for a in range(N)])\n",
    "            fig = sns.swarmplot(data=weight_values[:N], color='black', alpha=0.25)\n",
    "            fig.set_xticklabels(labels=feature_value[:N], rotation=90)\n",
    "            plt.xlim(-1,N)\n",
    "            plt.ylabel(r'Stacker Weight', fontsize=20)\n",
    "            plt.title('Top %d Features - All Datasets but Clinical' % (N), fontsize=24)\n",
    "            plt.savefig('%s/%s/%s/stacker/summary/top%d_allbutclinical.png' % (folder_name, dataset_name, output_folder, N), bbox_inches='tight', dpi=400)\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
