{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'compareclassifiers_logisticL1'\n",
    "datasets = [['clinical','gene_all','mutation_onehot_all']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_trainvalidation_test = 20\n",
    "k_train_validation = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgBoost stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hyperopt_iterations = 2**8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 1\n",
    "\n",
    "# implement seed\n",
    "random.seed(seed_)\n",
    "np.random.seed(seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_function(parameters):\n",
    "\n",
    "    # load data\n",
    "    with open('_files/data___.pickle', 'rb') as f:\n",
    "        X_train, y_train, X_validation, y_validation = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    # calculate performance\n",
    "    mean_validation_weightedlogloss = hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters)\n",
    "    \n",
    "    # return performance\n",
    "    return {'loss':mean_validation_weightedlogloss, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters):\n",
    "    \n",
    "    # initialize validation performance\n",
    "    validation_weightedlogloss = []\n",
    "    \n",
    "    # iterate over number of training/validation splits\n",
    "    for i in range(k_train_validation):\n",
    "\n",
    "        # parameters\n",
    "        param = parameters.copy()\n",
    "        param['penalty'] = 'l1'\n",
    "        param['random_state'] = seed_\n",
    "        param['solver'] = 'saga'\n",
    "\n",
    "        # train on training\n",
    "        clf = LogisticRegression(**param).fit(X_train[i], y_train[i])\n",
    "        \n",
    "        # evaluate on validation\n",
    "        y_pred = clf.predict_proba(X_validation[i])\n",
    "        \n",
    "        # remove nan\n",
    "        keep_index = [j for j in range(len(y_pred)) if len([x for x in y_pred[j] if not pd.isna(x)])==len(y_pred[0])]\n",
    "        y_val_ = np.array([y_validation[i][j] for j in keep_index])\n",
    "        y_pred_ = np.array([y_pred[j] for j in keep_index])\n",
    "        \n",
    "        # log loss\n",
    "        weightedlogloss = log_loss(y_val_, y_pred_, labels=list(range(len(datasets[a]))))\n",
    "        validation_weightedlogloss.append(weightedlogloss)\n",
    "    \n",
    "    # average validation performance over all folds\n",
    "    mean_validation_weightedlogloss = np.mean(validation_weightedlogloss) + np.std(validation_weightedlogloss)/np.sqrt(len(validation_weightedlogloss))\n",
    "    return mean_validation_weightedlogloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_y(y):\n",
    "    \n",
    "    dummy_y_ = [[],[]]\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            dummy_y_[0].append(1)\n",
    "            dummy_y_[1].append(0)\n",
    "        else:\n",
    "            dummy_y_[0].append(0)\n",
    "            dummy_y_[1].append(1)\n",
    "    dummy_y_ = np.array(dummy_y_).T\n",
    "    return dummy_y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset names\n",
    "dataset_names = []\n",
    "for a in range(len(datasets)):\n",
    "    dataset_names.append('+'.join(datasets[a]))\n",
    "    os.mkdir('%s/%s' % (output_folder, dataset_names[a]))\n",
    "    \n",
    "# performance files\n",
    "performance_files_weightedlogloss = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_weightedlogloss.to_csv('%s/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "performance_files_balancedaccuracy = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_balancedaccuracy.to_csv('%s/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "performance_files_auroc = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_auroc.to_csv('%s/auroc.csv' % output_folder)\n",
    "\n",
    "performance_files_sensitivity_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_sensitivity_50.to_csv('%s/sensitivity_50.csv' % output_folder)\n",
    "\n",
    "performance_files_specificity_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_specificity_50.to_csv('%s/specificity_50.csv' % output_folder)\n",
    "\n",
    "performance_files_ppv_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_ppv_50.to_csv('%s/ppv_50.csv' % output_folder)\n",
    "\n",
    "performance_files_npv_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_npv_50.to_csv('%s/npv_50.csv' % output_folder)\n",
    "\n",
    "performance_files_optimal_threshold = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_optimal_threshold.to_csv('%s/optimal_threshold.csv' % output_folder)\n",
    "\n",
    "performance_files_sensitivity_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_sensitivity_optimal.to_csv('%s/sensitivity_optimal.csv' % output_folder)\n",
    "\n",
    "performance_files_specificity_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_specificity_optimal.to_csv('%s/specificity_optimal.csv' % output_folder)\n",
    "\n",
    "performance_files_ppv_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_ppv_optimal.to_csv('%s/ppv_optimal.csv' % output_folder)\n",
    "\n",
    "performance_files_npv_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_npv_optimal.to_csv('%s/npv_optimal.csv' % output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "DATASET: clinical+gene_all+mutation_onehot_all\n",
      "-------------------------\n",
      "Split 1\n",
      "clinical: 336/732 - 45.90% - 64 features\n",
      "gene_all: 55/732 - 7.51% - 588 features\n",
      "mutation_onehot_all: 341/732 - 46.58% - 16028 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:33:32<00:00, 145.50s/it, best loss: 1.0814347573462422]\n",
      "Split 2\n",
      "clinical: 351/732 - 47.95% - 68 features\n",
      "gene_all: 64/732 - 8.74% - 517 features\n",
      "mutation_onehot_all: 317/732 - 43.31% - 20407 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [12:24:49<00:00, 130.55s/it, best loss: 1.0890240762242993]\n",
      "Split 3\n",
      "clinical: 343/732 - 46.86% - 67 features\n",
      "gene_all: 67/732 - 9.15% - 576 features\n",
      "mutation_onehot_all: 322/732 - 43.99% - 17314 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [10:53:20<00:00, 204.58s/it, best loss: 1.0901792808737427]\n",
      "Split 4\n",
      "clinical: 334/732 - 45.63% - 60 features\n",
      "gene_all: 78/732 - 10.66% - 578 features\n",
      "mutation_onehot_all: 320/732 - 43.72% - 15020 features\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [9:36:12<00:00, 97.72s/it, best loss: 1.0897435613884063]\n",
      "Split 5\n",
      "clinical: 337/732 - 46.04% - 73 features\n",
      "gene_all: 62/732 - 8.47% - 493 features\n",
      "mutation_onehot_all: 333/732 - 45.49% - 903 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [44:34<00:00, 13.43s/it, best loss: 1.0058517989330953]\n",
      "Split 6\n",
      "clinical: 342/732 - 46.72% - 71 features\n",
      "gene_all: 76/732 - 10.38% - 535 features\n",
      "mutation_onehot_all: 314/732 - 42.90% - 26688 features\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [15:53:54<00:00, 179.27s/it, best loss: 1.091200335082187]\n",
      "Split 7\n",
      "clinical: 323/732 - 44.13% - 57 features\n",
      "gene_all: 83/732 - 11.34% - 449 features\n",
      "mutation_onehot_all: 326/732 - 44.54% - 26420 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [21:30:27<00:00, 266.07s/it, best loss: 1.0921227431343274]\n",
      "Split 8\n",
      "clinical: 346/732 - 47.27% - 58 features\n",
      "gene_all: 76/732 - 10.38% - 473 features\n",
      "mutation_onehot_all: 310/732 - 42.35% - 17179 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [10:24:44<00:00, 172.64s/it, best loss: 1.0925109281059633]\n",
      "Split 9\n",
      "clinical: 332/732 - 45.36% - 71 features\n",
      "gene_all: 73/732 - 9.97% - 576 features\n",
      "mutation_onehot_all: 327/732 - 44.67% - 16330 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:10:08<00:00, 176.05s/it, best loss: 1.0784558953889058]\n",
      "Split 10\n",
      "clinical: 359/732 - 49.04% - 42 features\n",
      "gene_all: 62/732 - 8.47% - 512 features\n",
      "mutation_onehot_all: 311/732 - 42.49% - 16239 features\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [9:46:05<00:00, 105.20s/it, best loss: 1.082183614692194]\n",
      "Split 11\n",
      "clinical: 333/732 - 45.49% - 72 features\n",
      "gene_all: 61/732 - 8.33% - 445 features\n",
      "mutation_onehot_all: 338/732 - 46.17% - 18882 features\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:17:59<00:00, 181.22s/it, best loss: 1.089906131355388]\n",
      "Split 12\n",
      "clinical: 358/732 - 48.91% - 64 features\n",
      "gene_all: 66/732 - 9.02% - 530 features\n",
      "mutation_onehot_all: 308/732 - 42.08% - 16804 features\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [10:21:38<00:00, 95.00s/it, best loss: 1.089157856267223]\n",
      "Split 13\n",
      "clinical: 338/732 - 46.17% - 62 features\n",
      "gene_all: 83/732 - 11.34% - 528 features\n",
      "mutation_onehot_all: 311/732 - 42.49% - 15810 features\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [9:45:42<00:00, 137.25s/it, best loss: 1.0913083309227787]\n",
      "Split 14\n",
      "clinical: 335/732 - 45.77% - 71 features\n",
      "gene_all: 81/732 - 11.07% - 636 features\n",
      "mutation_onehot_all: 316/732 - 43.17% - 18172 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:22:47<00:00, 180.16s/it, best loss: 1.0862465585050778]\n",
      "Split 15\n",
      "clinical: 343/732 - 46.86% - 91 features\n",
      "gene_all: 78/732 - 10.66% - 580 features\n",
      "mutation_onehot_all: 311/732 - 42.49% - 17689 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [14:12:35<00:00, 180.68s/it, best loss: 1.0789998218368229]\n",
      "Split 16\n",
      "clinical: 358/732 - 48.91% - 44 features\n",
      "gene_all: 49/732 - 6.69% - 549 features\n",
      "mutation_onehot_all: 325/732 - 44.40% - 114 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [22:10<00:00,  5.76s/it, best loss: 0.8852417519273614]\n",
      "Split 17\n",
      "clinical: 365/732 - 49.86% - 77 features\n",
      "gene_all: 79/732 - 10.79% - 571 features\n",
      "mutation_onehot_all: 288/732 - 39.34% - 26794 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [15:09:20<00:00, 178.01s/it, best loss: 1.0932054144460666]\n",
      "Split 18\n",
      "clinical: 332/732 - 45.36% - 54 features\n",
      "gene_all: 81/732 - 11.07% - 415 features\n",
      "mutation_onehot_all: 319/732 - 43.58% - 17225 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [12:00:11<00:00, 160.30s/it, best loss: 1.0904624883795704]\n",
      "Split 19\n",
      "clinical: 354/732 - 48.36% - 57 features\n",
      "gene_all: 51/732 - 6.97% - 508 features\n",
      "mutation_onehot_all: 327/732 - 44.67% - 18189 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:00:55<00:00, 173.65s/it, best loss: 1.0822562552197943]\n",
      "Split 20\n",
      "clinical: 339/732 - 46.31% - 114 features\n",
      "gene_all: 81/732 - 11.07% - 462 features\n",
      "mutation_onehot_all: 312/732 - 42.62% - 20816 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [13:36:34<00:00, 157.97s/it, best loss: 1.0904546710947858]\n"
     ]
    }
   ],
   "source": [
    "# iterate over datasets\n",
    "for a in range(len(datasets)):\n",
    "    print('-------------------------')\n",
    "    print('DATASET: %s' % dataset_names[a])\n",
    "    print('-------------------------')\n",
    "    \n",
    "    # iterate over number of training+validation/testing splits\n",
    "    for b in range(n_splits_trainvalidation_test):\n",
    "    \n",
    "        print('Split %d' % (b+1))\n",
    "        \n",
    "        # load categorical conversion from each dataset\n",
    "        features = []\n",
    "        merged_features = []\n",
    "        with open('_datasets/%s.pickle' % datasets[a][0], 'rb') as f:\n",
    "            X_matrix, y_vector, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "        features.append(['%s # %s' % (datasets[a][0], x) for x in X_matrix.columns.tolist()])\n",
    "        categorical_conversion = {}\n",
    "        for key in categorical_conversion_old:\n",
    "            categorical_conversion['%s # %s' % (datasets[a][0], key)] = categorical_conversion_old[key]\n",
    "        if len(categorical_conversion) > 0:\n",
    "            merged_features.append([])\n",
    "            for feature in features[0]:\n",
    "                if feature.split(' | ')[0] not in categorical_conversion:\n",
    "                    merged_features[-1].append(feature)\n",
    "                elif feature.split(' | ')[0] not in merged_features[-1]:\n",
    "                    merged_features[-1].append(feature.split(' | ')[0])\n",
    "        else:\n",
    "            merged_features.append(features[0].copy())\n",
    "        for c in range(1,len(datasets[a])):\n",
    "            with open('_datasets/%s.pickle' % datasets[a][c], 'rb') as f:\n",
    "                X_matrix_, y_vector_, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "            features.append(['%s # %s' % (datasets[a][c], x) for x in X_matrix_.columns.tolist()])\n",
    "            categorical_conversion_ = {}\n",
    "            for key in categorical_conversion_old:\n",
    "                categorical_conversion_['%s # %s' % (datasets[a][c], key)] = categorical_conversion_old[key]\n",
    "            categorical_conversion = {**categorical_conversion, **categorical_conversion_}\n",
    "            if len(categorical_conversion_) > 0:\n",
    "                merged_features.append([])\n",
    "                for feature in features[c]:\n",
    "                    if feature.split(' | ')[0] not in categorical_conversion_:\n",
    "                        merged_features[-1].append(feature)\n",
    "                    elif feature.split(' | ')[0] not in merged_features[-1]:\n",
    "                        merged_features[-1].append(feature.split(' | ')[0])\n",
    "            else:\n",
    "                merged_features.append(features[c].copy())\n",
    "        \n",
    "        # load results from individual datasets\n",
    "        validation_X = []\n",
    "        validation_predictions = []\n",
    "        X_test = []\n",
    "        y_pred = []\n",
    "        clf = []\n",
    "        for c in range(len(datasets[a])):\n",
    "            with open('%s/_individual/%s/iter_%d.pickle' % (output_folder, datasets[a][c], b+1), 'rb') as f:\n",
    "                validation_X_, validation_y, validation_predictions_, X_test_, y_test, y_pred_, clf_ = pickle.load(f)\n",
    "            validation_X.append(validation_X_)\n",
    "            validation_predictions.append(validation_predictions_)\n",
    "            X_test.append(X_test_)\n",
    "            y_pred.append(y_pred_[:,1])\n",
    "            clf.append(clf_)\n",
    "\n",
    "        # combine predictions\n",
    "        validation_predictions = np.concatenate([x.reshape(-1,1) for x in validation_predictions], axis=1)\n",
    "        test_predictions = np.concatenate([x.reshape(-1,1) for x in y_pred], axis=1)\n",
    "        \n",
    "        # if more than one dataset\n",
    "        if len(datasets[a]) > 1:\n",
    "        \n",
    "            # validation best classifier\n",
    "            validation_best_classifier = []\n",
    "            for i in range(len(validation_y)):\n",
    "                if validation_y[i] == 0:\n",
    "                    validation_best_classifier.append(np.argmin(validation_predictions[i,:]))\n",
    "                elif validation_y[i] == 1:\n",
    "                    validation_best_classifier.append(np.argmax(validation_predictions[i,:]))\n",
    "            validation_best_classifier = np.array(validation_best_classifier)\n",
    "           \n",
    "            # subset features that are in any of the models\n",
    "            features_in_models = []\n",
    "            for c in range(len(clf)):\n",
    "                importance = clf[c].coef_[0]\n",
    "                features_in_models.extend([features[c][i] for i in range(len(features[c])) if importance[i] != 0])\n",
    "                print('%s: %d/%d - %0.2f%% - %d features' % (datasets[a][c], len([x for x in validation_best_classifier if x==c]), len(validation_best_classifier), len([x for x in validation_best_classifier if x==c])/len(validation_best_classifier)*100, len([features[c][i] for i in range(len(features[c])) if importance[i] != 0])))\n",
    "\n",
    "            # get combined dataset with features in models\n",
    "            X_trainvalidation = pd.concat(validation_X, axis=1)[features_in_models]\n",
    "            y_trainvalidation = validation_best_classifier.copy()\n",
    "            X_test = pd.concat(X_test, axis=1)[features_in_models]\n",
    "            \n",
    "            # separate full\n",
    "            sep1_index = []\n",
    "            sep2_index = []\n",
    "            skf = StratifiedKFold(n_splits=k_train_validation, shuffle=True, random_state=seed_)\n",
    "            for sep1_, sep2_ in skf.split(X_trainvalidation, y_trainvalidation):\n",
    "                sep1_index.append(list(sep1_))\n",
    "                sep2_index.append(list(sep2_))\n",
    "            X_train = []\n",
    "            X_validation = []\n",
    "            y_train = []\n",
    "            y_validation = []\n",
    "            for c in range(k_train_validation):\n",
    "                X_train.append(X_trainvalidation.iloc[sep1_index[c]])\n",
    "                X_validation.append(X_trainvalidation.iloc[sep2_index[c]])\n",
    "                y_train.append(y_trainvalidation[sep1_index[c]])\n",
    "                y_validation.append(y_trainvalidation[sep2_index[c]])\n",
    "                \n",
    "            # impute train+validation/testing\n",
    "            imp = SimpleImputer()\n",
    "            columns_to_add_back = [i for i,x in enumerate(X_trainvalidation.mean()) if pd.isna(x)]\n",
    "            X_trainvalidation = imp.fit_transform(X_trainvalidation)\n",
    "            for c in sorted(columns_to_add_back)[::-1]:\n",
    "                X_trainvalidation = np.hstack((X_trainvalidation[:,:c], np.zeros(X_trainvalidation.shape[0]).reshape(-1,1), X_trainvalidation[:,c:]))\n",
    "            X_test = imp.transform(X_test)\n",
    "            for c in sorted(columns_to_add_back)[::-1]:\n",
    "                X_test = np.hstack((X_test[:,:c], np.zeros(X_test.shape[0]).reshape(-1,1), X_test[:,c:]))\n",
    "            scaler = StandardScaler()\n",
    "            X_trainvalidation = scaler.fit_transform(X_trainvalidation)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # impute train/validation\n",
    "            for c in range(k_train_validation):\n",
    "                imp = SimpleImputer()\n",
    "                columns_to_add_back = [i for i,x in enumerate(X_train[c].mean()) if pd.isna(x)]\n",
    "                X_train[c] = imp.fit_transform(X_train[c])\n",
    "                for d in sorted(columns_to_add_back)[::-1]:\n",
    "                    X_train[c] = np.hstack((X_train[c][:,:d], np.zeros(X_train[c].shape[0]).reshape(-1,1), X_train[c][:,d:]))\n",
    "                X_validation[c] = imp.transform(X_validation[c])\n",
    "                for d in sorted(columns_to_add_back)[::-1]:\n",
    "                    X_validation[c] = np.hstack((X_validation[c][:,:d], np.zeros(X_validation[c].shape[0]).reshape(-1,1), X_validation[c][:,d:]))\n",
    "                scaler = StandardScaler()\n",
    "                X_train[c] = scaler.fit_transform(X_train[c])\n",
    "                X_validation[c] = scaler.transform(X_validation[c])\n",
    "            \n",
    "            # xgb parameter values\n",
    "            parameters = {\n",
    "            'C': hp.loguniform('C', np.log(1e-3), np.log(1e3)),\n",
    "                     }\n",
    "            \n",
    "            # save info for hyperopt\n",
    "            with open('_files/data___.pickle','wb') as f:\n",
    "                pickle.dump([X_train, y_train, X_validation, y_validation], f)\n",
    "\n",
    "            # hyperopt to find best parameters\n",
    "            trials = Trials()\n",
    "            best = fmin(hyperopt_function, parameters, algo=tpe.suggest, max_evals=n_hyperopt_iterations, trials=trials, rstate=np.random.RandomState(seed_), verbose=0, show_progressbar=True)\n",
    "            \n",
    "            # parameters\n",
    "            param = {'penalty':'l1', 'random_state':seed_, 'solver':'saga', 'C':best['C']}\n",
    "\n",
    "            # train on training\n",
    "            clf = LogisticRegression(**param).fit(X_trainvalidation, y_trainvalidation)\n",
    "\n",
    "            # evaluate on validation\n",
    "            weights = clf.predict_proba(X_test)\n",
    "            \n",
    "            # calculate stacker performance - log loss\n",
    "            test_best_classifier = []\n",
    "            for i in range(len(y_test)):\n",
    "                if y_test[i] == 0:\n",
    "                    test_best_classifier.append(np.argmin(test_predictions[i,:]))\n",
    "                elif y_test[i] == 1:\n",
    "                    test_best_classifier.append(np.argmax(test_predictions[i,:]))\n",
    "            test_best_classifier = np.array(test_best_classifier)\n",
    "            \n",
    "            # get predictions on test set\n",
    "            y_pred = []\n",
    "            for i in range(len(y_test)):\n",
    "                y_pred.append(np.average(test_predictions[i,:], weights=weights[i,:]))\n",
    "            y_pred = np.array(y_pred)\n",
    "            \n",
    "        # if only one dataset\n",
    "        else:\n",
    "            y_pred = y_pred[0]\n",
    "            weights = np.array([1 for x in y_test]).reshape(-1,1)\n",
    "        \n",
    "        # remove nan\n",
    "        keep_index = [i for i,x in enumerate(y_pred) if not pd.isna(x)]\n",
    "        samples_keep = [X_test_.index.tolist()[i] for i in keep_index]\n",
    "        y_test = np.array([y_test[i] for i in keep_index])\n",
    "        y_pred = np.array([y_pred[i] for i in keep_index])\n",
    "        \n",
    "        # save predictions\n",
    "        with open('%s/%s/predictions_%d.pickle' % (output_folder,dataset_names[a],b+1) ,'wb') as f:\n",
    "            pickle.dump([samples_keep, y_test, y_pred], f)\n",
    "        \n",
    "        # calculate test performance - weighted log loss\n",
    "        pos_weight = len([x for x in y_test if x==0])/len([x for x in y_test if x==1])\n",
    "        sample_weights = [pos_weight if x==1 else 1 for x in y_test]\n",
    "        performance = log_loss(y_test, y_pred, sample_weight=sample_weights)\n",
    "        performance_files_weightedlogloss.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_weightedlogloss.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_weightedlogloss.at['STERR', dataset_names[a]] = np.nanstd(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_weightedlogloss.to_csv('%s/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - balanced accuracy\n",
    "        y_pred_ = [1 if x>=0.5 else 0 for x in y_pred]\n",
    "        performance = balanced_accuracy_score(y_test, y_pred_)\n",
    "        performance_files_balancedaccuracy.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_balancedaccuracy.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_balancedaccuracy.at['STERR', dataset_names[a]] = np.nanstd(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_balancedaccuracy.to_csv('%s/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - auroc\n",
    "        y_pred_ = np.concatenate((np.array([1-x for x in y_pred]).reshape(-1,1), y_pred.reshape(-1,1)), axis=1)\n",
    "        performance = roc_auc_score(dummy_y(y_test), y_pred_)\n",
    "        performance_files_auroc.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_auroc.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_auroc.at['STERR', dataset_names[a]] = np.nanstd(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_auroc.to_csv('%s/auroc.csv' % output_folder)\n",
    "        \n",
    "        # tp, tn, fp, fn\n",
    "        tp = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]>0.5])\n",
    "        fp = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]>0.5])\n",
    "        tn = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]<0.5])\n",
    "        fn = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]<0.5])\n",
    "        \n",
    "        # calculate test performance - sensitivity - 50\n",
    "        performance = tp/(tp+fn)\n",
    "        performance_files_sensitivity_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_sensitivity_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_sensitivity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_sensitivity_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_sensitivity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_sensitivity_50.to_csv('%s/sensitivity_50.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - specificity - 50\n",
    "        performance = tn/(tn+fp)\n",
    "        performance_files_specificity_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_specificity_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_specificity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_specificity_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_specificity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_specificity_50.to_csv('%s/specificity_50.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - ppv - 50\n",
    "        performance = tp/(tp+fp)\n",
    "        performance_files_ppv_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_ppv_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_ppv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_ppv_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_ppv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_ppv_50.to_csv('%s/ppv_50.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - npv - 50\n",
    "        performance = tn/(tn+fn)\n",
    "        performance_files_npv_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_npv_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_npv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_npv_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_npv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_npv_50.to_csv('%s/npv_50.csv' % output_folder)\n",
    "        \n",
    "        # optimal threshold\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        youden = [(1-fpr[i])+tpr[i] for i in range(len(thresholds))]\n",
    "        top_index = []\n",
    "        top_threshold = []\n",
    "        for i in range(len(youden)):\n",
    "            if youden[i] == np.max(youden):\n",
    "                top_index.append(i)\n",
    "                top_threshold.append(thresholds[i])\n",
    "        distance_from_50 = [np.abs(x-0.5) for x in top_threshold]\n",
    "        top_index = top_index[np.argmin(distance_from_50)]\n",
    "        optimal_threshold = top_threshold[np.argmin(distance_from_50)]\n",
    "        performance_files_optimal_threshold.at['split_%d' % (b+1), dataset_names[a]] = optimal_threshold\n",
    "        performance_files_optimal_threshold.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_optimal_threshold.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_optimal_threshold.at['STERR', dataset_names[a]] = np.nanstd(performance_files_optimal_threshold.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_optimal_threshold.to_csv('%s/optimal_threshold.csv' % output_folder)\n",
    "        \n",
    "        # tp, tn, fp, fn\n",
    "        tp = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]>optimal_threshold])\n",
    "        fp = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]>optimal_threshold])\n",
    "        tn = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]<optimal_threshold])\n",
    "        fn = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]<optimal_threshold])\n",
    "        \n",
    "        # calculate test performance - sensitivity - optimal\n",
    "        performance = tp/(tp+fn)\n",
    "        performance_files_sensitivity_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_sensitivity_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_sensitivity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_sensitivity_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_sensitivity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_sensitivity_optimal.to_csv('%s/sensitivity_optimal.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - specificity - optimal\n",
    "        performance = tn/(tn+fp)\n",
    "        performance_files_specificity_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_specificity_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_specificity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_specificity_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_specificity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_specificity_optimal.to_csv('%s/specificity_optimal.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - ppv - optimal\n",
    "        performance = tp/(tp+fp)\n",
    "        performance_files_ppv_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_ppv_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_ppv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_ppv_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_ppv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_ppv_optimal.to_csv('%s/ppv_optimal.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - npv - optimal\n",
    "        performance = tn/(tn+fn)\n",
    "        performance_files_npv_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_npv_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_npv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_npv_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_npv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_npv_optimal.to_csv('%s/npv_optimal.csv' % output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
