{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_folder = 'compareclassifiers_logisticL1'\n",
    "output_folder = 'compareclassifiers_logisticL1_'\n",
    "\n",
    "if os.path.isdir(output_folder):\n",
    "    raise Exception('Already run!')\n",
    "else:\n",
    "    os.mkdir(output_folder)\n",
    "    os.mkdir('%s/_individual' % output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets = ['clinical','gene_all','mutation_onehot_all']\n",
    "datasets = ['mutation_onehot_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hyperopt_iterations = 2**8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_trainvalidation_test = 20\n",
    "test_size = 0.2\n",
    "k_train_validation = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 1\n",
    "\n",
    "# implement seed\n",
    "random.seed(seed_)\n",
    "np.random.seed(seed_)\n",
    "\n",
    "# timestamp\n",
    "timestamp = 1912111625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_function(parameters):\n",
    "\n",
    "    # load data\n",
    "    with open('_files/data_%s.pickle' % timestamp, 'rb') as f:\n",
    "        X_train, y_train, X_validation, y_validation = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    # calculate performance\n",
    "    mean_validation_weightedlogloss, validation_pred = hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters)\n",
    "    gc.collect()\n",
    "    \n",
    "    # save validation predictions if best classifier\n",
    "    with open('_files/validation_%s.pickle' % timestamp,'rb') as f:\n",
    "        best_weightedlogloss = pickle.load(f)\n",
    "    if mean_validation_weightedlogloss < best_weightedlogloss:\n",
    "        with open('_files/validation_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump(mean_validation_weightedlogloss, f)\n",
    "        with open('_files/validation_xgb_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump(validation_pred, f)\n",
    "    \n",
    "    # return performance\n",
    "    return {'loss':mean_validation_weightedlogloss, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters):\n",
    "    \n",
    "    # initialize validation performance and predictions\n",
    "    validation_weightedlogloss = []\n",
    "    validation_pred = []\n",
    "    \n",
    "    # iterate over number of training/validation splits\n",
    "    for i in range(k_train_validation):\n",
    "        \n",
    "        # positive weight\n",
    "        pos_weight = len([x for x in y_train[i] if x==0])/len([x for x in y_train[i] if x==1])\n",
    "\n",
    "        # parameters\n",
    "        param = parameters.copy()\n",
    "        param['penalty'] = 'l1'\n",
    "        param['class_weight'] = {0:1, 1:pos_weight}\n",
    "        param['random_state'] = seed_\n",
    "        param['solver'] = 'saga'\n",
    "\n",
    "        # train on training\n",
    "        clf = LogisticRegression(**param).fit(X_train[i], y_train[i])\n",
    "\n",
    "        # evaluate on validation\n",
    "        y_pred = clf.predict_proba(X_validation[i])\n",
    "        pos_weight = len([x for x in y_validation[i] if x==0])/len([x for x in y_validation[i] if x==1])\n",
    "        sample_weights = [pos_weight if x==1 else 1 for x in y_validation[i]]\n",
    "        weightedlogloss = log_loss(y_validation[i], y_pred, sample_weight=sample_weights)\n",
    "        validation_weightedlogloss.append(weightedlogloss)\n",
    "        validation_pred.append(y_pred)\n",
    "    \n",
    "    # average validation performance over all folds\n",
    "    mean_validation_weightedlogloss = np.mean(validation_weightedlogloss) + np.std(validation_weightedlogloss)/np.sqrt(len(validation_weightedlogloss))\n",
    "    return mean_validation_weightedlogloss, np.concatenate(validation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_y(y):\n",
    "    \n",
    "    dummy_y_ = [[],[]]\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            dummy_y_[0].append(1)\n",
    "            dummy_y_[1].append(0)\n",
    "        else:\n",
    "            dummy_y_[0].append(0)\n",
    "            dummy_y_[1].append(1)\n",
    "    dummy_y_ = np.array(dummy_y_).T\n",
    "    return dummy_y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over datasets\n",
    "for a in range(len(datasets)):\n",
    "    \n",
    "    # folder\n",
    "    os.mkdir('%s/_individual/%s' % (output_folder, datasets[a]))\n",
    "    \n",
    "# performance files\n",
    "performance_files_weightedlogloss = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=datasets)\n",
    "performance_files_weightedlogloss.to_csv('%s/_individual/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "performance_files_balancedaccuracy = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=datasets)\n",
    "performance_files_balancedaccuracy.to_csv('%s/_individual/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "performance_files_auroc = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=datasets)\n",
    "performance_files_auroc.to_csv('%s/_individual/auroc.csv' % output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "DATASET: mutation_onehot_all\n",
      "-------------------------\n",
      "Split 13\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:11:48<00:00, 112.63s/it, best loss: 0.6841568848809787]\n",
      "Split 14\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:23:53<00:00, 118.76s/it, best loss: 0.6802834661910446]\n",
      "Split 15\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:28:27<00:00, 124.94s/it, best loss: 0.6757981589974479]\n",
      "Split 16\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [6:36:32<00:00, 87.07s/it, best loss: 0.687837241006791]\n",
      "Split 17\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:31:06<00:00, 126.18s/it, best loss: 0.6769914195420857]\n",
      "Split 18\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:13:06<00:00, 117.96s/it, best loss: 0.6817270765791169]\n",
      "Split 19\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:20:33<00:00, 120.81s/it, best loss: 0.6847450859018336]\n",
      "Split 20\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [8:46:43<00:00, 140.22s/it, best loss: 0.6728685474704934]\n"
     ]
    }
   ],
   "source": [
    "# iterate over datasets\n",
    "for a in range(len(datasets)):\n",
    "    print('-------------------------')\n",
    "    print('DATASET: %s' % datasets[a])\n",
    "    print('-------------------------')\n",
    "    \n",
    "    # load dataset\n",
    "    with open('_datasets/%s.pickle' % datasets[a], 'rb') as f:\n",
    "        X_matrix, y_vector, categorical_conversion = pickle.load(f, encoding='latin1')\n",
    "    X_matrix.columns = ['%s # %s' % (datasets[a], feature) for feature in X_matrix.columns.tolist()]\n",
    "\n",
    "    # divide train+validation from testing\n",
    "    trainvalidation_index = []\n",
    "    test_index = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits_trainvalidation_test, test_size=test_size, random_state=seed_)\n",
    "    for trainvalidation_, test_ in sss.split(X_matrix, y_vector):\n",
    "        trainvalidation_index.append(list(trainvalidation_))\n",
    "        test_index.append(list(test_))\n",
    "\n",
    "    # iterate over number of training+validation/testing splits\n",
    "    #for b in range(n_splits_trainvalidation_test):\n",
    "    for b in range(n_splits_trainvalidation_test)[12:]:\n",
    "        print('Split %d' % (b+1))\n",
    "        \n",
    "        # separate train+validation and testing\n",
    "        X_trainvalidation = X_matrix.iloc[trainvalidation_index[b],]\n",
    "        X_test = X_matrix.iloc[test_index[b],]\n",
    "        y_trainvalidation = y_vector[trainvalidation_index[b]]\n",
    "        y_test = y_vector[test_index[b]]\n",
    "        \n",
    "        # divide train from validation\n",
    "        train_index = []\n",
    "        validation_index = []\n",
    "        skf = StratifiedKFold(n_splits=k_train_validation, shuffle=True, random_state=seed_)\n",
    "        for train_, validation_ in skf.split(X_trainvalidation, y_trainvalidation):\n",
    "            train_index.append(list(train_))\n",
    "            validation_index.append(list(validation_))\n",
    "\n",
    "        # separate train and validation\n",
    "        X_train = []\n",
    "        X_validation = []\n",
    "        y_train = []\n",
    "        y_validation = []\n",
    "        for c in range(k_train_validation):\n",
    "            X_train.append(X_trainvalidation.iloc[train_index[c],])\n",
    "            X_validation.append(X_trainvalidation.iloc[validation_index[c],])\n",
    "            y_train.append(y_trainvalidation[train_index[c]])\n",
    "            y_validation.append(y_trainvalidation[validation_index[c]])\n",
    "            \n",
    "        # impute train+validation/testing\n",
    "        X_trainvalidation_ = X_trainvalidation.copy()\n",
    "        X_test_ = X_test.copy()\n",
    "        imp = SimpleImputer()\n",
    "        columns_to_add_back = [i for i,x in enumerate(X_trainvalidation.mean()) if pd.isna(x)]\n",
    "        X_trainvalidation = imp.fit_transform(X_trainvalidation)\n",
    "        for c in sorted(columns_to_add_back)[::-1]:\n",
    "            X_trainvalidation = np.hstack((X_trainvalidation[:,:c], np.zeros(X_trainvalidation.shape[0]).reshape(-1,1), X_trainvalidation[:,c:]))\n",
    "        X_test = imp.transform(X_test)\n",
    "        for c in sorted(columns_to_add_back)[::-1]:\n",
    "            X_test = np.hstack((X_test[:,:c], np.zeros(X_test.shape[0]).reshape(-1,1), X_test[:,c:]))\n",
    "        scaler = StandardScaler()\n",
    "        X_trainvalidation = scaler.fit_transform(X_trainvalidation)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # impute train/validation\n",
    "        X_train_ = X_train.copy()\n",
    "        X_validation_ = X_validation.copy()\n",
    "        for c in range(k_train_validation):\n",
    "            imp = SimpleImputer()\n",
    "            columns_to_add_back = [i for i,x in enumerate(X_train[c].mean()) if pd.isna(x)]\n",
    "            X_train[c] = imp.fit_transform(X_train[c])\n",
    "            for d in sorted(columns_to_add_back)[::-1]:\n",
    "                X_train[c] = np.hstack((X_train[c][:,:d], np.zeros(X_train[c].shape[0]).reshape(-1,1), X_train[c][:,d:]))\n",
    "            X_validation[c] = imp.transform(X_validation[c])\n",
    "            for d in sorted(columns_to_add_back)[::-1]:\n",
    "                X_validation[c] = np.hstack((X_validation[c][:,:d], np.zeros(X_validation[c].shape[0]).reshape(-1,1), X_validation[c][:,d:]))\n",
    "            scaler = StandardScaler()\n",
    "            X_train[c] = scaler.fit_transform(X_train[c])\n",
    "            X_validation[c] = scaler.transform(X_validation[c])\n",
    "            \n",
    "        # initialize test predictions\n",
    "        classifier_test_predictions = []\n",
    "\n",
    "        # xgb parameters\n",
    "        parameters = {\n",
    "            'C': hp.loguniform('C', np.log(1e-3), np.log(1e3)),\n",
    "                     }\n",
    "\n",
    "        # save info for hyperopt\n",
    "        with open('_files/validation_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump(1000., f)\n",
    "        with open('_files/data_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump([X_train, y_train, X_validation, y_validation], f)\n",
    "\n",
    "        # hyperopt to find best parameters\n",
    "        trials = Trials()\n",
    "        best = fmin(hyperopt_function, parameters, algo=tpe.suggest, max_evals=n_hyperopt_iterations, trials=trials, rstate=np.random.RandomState(seed_), verbose=0, show_progressbar=True)      \n",
    "            \n",
    "        # create classifier using best parameters\n",
    "        pos_weight = len([x for x in y_trainvalidation if x==0])/len([x for x in y_trainvalidation if x==1])\n",
    "            \n",
    "        # parameters\n",
    "        param = {'penalty':'l1', 'class_weight':{0:1, 1:pos_weight}, 'random_state':seed_, 'solver':'saga', 'C':best['C']}\n",
    "\n",
    "        # train on training\n",
    "        clf = LogisticRegression(**param).fit(X_trainvalidation, y_trainvalidation)\n",
    "\n",
    "        # evaluate on validation\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "        # calculate test performance - weighted log loss\n",
    "        pos_weight = len([x for x in y_test if x==0])/len([x for x in y_test if x==1])\n",
    "        sample_weights = [pos_weight if x==1 else 1 for x in y_test]\n",
    "        performance = log_loss(y_test, y_pred, sample_weight=sample_weights)\n",
    "        performance_files_weightedlogloss.at['split_%d' % (b+1), datasets[a]] = performance\n",
    "        performance_files_weightedlogloss.at['MEAN', datasets[a]] = np.nanmean(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())\n",
    "        performance_files_weightedlogloss.at['STERR', datasets[a]] = np.nanstd(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_weightedlogloss.to_csv('%s/_individual/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - balanced accuracy\n",
    "        y_pred_ = [1 if x>=0.5 else 0 for x in y_pred[:,1]]\n",
    "        performance = balanced_accuracy_score(y_test, y_pred_)\n",
    "        performance_files_balancedaccuracy.at['split_%d' % (b+1), datasets[a]] = performance\n",
    "        performance_files_balancedaccuracy.at['MEAN', datasets[a]] = np.nanmean(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())\n",
    "        performance_files_balancedaccuracy.at['STERR', datasets[a]] = np.nanstd(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_balancedaccuracy.to_csv('%s/_individual/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - auroc\n",
    "        performance = roc_auc_score(dummy_y(y_test), y_pred)\n",
    "        performance_files_auroc.at['split_%d' % (b+1), datasets[a]] = performance\n",
    "        performance_files_auroc.at['MEAN', datasets[a]] = np.nanmean(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())\n",
    "        performance_files_auroc.at['STERR', datasets[a]] = np.nanstd(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_auroc.to_csv('%s/_individual/auroc.csv' % output_folder)\n",
    "\n",
    "        # load validation predictions\n",
    "        with open('_files/validation_xgb_%s.pickle' % timestamp,'rb') as f:\n",
    "            validation_predictions = pickle.load(f)\n",
    "        validation_y = np.concatenate(y_validation)\n",
    "        validation_X = pd.concat(X_validation_)\n",
    "\n",
    "        # save results\n",
    "        with open('%s/_individual/%s/iter_%d.pickle' % (output_folder, datasets[a], b+1), 'wb') as f:\n",
    "            pickle.dump([validation_X, validation_y, validation_predictions, X_test_, y_test, y_pred, clf], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
