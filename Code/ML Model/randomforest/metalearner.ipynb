{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'compareclassifiers_randomforest'\n",
    "datasets = [['clinical','gene_all','mutation_onehot_all']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_trainvalidation_test = 20\n",
    "k_train_validation = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgBoost stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hyperopt_iterations = 2**8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 1\n",
    "\n",
    "# implement seed\n",
    "random.seed(seed_)\n",
    "np.random.seed(seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_function(parameters):\n",
    "\n",
    "    # load data\n",
    "    with open('_files/data___.pickle', 'rb') as f:\n",
    "        X_train, y_train, X_validation, y_validation = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    # calculate performance\n",
    "    mean_validation_weightedlogloss = hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters)\n",
    "    \n",
    "    # return performance\n",
    "    return {'loss':mean_validation_weightedlogloss, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters):\n",
    "    \n",
    "    # initialize validation performance\n",
    "    validation_weightedlogloss = []\n",
    "    \n",
    "    # iterate over number of training/validation splits\n",
    "    for i in range(k_train_validation):\n",
    "\n",
    "        # parameters\n",
    "        param = parameters.copy()\n",
    "        param['random_state'] = seed_\n",
    "        param['n_estimators'] = int(param['n_estimators'])\n",
    "\n",
    "        # train on training\n",
    "        clf = RandomForestClassifier(**param).fit(X_train[i], y_train[i])\n",
    "\n",
    "        # evaluate on validation\n",
    "        y_pred = clf.predict_proba(X_validation[i])\n",
    "        weightedlogloss = log_loss(y_validation[i], y_pred, labels=list(range(len(datasets[a]))))\n",
    "        validation_weightedlogloss.append(weightedlogloss)\n",
    "    \n",
    "    # average validation performance over all folds\n",
    "    mean_validation_weightedlogloss = np.mean(validation_weightedlogloss) + np.std(validation_weightedlogloss)/np.sqrt(len(validation_weightedlogloss))\n",
    "    return mean_validation_weightedlogloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_y(y):\n",
    "    \n",
    "    dummy_y_ = [[],[]]\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            dummy_y_[0].append(1)\n",
    "            dummy_y_[1].append(0)\n",
    "        else:\n",
    "            dummy_y_[0].append(0)\n",
    "            dummy_y_[1].append(1)\n",
    "    dummy_y_ = np.array(dummy_y_).T\n",
    "    return dummy_y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset names\n",
    "dataset_names = []\n",
    "for a in range(len(datasets)):\n",
    "    dataset_names.append('+'.join(datasets[a]))\n",
    "    os.mkdir('%s/%s' % (output_folder, dataset_names[a]))\n",
    "    \n",
    "# performance files\n",
    "performance_files_weightedlogloss = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_weightedlogloss.to_csv('%s/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "performance_files_balancedaccuracy = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_balancedaccuracy.to_csv('%s/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "performance_files_auroc = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_auroc.to_csv('%s/auroc.csv' % output_folder)\n",
    "\n",
    "\n",
    "performance_files_sensitivity_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_sensitivity_50.to_csv('%s/sensitivity_50.csv' % output_folder)\n",
    "\n",
    "performance_files_specificity_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_specificity_50.to_csv('%s/specificity_50.csv' % output_folder)\n",
    "\n",
    "performance_files_ppv_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_ppv_50.to_csv('%s/ppv_50.csv' % output_folder)\n",
    "\n",
    "performance_files_npv_50 = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_npv_50.to_csv('%s/npv_50.csv' % output_folder)\n",
    "\n",
    "performance_files_optimal_threshold = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_optimal_threshold.to_csv('%s/optimal_threshold.csv' % output_folder)\n",
    "\n",
    "performance_files_sensitivity_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_sensitivity_optimal.to_csv('%s/sensitivity_optimal.csv' % output_folder)\n",
    "\n",
    "performance_files_specificity_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_specificity_optimal.to_csv('%s/specificity_optimal.csv' % output_folder)\n",
    "\n",
    "performance_files_ppv_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_ppv_optimal.to_csv('%s/ppv_optimal.csv' % output_folder)\n",
    "\n",
    "performance_files_npv_optimal = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=dataset_names)\n",
    "performance_files_npv_optimal.to_csv('%s/npv_optimal.csv' % output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "DATASET: clinical+gene_all+mutation_onehot_all\n",
      "-------------------------\n",
      "Split 1\n",
      "clinical: 243/732 - 33.20% - 305 features\n",
      "gene_all: 122/732 - 16.67% - 718 features\n",
      "mutation_onehot_all: 367/732 - 50.14% - 203 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:37<00:00,  4.40it/s, best loss: 1.0094394386045817]\n",
      "Split 2\n",
      "clinical: 309/732 - 42.21% - 169 features\n",
      "gene_all: 78/732 - 10.66% - 831 features\n",
      "mutation_onehot_all: 345/732 - 47.13% - 2948 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [02:22<00:00,  3.21it/s, best loss: 0.9561093541900673]\n",
      "Split 3\n",
      "clinical: 298/732 - 40.71% - 237 features\n",
      "gene_all: 85/732 - 11.61% - 144 features\n",
      "mutation_onehot_all: 349/732 - 47.68% - 110 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [05:58<00:00,  1.00s/it, best loss: 0.9693852758411627]\n",
      "Split 4\n",
      "clinical: 294/732 - 40.16% - 268 features\n",
      "gene_all: 99/732 - 13.52% - 1099 features\n",
      "mutation_onehot_all: 339/732 - 46.31% - 256 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:13<00:00,  1.53s/it, best loss: 0.9942233867615113]\n",
      "Split 5\n",
      "clinical: 241/732 - 32.92% - 212 features\n",
      "gene_all: 127/732 - 17.35% - 20 features\n",
      "mutation_onehot_all: 364/732 - 49.73% - 6 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [02:40<00:00,  1.59it/s, best loss: 1.0168207355080334]\n",
      "Split 6\n",
      "clinical: 265/732 - 36.20% - 316 features\n",
      "gene_all: 126/732 - 17.21% - 28 features\n",
      "mutation_onehot_all: 341/732 - 46.58% - 147 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [06:14<00:00,  2.07s/it, best loss: 1.0271176956438355]\n",
      "Split 7\n",
      "clinical: 238/732 - 32.51% - 237 features\n",
      "gene_all: 142/732 - 19.40% - 80 features\n",
      "mutation_onehot_all: 352/732 - 48.09% - 456 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:46<00:00,  1.13it/s, best loss: 1.0355516784188243]\n",
      "Split 8\n",
      "clinical: 295/732 - 40.30% - 291 features\n",
      "gene_all: 118/732 - 16.12% - 3 features\n",
      "mutation_onehot_all: 319/732 - 43.58% - 4959 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:47<00:00,  2.71it/s, best loss: 1.0232920228648237]\n",
      "Split 9\n",
      "clinical: 255/732 - 34.84% - 302 features\n",
      "gene_all: 149/732 - 20.36% - 345 features\n",
      "mutation_onehot_all: 328/732 - 44.81% - 139 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [01:56<00:00,  2.92it/s, best loss: 1.0486907555532512]\n",
      "Split 10\n",
      "clinical: 302/732 - 41.26% - 323 features\n",
      "gene_all: 109/732 - 14.89% - 331 features\n",
      "mutation_onehot_all: 321/732 - 43.85% - 792 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:05<00:00,  1.99it/s, best loss: 1.0106584192732546]\n",
      "Split 11\n",
      "clinical: 301/732 - 41.12% - 333 features\n",
      "gene_all: 86/732 - 11.75% - 259 features\n",
      "mutation_onehot_all: 345/732 - 47.13% - 2691 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:40<00:00,  2.10s/it, best loss: 0.9728776630719219]\n",
      "Split 12\n",
      "clinical: 315/732 - 43.03% - 107 features\n",
      "gene_all: 90/732 - 12.30% - 730 features\n",
      "mutation_onehot_all: 327/732 - 44.67% - 13 features\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:43<00:00,  1.24s/it, best loss: 0.980658460354724]\n",
      "Split 13\n",
      "clinical: 334/732 - 45.63% - 105 features\n",
      "gene_all: 93/732 - 12.70% - 19 features\n",
      "mutation_onehot_all: 305/732 - 41.67% - 1350 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [05:52<00:00,  1.22s/it, best loss: 0.9863931861217491]\n",
      "Split 14\n",
      "clinical: 310/732 - 42.35% - 312 features\n",
      "gene_all: 87/732 - 11.89% - 142 features\n",
      "mutation_onehot_all: 335/732 - 45.77% - 1463 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:18<00:00,  2.55it/s, best loss: 0.9760816862676519]\n",
      "Split 15\n",
      "clinical: 303/732 - 41.39% - 321 features\n",
      "gene_all: 95/732 - 12.98% - 338 features\n",
      "mutation_onehot_all: 334/732 - 45.63% - 454 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [05:13<00:00,  2.08it/s, best loss: 0.9878199013001429]\n",
      "Split 16\n",
      "clinical: 309/732 - 42.21% - 319 features\n",
      "gene_all: 85/732 - 11.61% - 443 features\n",
      "mutation_onehot_all: 338/732 - 46.17% - 91 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [05:52<00:00,  2.23s/it, best loss: 0.9712678909657534]\n",
      "Split 17\n",
      "clinical: 320/732 - 43.72% - 307 features\n",
      "gene_all: 98/732 - 13.39% - 164 features\n",
      "mutation_onehot_all: 314/732 - 42.90% - 2378 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [01:41<00:00,  2.96it/s, best loss: 0.9907419404792824]\n",
      "Split 18\n",
      "clinical: 301/732 - 41.12% - 192 features\n",
      "gene_all: 94/732 - 12.84% - 300 features\n",
      "mutation_onehot_all: 337/732 - 46.04% - 1385 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [05:29<00:00,  1.38s/it, best loss: 0.9860213280409937]\n",
      "Split 19\n",
      "clinical: 253/732 - 34.56% - 287 features\n",
      "gene_all: 153/732 - 20.90% - 2 features\n",
      "mutation_onehot_all: 326/732 - 44.54% - 446 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [01:20<00:00,  6.38it/s, best loss: 1.0543254288165855]\n",
      "Split 20\n",
      "clinical: 291/732 - 39.75% - 322 features\n",
      "gene_all: 118/732 - 16.12% - 7 features\n",
      "mutation_onehot_all: 323/732 - 44.13% - 446 features\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [01:36<00:00,  2.95it/s, best loss: 1.0202763925284948]\n"
     ]
    }
   ],
   "source": [
    "# iterate over datasets\n",
    "for a in range(len(datasets)):\n",
    "    print('-------------------------')\n",
    "    print('DATASET: %s' % dataset_names[a])\n",
    "    print('-------------------------')\n",
    "    \n",
    "    # iterate over number of training+validation/testing splits\n",
    "    for b in range(n_splits_trainvalidation_test):\n",
    "    \n",
    "        print('Split %d' % (b+1))\n",
    "        \n",
    "        # load categorical conversion from each dataset\n",
    "        features = []\n",
    "        merged_features = []\n",
    "        with open('_datasets/%s.pickle' % datasets[a][0], 'rb') as f:\n",
    "            X_matrix, y_vector, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "        features.append(['%s # %s' % (datasets[a][0], x) for x in X_matrix.columns.tolist()])\n",
    "        categorical_conversion = {}\n",
    "        for key in categorical_conversion_old:\n",
    "            categorical_conversion['%s # %s' % (datasets[a][0], key)] = categorical_conversion_old[key]\n",
    "        if len(categorical_conversion) > 0:\n",
    "            merged_features.append([])\n",
    "            for feature in features[0]:\n",
    "                if feature.split(' | ')[0] not in categorical_conversion:\n",
    "                    merged_features[-1].append(feature)\n",
    "                elif feature.split(' | ')[0] not in merged_features[-1]:\n",
    "                    merged_features[-1].append(feature.split(' | ')[0])\n",
    "        else:\n",
    "            merged_features.append(features[0].copy())\n",
    "        for c in range(1,len(datasets[a])):\n",
    "            with open('_datasets/%s.pickle' % datasets[a][c], 'rb') as f:\n",
    "                X_matrix_, y_vector_, categorical_conversion_old = pickle.load(f, encoding='latin1')\n",
    "            features.append(['%s # %s' % (datasets[a][c], x) for x in X_matrix_.columns.tolist()])\n",
    "            categorical_conversion_ = {}\n",
    "            for key in categorical_conversion_old:\n",
    "                categorical_conversion_['%s # %s' % (datasets[a][c], key)] = categorical_conversion_old[key]\n",
    "            categorical_conversion = {**categorical_conversion, **categorical_conversion_}\n",
    "            if len(categorical_conversion_) > 0:\n",
    "                merged_features.append([])\n",
    "                for feature in features[c]:\n",
    "                    if feature.split(' | ')[0] not in categorical_conversion_:\n",
    "                        merged_features[-1].append(feature)\n",
    "                    elif feature.split(' | ')[0] not in merged_features[-1]:\n",
    "                        merged_features[-1].append(feature.split(' | ')[0])\n",
    "            else:\n",
    "                merged_features.append(features[c].copy())\n",
    "        \n",
    "        # load results from individual datasets\n",
    "        validation_X = []\n",
    "        validation_predictions = []\n",
    "        X_test = []\n",
    "        y_pred = []\n",
    "        clf = []\n",
    "        for c in range(len(datasets[a])):\n",
    "            with open('%s/_individual/%s/iter_%d.pickle' % (output_folder, datasets[a][c], b+1), 'rb') as f:\n",
    "                validation_X_, validation_y, validation_predictions_, X_test_, y_test, y_pred_, clf_ = pickle.load(f)\n",
    "            validation_X.append(validation_X_)\n",
    "            validation_predictions.append(validation_predictions_)\n",
    "            X_test.append(X_test_)\n",
    "            y_pred.append(y_pred_[:,1])\n",
    "            clf.append(clf_)\n",
    "\n",
    "        # combine predictions\n",
    "        validation_predictions = np.concatenate([x.reshape(-1,1) for x in validation_predictions], axis=1)\n",
    "        test_predictions = np.concatenate([x.reshape(-1,1) for x in y_pred], axis=1)\n",
    "        \n",
    "        # if more than one dataset\n",
    "        if len(datasets[a]) > 1:\n",
    "        \n",
    "            # validation best classifier\n",
    "            validation_best_classifier = []\n",
    "            for i in range(len(validation_y)):\n",
    "                if validation_y[i] == 0:\n",
    "                    validation_best_classifier.append(np.argmin(validation_predictions[i,:]))\n",
    "                elif validation_y[i] == 1:\n",
    "                    validation_best_classifier.append(np.argmax(validation_predictions[i,:]))\n",
    "            validation_best_classifier = np.array(validation_best_classifier)\n",
    "           \n",
    "            # subset features that are in any of the models\n",
    "            features_in_models = []\n",
    "            for c in range(len(clf)):\n",
    "                importance = clf[c].feature_importances_\n",
    "                features_in_models.extend([features[c][i] for i in range(len(features[c])) if importance[i] != 0])\n",
    "                print('%s: %d/%d - %0.2f%% - %d features' % (datasets[a][c], len([x for x in validation_best_classifier if x==c]), len(validation_best_classifier), len([x for x in validation_best_classifier if x==c])/len(validation_best_classifier)*100, len([features[c][i] for i in range(len(features[c])) if importance[i] != 0])))\n",
    "\n",
    "            # get combined dataset with features in models\n",
    "            X_trainvalidation = pd.concat(validation_X, axis=1)[features_in_models]\n",
    "            y_trainvalidation = validation_best_classifier.copy()\n",
    "            X_test = pd.concat(X_test, axis=1)[features_in_models]\n",
    "            \n",
    "            # separate full\n",
    "            sep1_index = []\n",
    "            sep2_index = []\n",
    "            skf = StratifiedKFold(n_splits=k_train_validation, shuffle=True, random_state=seed_)\n",
    "            for sep1_, sep2_ in skf.split(X_trainvalidation, y_trainvalidation):\n",
    "                sep1_index.append(list(sep1_))\n",
    "                sep2_index.append(list(sep2_))\n",
    "            X_train = []\n",
    "            X_validation = []\n",
    "            y_train = []\n",
    "            y_validation = []\n",
    "            for c in range(k_train_validation):\n",
    "                X_train.append(X_trainvalidation.iloc[sep1_index[c]])\n",
    "                X_validation.append(X_trainvalidation.iloc[sep2_index[c]])\n",
    "                y_train.append(y_trainvalidation[sep1_index[c]])\n",
    "                y_validation.append(y_trainvalidation[sep2_index[c]])\n",
    "                \n",
    "            # impute train+validation/testing\n",
    "            imp = SimpleImputer()\n",
    "            columns_to_add_back = [i for i,x in enumerate(X_trainvalidation.mean()) if pd.isna(x)]\n",
    "            X_trainvalidation = imp.fit_transform(X_trainvalidation)\n",
    "            for c in sorted(columns_to_add_back)[::-1]:\n",
    "                X_trainvalidation = np.hstack((X_trainvalidation[:,:c], np.zeros(X_trainvalidation.shape[0]).reshape(-1,1), X_trainvalidation[:,c:]))\n",
    "            X_test = imp.transform(X_test)\n",
    "            for c in sorted(columns_to_add_back)[::-1]:\n",
    "                X_test = np.hstack((X_test[:,:c], np.zeros(X_test.shape[0]).reshape(-1,1), X_test[:,c:]))\n",
    "            scaler = StandardScaler()\n",
    "            X_trainvalidation = scaler.fit_transform(X_trainvalidation)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # impute train/validation\n",
    "            for c in range(k_train_validation):\n",
    "                imp = SimpleImputer()\n",
    "                columns_to_add_back = [i for i,x in enumerate(X_train[c].mean()) if pd.isna(x)]\n",
    "                X_train[c] = imp.fit_transform(X_train[c])\n",
    "                for d in sorted(columns_to_add_back)[::-1]:\n",
    "                    X_train[c] = np.hstack((X_train[c][:,:d], np.zeros(X_train[c].shape[0]).reshape(-1,1), X_train[c][:,d:]))\n",
    "                X_validation[c] = imp.transform(X_validation[c])\n",
    "                for d in sorted(columns_to_add_back)[::-1]:\n",
    "                    X_validation[c] = np.hstack((X_validation[c][:,:d], np.zeros(X_validation[c].shape[0]).reshape(-1,1), X_validation[c][:,d:]))\n",
    "                scaler = StandardScaler()\n",
    "                X_train[c] = scaler.fit_transform(X_train[c])\n",
    "                X_validation[c] = scaler.transform(X_validation[c])\n",
    "            \n",
    "            # xgb parameter values\n",
    "            criterion_options = ['gini','entropy']\n",
    "            max_features_options = ['sqrt','log2']\n",
    "            parameters = {\n",
    "                'n_estimators': scope.int(hp.qloguniform('n_estimators', np.log(1e0), np.log(1e3), 1)),\n",
    "                'criterion': hp.choice('criterion', criterion_options), \n",
    "                'max_depth': scope.int(hp.uniform('max_depth', 1, 11)),\n",
    "                'min_samples_split': hp.uniform('min_samples_split', 0., 1.),\n",
    "                'min_samples_leaf': hp.uniform('min_samples_leaf', 0., 0.5),\n",
    "                'max_features': hp.choice('max_features', max_features_options)\n",
    "                         }\n",
    "\n",
    "            # save info for hyperopt\n",
    "            with open('_files/data___.pickle','wb') as f:\n",
    "                pickle.dump([X_train, y_train, X_validation, y_validation], f)\n",
    "\n",
    "            # hyperopt to find best parameters\n",
    "            trials = Trials()\n",
    "            best = fmin(hyperopt_function, parameters, algo=tpe.suggest, max_evals=n_hyperopt_iterations, trials=trials, rstate=np.random.RandomState(seed_), verbose=0, show_progressbar=True)\n",
    "            \n",
    "            # parameters\n",
    "            param = {'random_state':seed_, 'n_estimators':int(best['n_estimators']), 'criterion':criterion_options[best['criterion']], 'max_depth':best['max_depth'], 'min_samples_split':best['min_samples_split'], 'min_samples_leaf':best['min_samples_leaf'], 'max_features':max_features_options[best['max_features']]}\n",
    "\n",
    "            # train on training\n",
    "            clf = RandomForestClassifier(**param).fit(X_trainvalidation, y_trainvalidation)\n",
    "\n",
    "            # evaluate on validation\n",
    "            weights = clf.predict_proba(X_test)\n",
    "            \n",
    "            # calculate stacker performance - log loss\n",
    "            test_best_classifier = []\n",
    "            for i in range(len(y_test)):\n",
    "                if y_test[i] == 0:\n",
    "                    test_best_classifier.append(np.argmin(test_predictions[i,:]))\n",
    "                elif y_test[i] == 1:\n",
    "                    test_best_classifier.append(np.argmax(test_predictions[i,:]))\n",
    "            test_best_classifier = np.array(test_best_classifier)\n",
    "            \n",
    "            # get predictions on test set\n",
    "            y_pred = []\n",
    "            for i in range(len(y_test)):\n",
    "                y_pred.append(np.average(test_predictions[i,:], weights=weights[i,:]))\n",
    "            y_pred = np.array(y_pred)\n",
    "            \n",
    "        # if only one dataset\n",
    "        else:\n",
    "            y_pred = y_pred[0]\n",
    "            weights = np.array([1 for x in y_test]).reshape(-1,1)\n",
    "        \n",
    "        # save predictions\n",
    "        with open('%s/%s/predictions_%d.pickle' % (output_folder,dataset_names[a],b+1) ,'wb') as f:\n",
    "            pickle.dump([X_test_.index.tolist(), y_test, y_pred], f)\n",
    "        \n",
    "        # calculate test performance - weighted log loss\n",
    "        pos_weight = len([x for x in y_test if x==0])/len([x for x in y_test if x==1])\n",
    "        sample_weights = [pos_weight if x==1 else 1 for x in y_test]\n",
    "        performance = log_loss(y_test, y_pred, sample_weight=sample_weights)\n",
    "        performance_files_weightedlogloss.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_weightedlogloss.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_weightedlogloss.at['STERR', dataset_names[a]] = np.nanstd(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_weightedlogloss.to_csv('%s/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - balanced accuracy\n",
    "        y_pred_ = [1 if x>=0.5 else 0 for x in y_pred]\n",
    "        performance = balanced_accuracy_score(y_test, y_pred_)\n",
    "        performance_files_balancedaccuracy.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_balancedaccuracy.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_balancedaccuracy.at['STERR', dataset_names[a]] = np.nanstd(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_balancedaccuracy.to_csv('%s/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - auroc\n",
    "        y_pred_ = np.concatenate((np.array([1-x for x in y_pred]).reshape(-1,1), y_pred.reshape(-1,1)), axis=1)\n",
    "        performance = roc_auc_score(dummy_y(y_test), y_pred_)\n",
    "        performance_files_auroc.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_auroc.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_auroc.at['STERR', dataset_names[a]] = np.nanstd(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_auroc.to_csv('%s/auroc.csv' % output_folder)\n",
    "        \n",
    "        # tp, tn, fp, fn\n",
    "        tp = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]>0.5])\n",
    "        fp = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]>0.5])\n",
    "        tn = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]<0.5])\n",
    "        fn = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]<0.5])\n",
    "        \n",
    "        # calculate test performance - sensitivity - 50\n",
    "        performance = tp/(tp+fn)\n",
    "        performance_files_sensitivity_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_sensitivity_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_sensitivity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_sensitivity_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_sensitivity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_sensitivity_50.to_csv('%s/sensitivity_50.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - specificity - 50\n",
    "        performance = tn/(tn+fp)\n",
    "        performance_files_specificity_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_specificity_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_specificity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_specificity_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_specificity_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_specificity_50.to_csv('%s/specificity_50.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - ppv - 50\n",
    "        performance = tp/(tp+fp)\n",
    "        performance_files_ppv_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_ppv_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_ppv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_ppv_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_ppv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_ppv_50.to_csv('%s/ppv_50.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - npv - 50\n",
    "        performance = tn/(tn+fn)\n",
    "        performance_files_npv_50.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_npv_50.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_npv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_npv_50.at['STERR', dataset_names[a]] = np.nanstd(performance_files_npv_50.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_npv_50.to_csv('%s/npv_50.csv' % output_folder)\n",
    "        \n",
    "        # optimal threshold\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        youden = [(1-fpr[i])+tpr[i] for i in range(len(thresholds))]\n",
    "        top_index = []\n",
    "        top_threshold = []\n",
    "        for i in range(len(youden)):\n",
    "            if youden[i] == np.max(youden):\n",
    "                top_index.append(i)\n",
    "                top_threshold.append(thresholds[i])\n",
    "        distance_from_50 = [np.abs(x-0.5) for x in top_threshold]\n",
    "        top_index = top_index[np.argmin(distance_from_50)]\n",
    "        optimal_threshold = top_threshold[np.argmin(distance_from_50)]\n",
    "        performance_files_optimal_threshold.at['split_%d' % (b+1), dataset_names[a]] = optimal_threshold\n",
    "        performance_files_optimal_threshold.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_optimal_threshold.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_optimal_threshold.at['STERR', dataset_names[a]] = np.nanstd(performance_files_optimal_threshold.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_optimal_threshold.to_csv('%s/optimal_threshold.csv' % output_folder)\n",
    "        \n",
    "        # tp, tn, fp, fn\n",
    "        tp = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]>optimal_threshold])\n",
    "        fp = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]>optimal_threshold])\n",
    "        tn = len([i for i in range(len(y_test)) if y_test[i]==0 and y_pred[i]<optimal_threshold])\n",
    "        fn = len([i for i in range(len(y_test)) if y_test[i]==1 and y_pred[i]<optimal_threshold])\n",
    "        \n",
    "        # calculate test performance - sensitivity - optimal\n",
    "        performance = tp/(tp+fn)\n",
    "        performance_files_sensitivity_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_sensitivity_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_sensitivity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_sensitivity_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_sensitivity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_sensitivity_optimal.to_csv('%s/sensitivity_optimal.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - specificity - optimal\n",
    "        performance = tn/(tn+fp)\n",
    "        performance_files_specificity_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_specificity_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_specificity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_specificity_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_specificity_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_specificity_optimal.to_csv('%s/specificity_optimal.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - ppv - optimal\n",
    "        performance = tp/(tp+fp)\n",
    "        performance_files_ppv_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_ppv_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_ppv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_ppv_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_ppv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_ppv_optimal.to_csv('%s/ppv_optimal.csv' % output_folder)\n",
    "        \n",
    "        # calculate test performance - npv - optimal\n",
    "        performance = tn/(tn+fn)\n",
    "        performance_files_npv_optimal.at['split_%d' % (b+1), dataset_names[a]] = performance\n",
    "        performance_files_npv_optimal.at['MEAN', dataset_names[a]] = np.nanmean(performance_files_npv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())\n",
    "        performance_files_npv_optimal.at['STERR', dataset_names[a]] = np.nanstd(performance_files_npv_optimal.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], dataset_names[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_npv_optimal.to_csv('%s/npv_optimal.csv' % output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
