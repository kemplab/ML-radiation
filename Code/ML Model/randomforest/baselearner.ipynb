{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'compareclassifiers_randomforest'\n",
    "\n",
    "if os.path.isdir(output_folder):\n",
    "    raise Exception('Already run!')\n",
    "else:\n",
    "    os.mkdir(output_folder)\n",
    "    os.mkdir('%s/_individual' % output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['clinical','gene_all','mutation_onehot_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hyperopt_iterations = 2**8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits_trainvalidation_test = 20\n",
    "test_size = 0.2\n",
    "k_train_validation = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ = 1\n",
    "\n",
    "# implement seed\n",
    "random.seed(seed_)\n",
    "np.random.seed(seed_)\n",
    "\n",
    "# timestamp\n",
    "timestamp = 1912131135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_function(parameters):\n",
    "\n",
    "    # load data\n",
    "    with open('_files/data_%s.pickle' % timestamp, 'rb') as f:\n",
    "        X_train, y_train, X_validation, y_validation = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    # calculate performance\n",
    "    mean_validation_weightedlogloss, validation_pred = hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters)\n",
    "    gc.collect()\n",
    "    \n",
    "    # save validation predictions if best classifier\n",
    "    with open('_files/validation_%s.pickle' % timestamp,'rb') as f:\n",
    "        best_weightedlogloss = pickle.load(f)\n",
    "    if mean_validation_weightedlogloss < best_weightedlogloss:\n",
    "        with open('_files/validation_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump(mean_validation_weightedlogloss, f)\n",
    "        with open('_files/validation_xgb_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump(validation_pred, f)\n",
    "    \n",
    "    # return performance\n",
    "    return {'loss':mean_validation_weightedlogloss, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_performance(X_train, y_train, X_validation, y_validation, parameters):\n",
    "    \n",
    "    # initialize validation performance and predictions\n",
    "    validation_weightedlogloss = []\n",
    "    validation_pred = []\n",
    "    \n",
    "    # iterate over number of training/validation splits\n",
    "    for i in range(k_train_validation):\n",
    "        \n",
    "        # positive weight\n",
    "        pos_weight = len([x for x in y_train[i] if x==0])/len([x for x in y_train[i] if x==1])\n",
    "\n",
    "        # parameters\n",
    "        param = parameters.copy()\n",
    "        param['class_weight'] = {0:1, 1:pos_weight}\n",
    "        param['random_state'] = seed_\n",
    "        param['n_estimators'] = int(param['n_estimators'])\n",
    "\n",
    "        # train on training\n",
    "        clf = RandomForestClassifier(**param).fit(X_train[i], y_train[i])\n",
    "\n",
    "        # evaluate on validation\n",
    "        y_pred = clf.predict_proba(X_validation[i])\n",
    "        pos_weight = len([x for x in y_validation[i] if x==0])/len([x for x in y_validation[i] if x==1])\n",
    "        sample_weights = [pos_weight if x==1 else 1 for x in y_validation[i]]\n",
    "        weightedlogloss = log_loss(y_validation[i], y_pred, sample_weight=sample_weights)\n",
    "        validation_weightedlogloss.append(weightedlogloss)\n",
    "        validation_pred.append(y_pred)\n",
    "    \n",
    "    # average validation performance over all folds\n",
    "    mean_validation_weightedlogloss = np.mean(validation_weightedlogloss) + np.std(validation_weightedlogloss)/np.sqrt(len(validation_weightedlogloss))\n",
    "    return mean_validation_weightedlogloss, np.concatenate(validation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_y(y):\n",
    "    \n",
    "    dummy_y_ = [[],[]]\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            dummy_y_[0].append(1)\n",
    "            dummy_y_[1].append(0)\n",
    "        else:\n",
    "            dummy_y_[0].append(0)\n",
    "            dummy_y_[1].append(1)\n",
    "    dummy_y_ = np.array(dummy_y_).T\n",
    "    return dummy_y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over datasets\n",
    "for a in range(len(datasets)):\n",
    "    \n",
    "    # folder\n",
    "    os.mkdir('%s/_individual/%s' % (output_folder, datasets[a]))\n",
    "    \n",
    "# performance files\n",
    "performance_files_weightedlogloss = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=datasets)\n",
    "performance_files_weightedlogloss.to_csv('%s/_individual/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "performance_files_balancedaccuracy = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=datasets)\n",
    "performance_files_balancedaccuracy.to_csv('%s/_individual/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "performance_files_auroc = pd.DataFrame(index=['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)]+['MEAN','STERR'], columns=datasets)\n",
    "performance_files_auroc.to_csv('%s/_individual/auroc.csv' % output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "DATASET: clinical\n",
      "-------------------------\n",
      "Split 1\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [05:25<00:00,  2.32it/s, best loss: 0.4616142253801125]\n",
      "Split 2\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:31<00:00,  1.98it/s, best loss: 0.4825529504465158]\n",
      "Split 3\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [02:52<00:00,  1.43it/s, best loss: 0.4441096460459606]\n",
      "Split 4\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [02:48<00:00,  3.29it/s, best loss: 0.48121814827706055]\n",
      "Split 5\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:12<00:00,  3.14it/s, best loss: 0.46338170564995873]\n",
      "Split 6\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:51<00:00,  1.76s/it, best loss: 0.4659264361982029]\n",
      "Split 7\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [02:41<00:00,  2.98it/s, best loss: 0.47940645941354876]\n",
      "Split 8\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:41<00:00,  6.08it/s, best loss: 0.4768442127730349]\n",
      "Split 9\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:39<00:00,  1.49it/s, best loss: 0.48200889089583043]\n",
      "Split 10\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:47<00:00,  1.93it/s, best loss: 0.4654708707816137]\n",
      "Split 11\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [06:07<00:00,  1.65s/it, best loss: 0.4911711779231431]\n",
      "Split 12\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:37<00:00,  2.82s/it, best loss: 0.4625420101089982]\n",
      "Split 13\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [02:45<00:00,  5.45it/s, best loss: 0.4863305134347007]\n",
      "Split 14\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:44<00:00,  1.99it/s, best loss: 0.47220681533761055]\n",
      "Split 15\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:37<00:00,  2.07it/s, best loss: 0.47120937078472797]\n",
      "Split 16\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:14<00:00,  1.55s/it, best loss: 0.4838775744811406]\n",
      "Split 17\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:20<00:00,  2.27s/it, best loss: 0.46058971336666127]\n",
      "Split 18\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:17<00:00,  2.28it/s, best loss: 0.4661073549704818]\n",
      "Split 19\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [04:33<00:00,  1.82it/s, best loss: 0.46413878893369326]\n",
      "Split 20\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [03:51<00:00,  2.12it/s, best loss: 0.47943424905474163]\n",
      "-------------------------\n",
      "DATASET: gene_all\n",
      "-------------------------\n",
      "Split 1\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [36:19<00:00,  5.11s/it, best loss: 0.5287270367916533]\n",
      "Split 2\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [28:55<00:00,  5.35s/it, best loss: 0.5475582142536548]\n",
      "Split 3\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [16:31<00:00,  2.77s/it, best loss: 0.5459629763311525]\n",
      "Split 4\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [34:16<00:00,  3.04s/it, best loss: 0.5543444371210983]\n",
      "Split 5\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [14:52<00:00,  3.91s/it, best loss: 0.556458483753157]\n",
      "Split 6\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [12:39<00:00,  1.29s/it, best loss: 0.5416502685975217]\n",
      "Split 7\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [23:13<00:00,  2.51s/it, best loss: 0.5513896854431082]\n",
      "Split 8\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [17:14<00:00,  1.13s/it, best loss: 0.5612524598118855]\n",
      "Split 9\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [29:18<00:00,  4.95s/it, best loss: 0.5486171502849929]\n",
      "Split 10\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [21:49<00:00,  3.15s/it, best loss: 0.5289457071329972]\n",
      "Split 11\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [20:40<00:00,  2.46s/it, best loss: 0.5476398570028316]\n",
      "Split 12\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [29:36<00:00,  4.58s/it, best loss: 0.5601017798805399]\n",
      "Split 13\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [06:06<00:00,  1.10it/s, best loss: 0.5540590431148684]\n",
      "Split 14\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [14:50<00:00,  2.78s/it, best loss: 0.554989495243598]\n",
      "Split 15\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [22:13<00:00,  4.99s/it, best loss: 0.5325180701395439]\n",
      "Split 16\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [36:37<00:00, 10.30s/it, best loss: 0.5584977469850109]\n",
      "Split 17\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [17:12<00:00,  5.66s/it, best loss: 0.5413243000575672]\n",
      "Split 18\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [27:43<00:00,  2.97s/it, best loss: 0.5435266279615789]\n",
      "Split 19\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [10:11<00:00,  1.27s/it, best loss: 0.5424799163478943]\n",
      "Split 20\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [14:23<00:00,  1.72s/it, best loss: 0.554989452042509]\n",
      "-------------------------\n",
      "DATASET: mutation_onehot_all\n",
      "-------------------------\n",
      "Split 1\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [08:39<00:00,  1.10s/it, best loss: 0.6811928981114346]\n",
      "Split 2\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:02<00:00,  2.14s/it, best loss: 0.6738588629628472]\n",
      "Split 3\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [09:33<00:00,  2.52s/it, best loss: 0.6915288845488831]\n",
      "Split 4\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [08:54<00:00,  2.07s/it, best loss: 0.689588039769903]\n",
      "Split 5\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:46<00:00,  1.60s/it, best loss: 0.6876888383600074]\n",
      "Split 6\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [06:46<00:00,  1.15s/it, best loss: 0.6771320392686625]\n",
      "Split 7\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:38<00:00,  1.43s/it, best loss: 0.6774623098718916]\n",
      "Split 8\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [09:36<00:00,  2.13s/it, best loss: 0.6839212840791374]\n",
      "Split 9\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:10<00:00,  1.35s/it, best loss: 0.6769363956891731]\n",
      "Split 10\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [09:09<00:00,  2.29s/it, best loss: 0.6849404618993642]\n",
      "Split 11\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [11:03<00:00,  1.97s/it, best loss: 0.683539755938478]\n",
      "Split 12\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [09:19<00:00,  2.14s/it, best loss: 0.6921341460493725]\n",
      "Split 13\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [09:56<00:00,  2.41s/it, best loss: 0.6808499581367726]\n",
      "Split 14\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:41<00:00,  1.67s/it, best loss: 0.6799990508950777]\n",
      "Split 15\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [08:02<00:00,  2.58s/it, best loss: 0.6705789829156152]\n",
      "Split 16\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:07<00:00,  1.08s/it, best loss: 0.6890540799033724]\n",
      "Split 17\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:58<00:00,  2.46s/it, best loss: 0.6761837689158904]\n",
      "Split 18\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [08:28<00:00,  1.89s/it, best loss: 0.6776425480818326]\n",
      "Split 19\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [07:17<00:00,  1.46s/it, best loss: 0.6782514339789767]\n",
      "Split 20\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [08:24<00:00,  1.52s/it, best loss: 0.6739032915236405]\n"
     ]
    }
   ],
   "source": [
    "# iterate over datasets\n",
    "for a in range(len(datasets)):\n",
    "    print('-------------------------')\n",
    "    print('DATASET: %s' % datasets[a])\n",
    "    print('-------------------------')\n",
    "    \n",
    "    # load dataset\n",
    "    with open('_datasets/%s.pickle' % datasets[a], 'rb') as f:\n",
    "        X_matrix, y_vector, categorical_conversion = pickle.load(f, encoding='latin1')\n",
    "    X_matrix.columns = ['%s # %s' % (datasets[a], feature) for feature in X_matrix.columns.tolist()]\n",
    "\n",
    "    # divide train+validation from testing\n",
    "    trainvalidation_index = []\n",
    "    test_index = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits_trainvalidation_test, test_size=test_size, random_state=seed_)\n",
    "    for trainvalidation_, test_ in sss.split(X_matrix, y_vector):\n",
    "        trainvalidation_index.append(list(trainvalidation_))\n",
    "        test_index.append(list(test_))\n",
    "\n",
    "    # iterate over number of training+validation/testing splits\n",
    "    for b in range(n_splits_trainvalidation_test):\n",
    "        print('Split %d' % (b+1))\n",
    "        \n",
    "        # separate train+validation and testing\n",
    "        X_trainvalidation = X_matrix.iloc[trainvalidation_index[b],]\n",
    "        X_test = X_matrix.iloc[test_index[b],]\n",
    "        y_trainvalidation = y_vector[trainvalidation_index[b]]\n",
    "        y_test = y_vector[test_index[b]]\n",
    "        \n",
    "        # divide train from validation\n",
    "        train_index = []\n",
    "        validation_index = []\n",
    "        skf = StratifiedKFold(n_splits=k_train_validation, shuffle=True, random_state=seed_)\n",
    "        for train_, validation_ in skf.split(X_trainvalidation, y_trainvalidation):\n",
    "            train_index.append(list(train_))\n",
    "            validation_index.append(list(validation_))\n",
    "\n",
    "        # separate train and validation\n",
    "        X_train = []\n",
    "        X_validation = []\n",
    "        y_train = []\n",
    "        y_validation = []\n",
    "        for c in range(k_train_validation):\n",
    "            X_train.append(X_trainvalidation.iloc[train_index[c],])\n",
    "            X_validation.append(X_trainvalidation.iloc[validation_index[c],])\n",
    "            y_train.append(y_trainvalidation[train_index[c]])\n",
    "            y_validation.append(y_trainvalidation[validation_index[c]])\n",
    "            \n",
    "        # impute train+validation/testing\n",
    "        X_trainvalidation_ = X_trainvalidation.copy()\n",
    "        X_test_ = X_test.copy()\n",
    "        imp = SimpleImputer()\n",
    "        columns_to_add_back = [i for i,x in enumerate(X_trainvalidation.mean()) if pd.isna(x)]\n",
    "        X_trainvalidation = imp.fit_transform(X_trainvalidation)\n",
    "        for c in sorted(columns_to_add_back)[::-1]:\n",
    "            X_trainvalidation = np.hstack((X_trainvalidation[:,:c], np.zeros(X_trainvalidation.shape[0]).reshape(-1,1), X_trainvalidation[:,c:]))\n",
    "        X_test = imp.transform(X_test)\n",
    "        for c in sorted(columns_to_add_back)[::-1]:\n",
    "            X_test = np.hstack((X_test[:,:c], np.zeros(X_test.shape[0]).reshape(-1,1), X_test[:,c:]))\n",
    "        scaler = StandardScaler()\n",
    "        X_trainvalidation = scaler.fit_transform(X_trainvalidation)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # impute train/validation\n",
    "        X_train_ = X_train.copy()\n",
    "        X_validation_ = X_validation.copy()\n",
    "        for c in range(k_train_validation):\n",
    "            imp = SimpleImputer()\n",
    "            columns_to_add_back = [i for i,x in enumerate(X_train[c].mean()) if pd.isna(x)]\n",
    "            X_train[c] = imp.fit_transform(X_train[c])\n",
    "            for d in sorted(columns_to_add_back)[::-1]:\n",
    "                X_train[c] = np.hstack((X_train[c][:,:d], np.zeros(X_train[c].shape[0]).reshape(-1,1), X_train[c][:,d:]))\n",
    "            X_validation[c] = imp.transform(X_validation[c])\n",
    "            for d in sorted(columns_to_add_back)[::-1]:\n",
    "                X_validation[c] = np.hstack((X_validation[c][:,:d], np.zeros(X_validation[c].shape[0]).reshape(-1,1), X_validation[c][:,d:]))\n",
    "            scaler = StandardScaler()\n",
    "            X_train[c] = scaler.fit_transform(X_train[c])\n",
    "            X_validation[c] = scaler.transform(X_validation[c])\n",
    "            \n",
    "        # initialize test predictions\n",
    "        classifier_test_predictions = []\n",
    "\n",
    "        # xgb parameters\n",
    "        criterion_options = ['gini','entropy']\n",
    "        max_features_options = ['sqrt','log2']\n",
    "        parameters = {\n",
    "            'n_estimators': scope.int(hp.qloguniform('n_estimators', np.log(1e0), np.log(1e3), 1)),\n",
    "            'criterion': hp.choice('criterion', criterion_options), \n",
    "            'max_depth': scope.int(hp.uniform('max_depth', 1, 11)),\n",
    "            'min_samples_split': hp.uniform('min_samples_split', 0., 1.),\n",
    "            'min_samples_leaf': hp.uniform('min_samples_leaf', 0., 0.5),\n",
    "            'max_features': hp.choice('max_features', max_features_options)\n",
    "                     }\n",
    "\n",
    "        # save info for hyperopt\n",
    "        with open('_files/validation_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump(1000., f)\n",
    "        with open('_files/data_%s.pickle' % timestamp,'wb') as f:\n",
    "            pickle.dump([X_train, y_train, X_validation, y_validation], f)\n",
    "\n",
    "        # hyperopt to find best parameters\n",
    "        trials = Trials()\n",
    "        best = fmin(hyperopt_function, parameters, algo=tpe.suggest, max_evals=n_hyperopt_iterations, trials=trials, rstate=np.random.RandomState(seed_), verbose=0, show_progressbar=True)      \n",
    "            \n",
    "        # create classifier using best parameters\n",
    "        pos_weight = len([x for x in y_trainvalidation if x==0])/len([x for x in y_trainvalidation if x==1])\n",
    "            \n",
    "        # parameters\n",
    "        param = {'class_weight':{0:1, 1:pos_weight}, 'random_state':seed_, 'n_estimators':int(best['n_estimators']), 'criterion':criterion_options[best['criterion']], 'max_depth':best['max_depth'], 'min_samples_split':best['min_samples_split'], 'min_samples_leaf':best['min_samples_leaf'], 'max_features':max_features_options[best['max_features']]}\n",
    "\n",
    "        # train on training\n",
    "        clf = RandomForestClassifier(**param).fit(X_trainvalidation, y_trainvalidation)\n",
    "\n",
    "        # evaluate on validation\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "        # calculate test performance - weighted log loss\n",
    "        pos_weight = len([x for x in y_test if x==0])/len([x for x in y_test if x==1])\n",
    "        sample_weights = [pos_weight if x==1 else 1 for x in y_test]\n",
    "        performance = log_loss(y_test, y_pred, sample_weight=sample_weights)\n",
    "        performance_files_weightedlogloss.at['split_%d' % (b+1), datasets[a]] = performance\n",
    "        performance_files_weightedlogloss.at['MEAN', datasets[a]] = np.nanmean(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())\n",
    "        performance_files_weightedlogloss.at['STERR', datasets[a]] = np.nanstd(performance_files_weightedlogloss.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_weightedlogloss.to_csv('%s/_individual/weightedlogloss.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - balanced accuracy\n",
    "        y_pred_ = [1 if x>=0.5 else 0 for x in y_pred[:,1]]\n",
    "        performance = balanced_accuracy_score(y_test, y_pred_)\n",
    "        performance_files_balancedaccuracy.at['split_%d' % (b+1), datasets[a]] = performance\n",
    "        performance_files_balancedaccuracy.at['MEAN', datasets[a]] = np.nanmean(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())\n",
    "        performance_files_balancedaccuracy.at['STERR', datasets[a]] = np.nanstd(performance_files_balancedaccuracy.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_balancedaccuracy.to_csv('%s/_individual/balancedaccuracy.csv' % output_folder)\n",
    "\n",
    "        # calculate test performance - auroc\n",
    "        performance = roc_auc_score(dummy_y(y_test), y_pred)\n",
    "        performance_files_auroc.at['split_%d' % (b+1), datasets[a]] = performance\n",
    "        performance_files_auroc.at['MEAN', datasets[a]] = np.nanmean(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())\n",
    "        performance_files_auroc.at['STERR', datasets[a]] = np.nanstd(performance_files_auroc.loc[['split_%d' % x for x in range(1,n_splits_trainvalidation_test+1)], datasets[a]].values.tolist())/np.sqrt(b+1)\n",
    "        performance_files_auroc.to_csv('%s/_individual/auroc.csv' % output_folder)\n",
    "\n",
    "        # load validation predictions\n",
    "        with open('_files/validation_xgb_%s.pickle' % timestamp,'rb') as f:\n",
    "            validation_predictions = pickle.load(f)\n",
    "        validation_y = np.concatenate(y_validation)\n",
    "        validation_X = pd.concat(X_validation_)\n",
    "\n",
    "        # save results\n",
    "        with open('%s/_individual/%s/iter_%d.pickle' % (output_folder, datasets[a], b+1), 'wb') as f:\n",
    "            pickle.dump([validation_X, validation_y, validation_predictions, X_test_, y_test, y_pred, clf], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
